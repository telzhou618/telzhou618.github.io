[{"categories":["devops"],"content":"在现实中，往往会遇到集群节点资源紧张，这时候需要增加更多的节点来缓解，并且k8s会自动迁移一些容器到新的节点上，以保证各个节点压力均很，接下来利用 kubesphere 社区提供的集群安装工具 kubekey 来给集群增加新的 worker 节点。 现有的集群有三个节点，分别为master、node1、node2， 现在给集群扩容一个节点 node3，操作步骤如下所示。 ","date":"2024-04-09","objectID":"/posts/a9d9636/:0:0","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - k8s worker 节点扩容","uri":"/posts/a9d9636/"},{"categories":["devops"],"content":"\r创建新机器集群用的 VM 虚拟机，系统centos7，先找一台干净的虚拟机克隆一台新机器，注意需要关闭VM后才能点击克隆。 ","date":"2024-04-09","objectID":"/posts/a9d9636/:0:1","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - k8s worker 节点扩容","uri":"/posts/a9d9636/"},{"categories":["devops"],"content":"\r配置网络新克隆的虚拟机可能存在网络IP冲突，需要先配置一个新的IP地址，才能用xshell工具连接，按照如下步骤配置网络。 在vm窗口登录root账号 使用 nmtui 引导配置网络，在终端输入nmtui，具体步骤如下： nmtui 修改一个新的IP地址 保存后重启网络，如果没有任何输出说明ok。 systemctl restart newwork 然后就可以用 xshell 连接了，操作起来更加方便。 ","date":"2024-04-09","objectID":"/posts/a9d9636/:0:2","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - k8s worker 节点扩容","uri":"/posts/a9d9636/"},{"categories":["devops"],"content":"\r安装依赖 设置 hostname hostnamectl set-hostnmae node3 设置时区 timedatectl set-timezone Asia/Shanghai timedatectl 配置时间同步器 yum install -y chrony systemctl restart chronyd \u0026\u0026 systemctl enable chronyd 配置集群所有节点 hosts , 把 node3 加入到 hosts配置文件中。 其他三个要修改的地方，和安装集群时操作一致，这里放在一起说明。 1、关闭防火墙 systemctl stop firewalld systemctl disable firewalld 2、关闭 selinux sed -i 's/enforcing/disabled/' /etc/selinux/config # 永久关闭 setenforce 0 # 临时关闭 3、关闭 swap swapoff -a # 临时关闭 vim /etc/fstab # 永久关闭 #注释掉swap这行 # /dev/mapper/centos-swap swap swap defaults 0 0 systemctl reboot #重启生效 free -m #查看下swap交换区是否都为0，如果都为0则swap关闭成功 安装依赖, 这是集群所必须依赖的软件。 # 安装 Kubernetes 系统依赖包 yum install curl socat conntrack ebtables ipset ipvsadm # 安装其他必备包，openEuler 也是奇葩了，默认居然都不安装tar，不装的话后面会报错 yum install tar ","date":"2024-04-09","objectID":"/posts/a9d9636/:0:3","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - k8s worker 节点扩容","uri":"/posts/a9d9636/"},{"categories":["devops"],"content":"\r执行扩容 在 master 节点找到安装集群时用的配置文件和kk工具。 执行 vim 修改配置文件，加入 node3 新节点的配置信息。 vim config-sample.yaml 执行以下命令扩容，在检查通过后输入 yes export KKZONE=cn ./kk add nodes -f config-sample.yaml 一段时间后看到如下结果表示扩容成功。 ","date":"2024-04-09","objectID":"/posts/a9d9636/:0:4","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - k8s worker 节点扩容","uri":"/posts/a9d9636/"},{"categories":["devops"],"content":"\r验证状态 查看集群的状态，发现node3已就绪。 kubectl get node 登录到 kubesphere 控制台查看，部分节点已经自动迁移到 node3 上。 ","date":"2024-04-09","objectID":"/posts/a9d9636/:0:5","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - k8s worker 节点扩容","uri":"/posts/a9d9636/"},{"categories":["devops"],"content":"\r参考文档 基于 KubeKey 扩容 Kubernetes v1.24 Worker 节点实战 ","date":"2024-04-09","objectID":"/posts/a9d9636/:0:6","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - k8s worker 节点扩容","uri":"/posts/a9d9636/"},{"categories":["devops"],"content":"\r准备一个 spring-boot 项目项目如下，是一个简单的springboot项目 定义一个简单接口, 返回 helloworld package com.example.demo; import org.springframework.boot.*; import org.springframework.boot.autoconfigure.*; import org.springframework.web.bind.annotation.*; @SpringBootApplication @RestController public class DemoApplication { @GetMapping(\"/\") public String home() { return \"hello world!!!\"; } public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); } } 单元测试类 DemoApplicationTests.java package com.example.demo; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.boot.test.context.SpringBootTest.WebEnvironment; import org.springframework.boot.test.web.client.TestRestTemplate; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.test.context.junit4.SpringRunner; import static org.assertj.core.api.Assertions.assertThat; @RunWith(SpringRunner.class) @SpringBootTest(webEnvironment = WebEnvironment.RANDOM_PORT) public class DemoApplicationTests { @Test public void contextLoads() { } @Autowired private TestRestTemplate restTemplate; @Test public void homeResponse() { String body = this.restTemplate.getForObject(\"/\", String.class); assertThat(body).isNotBlank(); } } ","date":"2024-03-08","objectID":"/posts/a9d96f7/:1:0","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - Kubesphere CI/CD流谁线自动化部署","uri":"/posts/a9d96f7/"},{"categories":["devops"],"content":"\r开启devops功能登录 KubeSphere ，找到定制资源，搜索config 点击 ClusterConfiguration，然后点击三个点编辑YAML 编辑配置，将devops 的 enabled 改为true ","date":"2024-03-08","objectID":"/posts/a9d96f7/:2:0","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - Kubesphere CI/CD流谁线自动化部署","uri":"/posts/a9d96f7/"},{"categories":["devops"],"content":"\r流水线部署创建流水线项目 进入项目创建流水线 编辑流水线 全局代理选择 maven 第一步拉取代码 第二部单元测试 第三部打包并构建镜像 部署到指定k8s集群 搞定！ 运行流水线 运行日志 ","date":"2024-03-08","objectID":"/posts/a9d96f7/:3:0","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - Kubesphere CI/CD流谁线自动化部署","uri":"/posts/a9d96f7/"},{"categories":["devops"],"content":"\r所需配置文件完整的 jenkinsfile 文件内容 pipeline { agent { node { label 'maven' } } stages { stage('拉取代码') { agent none steps { git(url: 'http://192.168.1.4/root/java-web-demo.git', credentialsId: 'gitlab', branch: 'master', changelog: true, poll: false) } } stage('单元测试') { agent none steps { container('maven') { sh 'mvn clean test' } } } stage('构建镜像') { agent none steps { container('maven') { sh 'mvn -Dmaven.test.skip=true clean package' sh 'docker build -f deploy/Dockerfile -t $REGISTRY/$DOCKERHUB_NAMESPACE/$APP_NAME:SNAPSHOT-$BUILD_NUMBER .' withCredentials([usernamePassword(credentialsId: 'dockerhub-id', passwordVariable: 'DOCKER_PASSWORD', usernameVariable: 'DOCKER_USERNAME')]) { sh 'echo \"$DOCKER_PASSWORD\" | docker login $REGISTRY -u \"$DOCKER_USERNAME\" --password-stdin' sh 'docker push $REGISTRY/$DOCKERHUB_NAMESPACE/$APP_NAME:SNAPSHOT-$BUILD_NUMBER' } } } } stage('发布到test环境') { agent none steps { container('maven') { withCredentials([kubeconfigContent(credentialsId: 'demo-kubeconfig', variable: 'KUBECONFIG_CONTENT')]) { sh '''mkdir ~/.kube echo \"$KUBECONFIG_CONTENT\" \u003e ~/.kube/config envsubst \u003c deploy/k8s-deploy-test.yaml | kubectl apply -f -''' } } } } } environment { DOCKER_CREDENTIAL_ID = 'dockerhub-id' GITHUB_CREDENTIAL_ID = 'github-id' KUBECONFIG_CREDENTIAL_ID = 'demo-kubeconfig' REGISTRY = 'docker.io' DOCKERHUB_NAMESPACE = 'telzhou618' GITHUB_ACCOUNT = 'kubesphere' APP_NAME = 'java-web-demo-test' } } Dockerfile 文件 FROM java:8u92-jre-alpine MAINTAINER \"telzhou618\" ADD target/java-web-demo-0.0.1-SNAPSHOT.jar app.jar EXPOSE 8080 ENTRYPOINT [\"java\", \"-jar\", \"/app.jar\"] k8s-deploy.yaml 文件, 一个 Deployment, 一个service apiVersion: apps/v1 kind: Deployment metadata: labels: app: java-web-demo-test name: java-web-demo-test namespace: bbs spec: replicas: 2 selector: matchLabels: app: java-web-demo-test template: metadata: labels: app: java-web-demo-test spec: containers: - name: java-web-demo-test image: $REGISTRY/$DOCKERHUB_NAMESPACE/$APP_NAME:SNAPSHOT-$BUILD_NUMBER ports: - containerPort: 8080 protocol: TCP resources: limits: cpu: \"1\" requests: cpu: 500m restartPolicy: Always --- apiVersion: v1 kind: Service metadata: labels: app: java-web-demo-test name: java-web-demo-test namespace: bbs spec: ports: - name: http port: 8080 protocol: TCP targetPort: 8080 nodePort: 30963 selector: app: java-web-demo-test type: NodePort ","date":"2024-03-08","objectID":"/posts/a9d96f7/:4:0","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - Kubesphere CI/CD流谁线自动化部署","uri":"/posts/a9d96f7/"},{"categories":["devops"],"content":"\rKubekey 一键安装k8s","date":"2024-03-07","objectID":"/posts/fbb3944/:1:0","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - Kubekey安装k8s和kubesphere","uri":"/posts/fbb3944/"},{"categories":["devops"],"content":"\r准备工作三台虚拟机, 系统为 centos7, 如下 机器IP hostname 角色 192.168.1.20 k8s-master master 192.168.1.21 k8s-node1 worker 192.168.1.22 k8s-node2 worker 执行如下操作 1、关闭防火墙 systemctl stop firewalld systemctl disable firewalld 2、关闭 selinux sed -i 's/enforcing/disabled/' /etc/selinux/config # 永久关闭 setenforce 0 # 临时关闭 3、关闭 swap swapoff -a # 临时关闭 vim /etc/fstab # 永久关闭 #注释掉swap这行 # /dev/mapper/centos-swap swap swap defaults 0 0 systemctl reboot #重启生效 free -m #查看下swap交换区是否都为0，如果都为0则swap关闭成功 4、给三台机器分别设置主机名 hostnamectl set-hostname \u003chostname\u003e 第一台：k8s-master 第二台：k8s-node1 第三台：k8s-node2 5、设置时间同步 yum install ntpdate -y ntpdate time.windows.com ","date":"2024-03-07","objectID":"/posts/fbb3944/:1:1","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - Kubekey安装k8s和kubesphere","uri":"/posts/fbb3944/"},{"categories":["devops"],"content":"\rkubekey安装k8s集群 安装 socat，必须 yum install -y socat 安装conntrack，必须 yum install -y conntrack 下载 kubekey 工具 curl -sfL https://get-kk.kubesphere.io | VERSION=v3.0.13 sh - 授权kk工具可执行权限 chmod +x kk 创建集群配置文件 ./kk create config --with-kubernetes v1.23.10 --with-kubesphere v3.4.1 在当前目录生成 config-sample.yaml 可通过 [-f ~/myfolder/abc.yaml] 制定配置文件位置 编辑配置文件，修改 hosts 节点信息，修改 roleGroups 各个组件的节点 vim config-sample.yaml 创建集群 ./kk create cluster -f config-sample.yaml 验证通过会提是是否开始安装，输入 yes 暗转，耐心等待 会自动安装依赖的 docker 机器 k8s相关的组件，同时会安装 kubesphere 管理工具。 一段时间后看到类似下面界面表示安装成功，速度取决于网速 查看集群，浏览区输入上面的地址和账号密码登录 ","date":"2024-03-07","objectID":"/posts/fbb3944/:1:2","tags":["k8s","kubesphere"],"title":"k8s学习笔记 - Kubekey安装k8s和kubesphere","uri":"/posts/fbb3944/"},{"categories":["devops"],"content":"\r安装 k8s准备三台机器, 系统为 centos7, 如下 机器IP hostname 角色 192.168.1.20 k8s-master master 192.168.1.21 k8s-node1 worker 192.168.1.22 k8s-node2 worker ","date":"2024-03-06","objectID":"/posts/8a64657/:1:0","tags":["k8s"],"title":"k8s学习笔记 - k8s安装和基本用法","uri":"/posts/8a64657/"},{"categories":["devops"],"content":"\r准备工作安装前期准备，以下8个步骤在三台机器都要执行。 关闭防火墙 systemctl stop firewalld systemctl disable firewalld 关闭 selinux sed -i 's/enforcing/disabled/' /etc/selinux/config # 永久关闭 setenforce 0 # 临时关闭 关闭 swap vim /etc/fstab # 永久关闭 #注释掉swap这行，需要重启生效 # /dev/mapper/centos-swap swap swap defaults 设置机器hostname hostnamectl set-hostname \u003chostname\u003e 192.168.1.20：k8s-master 192.168.1.21：k8s-node1 192.168.1.22：k8s-node2 设置时间同步 # 设置时区为亚洲上海 timedatectl set-timezone Asia/Shanghai timedatectl status # 查看状态 # 同步时间 yum install ntpdate -y ntpdate time.windows.com 这一步成败的关键，三台机器的时间要同步 重启机器,让以上所有设置生效 reboot 安装 docker, 这是k8s所需要的 # 安装utiles 拥有 yum-config-manager 工具 yum install -y yum-utils # 设置 docker yum 源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum makecache fast # 查看 docker-ce 版本 yum list docker-ce --showduplicates | sort -r # 安装 yum install -y docker-ce-3:19.03.9-3.el7.x86_64 # 这是指定版本安装 开启启动 systemctl start docker \u0026\u0026 systemctl enable docker 安装 kubelet, kubeadm, kubectl # 添加 k8s yum 源 cat \u003e /etc/yum.repos.d/kubernetes.repo \u003c\u003c EOF [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 查看所有版本 yum list kubelet --showduplicates | sort -r # 安装kubelet、kubeadm、kubectl 指定版本 yum install -y kubelet-1.18.0 kubeadm-1.18.0 kubectl-1.18.0 # 开机启动 systemctl enable kubelet \u0026\u0026 systemctl start kubelet ","date":"2024-03-06","objectID":"/posts/8a64657/:1:1","tags":["k8s"],"title":"k8s学习笔记 - k8s安装和基本用法","uri":"/posts/8a64657/"},{"categories":["devops"],"content":"\r初始化集群 初始化集群，在 master 节点执行 kubeadm init --apiserver-advertise-address=192.168.1.20 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.18.0 --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16 根据初始化结果执行以下操作，在 master 节点执行 #配置使用 kubectl 命令工具(类似docker这个命令)，执行上图第二个红框里的命令 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config #查看kubectl是否能正常使用 kubectl get nodes #安装 Pod 网络插件 kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml # 如果上面这个calico网络插件安装不成功可以试下下面这个 # kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kubeflannel.yml 将worker节点加入到集群，分别在node1和node2上执行以下操作 # 将node节点加入进master节点的集群里 kubeadm join 192.168.1.20:6443 --token hbovty.6x82bkdlsk6dfy32 \\ --discovery-token-ca-cert-hash sha256:659511b431f276b2a5f47397677b1dff74838ae5eb18e24135e6dae1b8c45840 ","date":"2024-03-06","objectID":"/posts/8a64657/:1:2","tags":["k8s"],"title":"k8s学习笔记 - k8s安装和基本用法","uri":"/posts/8a64657/"},{"categories":["devops"],"content":"\r验证集群 kubectl get nodes ","date":"2024-03-06","objectID":"/posts/8a64657/:1:3","tags":["k8s"],"title":"k8s学习笔记 - k8s安装和基本用法","uri":"/posts/8a64657/"},{"categories":["devops"],"content":"\r安装 tomcat 运行 deployment kubectl create deployment my-tomcat --image=tomcat:7.0.75-alpine 暴露 service kubectl expose deployment my-tomcat --name=tomcat --port=8080 --type=NodePort 验证, 浏览器输入http://192.168.1.21:31520 查看 ","date":"2024-03-06","objectID":"/posts/8a64657/:2:0","tags":["k8s"],"title":"k8s学习笔记 - k8s安装和基本用法","uri":"/posts/8a64657/"},{"categories":["devops"],"content":"\r其他操作命令 创建部署 kubectl create deployment my-tomcat --image=tomcat:7.0.75-alpine 查看pod 日志 kubectl logs my-tomcat-685b8fd9c9-rw42d(pod名称) 进入Pod 容器 kubectl exec my-tomcat-685b8fd9c9-rw42d -- sh 暴露服务 kubectl expose deployment my-tomcat --name=tomcat --port=8080 --type=NodePort 删除 pod,service,deployment kubectl delete pod pod-name -n [namespace] kubectl delete service service-name -n [namespace] kubectl delete deployment deplotment-name -n [namespace] 扩容 kubectl scale --replicas=5 deployment my-tomcat 查看 Pod 详细信息 kubectl describe pod my-tomcat-547db86547-4btmd 回滚 # 查看历史版本 kubectl rollout history deploy my-tomcat # 回滚到上一个版本 kubectl rollout undo deployment my-tomcat #--to-revision 参数可以指定回退的版本 ","date":"2024-03-06","objectID":"/posts/8a64657/:3:0","tags":["k8s"],"title":"k8s学习笔记 - k8s安装和基本用法","uri":"/posts/8a64657/"},{"categories":["devops"],"content":"\rdocker 安装JK下载镜像 docker pull jenkins 启动 docker run -d -p 8088:8080 -p 50000:50000 -v /docker/jenkins_home:/var/jenkins_home jenkins 报错了，挂在的目录 /docker/jenkins_home 无权限 解决方案：更改宿主机挂载目录的权限,使用 chmod 命令将 /docker/jenkins_home 目录的权限更改为允许容器内的用户写入 sudo chmod 777 /docker/jenkins_home 注意：chmod 777 是开放最大权限，这样做可能会存在安全风险，最好根据实际需求设置更严格的权限。 再次执行上面的docker run 重启容器，然后 docker ps 查看运行状态,显示Up,正常。 docker ps 打开浏览器，输入宿主主机ip:8080 看到下面结果说明jk安装成功。 登录jenkins, 根据界面提示密码在 /var/jenkins_home/secrets/initialAdminPassword,docker 启动时做了目录映射，对应宿主机的目录为 /docker/jenkins_home/ cat /docker/jenkins_home/secrets/initialAdminPassword 输入密码后登录。 ","date":"2024-03-02","objectID":"/posts/704c8ae/:1:0","tags":["jenkins"],"title":"Jenkins 的三种安装方式","uri":"/posts/704c8ae/"},{"categories":["devops"],"content":"\rcentos yum安装JK","date":"2024-03-02","objectID":"/posts/704c8ae/:2:0","tags":["jenkins"],"title":"Jenkins 的三种安装方式","uri":"/posts/704c8ae/"},{"categories":["devops"],"content":"\r安装 jdk最新版的jk最低要求java11,先卸载低版本的 java, 查找一下已安装的java版本 yum list installed | grep java 查找 java1.7和1.8两个版本，都先卸载掉,执行以下命令 yum remove -y java* 然后安装 java11, 在安装之前先查找一下 yum list | grep java-11 执行 Install 安装 yum install -y java-11-openjdk-devel 注意，执行 yum install -y java-11-openjdk 安装的的包不完整，会缺少jps、javac等命令，这里执行上面命令，会自动依赖安装 java-11-openjdk 包。 验证是否安装成功 java -version ok, 下面安装jenkins。 ","date":"2024-03-02","objectID":"/posts/704c8ae/:2:1","tags":["jenkins"],"title":"Jenkins 的三种安装方式","uri":"/posts/704c8ae/"},{"categories":["devops"],"content":"\r安装 jenkins设置官方最新jk镜像仓库,地址：https://pkg.jenkins.io/redhat-stable/ sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key 安装 yum install -y jenkins 查看安装位置 rpm -ql jenkins 启动jk服务 systemctl start jenkins 日志显示启动失败,查看下状态 systemctl status jenkins 再看看启动日志 journalctl -u jenkins.service # 从头查看日志 发现端口被占用，这种情况会一直重启，不断尝试。 原来的是我的 docker 容器有个tomcat占用了8080端口，先把它kill或停止掉。 docker ps docker stop my-tomcat # 停止tomcat容器 再次启动 jenkins systemctl start jenkins # 启动 systemctl status jenkins # 查看状态 在浏览器输入ip:8080 查看，看到下面界面说明安装成功了。 根据提示密码存在 /var/lib/jenkins/secrets/initialAdminPassword 文件中，找到后输入密码。 安装插件页面，推荐选择“安装推荐的插件”，点击等等安装。 等等安装下面的插件。 下一步创建管理员用户。 点击完成，进入JK主界面。 ","date":"2024-03-02","objectID":"/posts/704c8ae/:2:2","tags":["jenkins"],"title":"Jenkins 的三种安装方式","uri":"/posts/704c8ae/"},{"categories":["devops"],"content":"\r开机启动启动服务 systemctl start jenkins 查看服务状态 systemctl status jenkins 查看启动日志 journalctl -u jenkins.service # 从头查看日志 journalctl -f -u jenkins.service # -f 监听日志变化 查看服务的开机启动状态 systemctl list-unit-files | grep jenkins 设为开机启动 systemctl enable jenkins 其他 systemctl 命令 systemctl stop jenkins # 停止 systemctl restart jenkins # 重启 systemctl enable jenkins # 设为开机启动 systemctl disable jenkins # 禁用开机启动 ","date":"2024-03-02","objectID":"/posts/704c8ae/:2:3","tags":["jenkins"],"title":"Jenkins 的三种安装方式","uri":"/posts/704c8ae/"},{"categories":["devops"],"content":"\rwar 包安装JK下载 war 包，下载地址：https://www.jenkins.io/zh/doc/book/installing/，点击WAR包下载。 前提安装java11,新版jk的最低要求。 最简单的方式启动 java -jar jenkins.war 默认端口8080 指定端口启动 java -jar jenkins.war --httpPort=9090 生产环境最佳实战 创建工作目录 mkdir -p /root/.jinkins_home 启动jk服务 java -DJENKINS_HOME=/root/.jenkins_home/ -jar jenkins.war --httpPort=9090 --logfile=/root/.jenkins_home/jenkins.log -DJENKINS_HOME 指定工作目录 –httpPort 端口 –logfile 日志文件位置 后台启动 nohup java -DJENKINS_HOME=/root/.jenkins_home/ -jar jenkins.war --httpPort=9090 --logfile=/root/.jenkins_home/jenkins.log \u0026 会在当前目录下生成 nohup.out 文件作为输出日志，更多详细日志查看–logfile 的配置。 浏览器地址输入 ip:9090 验证。 ","date":"2024-03-02","objectID":"/posts/704c8ae/:3:0","tags":["jenkins"],"title":"Jenkins 的三种安装方式","uri":"/posts/704c8ae/"},{"categories":["linux"],"content":"虚拟机 centos 启动后网络无法启动报错 解决报错Failed to start LSB: Bring up/down networking一般情况是网络冲突了或者mac地址冲突。 查看网络状态 systemctl status network ","date":"2024-03-01","objectID":"/posts/57808a3/:0:0","tags":["centos"],"title":"Centos 网络错误问题解决","uri":"/posts/57808a3/"},{"categories":["linux"],"content":"\r解决方案1禁用 NetworkManager systemctl stop NetworkManager systemctl disable NetworkManager 重启网络服务 systemctl start network 如果还没好, 尝试以下家解决方案 ","date":"2024-03-01","objectID":"/posts/57808a3/:1:0","tags":["centos"],"title":"Centos 网络错误问题解决","uri":"/posts/57808a3/"},{"categories":["linux"],"content":"\r解决方案2查看MAC地址 ip a 修改网络配置文件, 加上 mac 地址 cd /etc/sysconfig/network-scripts/ vim ifcfg-ens33 最后重启网络看看！ ","date":"2024-03-01","objectID":"/posts/57808a3/:2:0","tags":["centos"],"title":"Centos 网络错误问题解决","uri":"/posts/57808a3/"},{"categories":["java"],"content":"\r微服务的优缺点","date":"2024-02-24","objectID":"/posts/57808a6/:1:0","tags":["微服务"],"title":"微服务的优缺点","uri":"/posts/57808a6/"},{"categories":["java"],"content":"\r优点 易于开发和维护， 每个模块独立开发，不同的人负责不同的模块，互不干涉，减少冲突，提高效率。 易独立部署易扩展，每个服务费独立部署，易于弹性伸缩，不同的微服务部署不同的数量，资源利用率高。 技术选择更具多样性，不同的微服务可以使用不同的语言，选择性更多，人尽其才，物尽其用。 可靠性和容错能力、并发能力强，个别微服务的故障不会影响整个系统的稳定性，同时不同的请求发到不同的服务，调度不同机器的计算机资源，并发能力强。 ","date":"2024-02-24","objectID":"/posts/57808a6/:1:1","tags":["微服务"],"title":"微服务的优缺点","uri":"/posts/57808a6/"},{"categories":["java"],"content":"\r缺点 技术更复杂，微服务之后需要服务器注册、发现、负载均衡、分布式链路跟踪等技术的支持。 运维成本高，拆分成多个服务后，运维部署成功高，需要额外的工具支持。 服务间通信的开销，跨网络调用，带来一定的新能损失。 数据一致性问题，夸多个节点调用数据一致性难保证，需要分布式事务、补偿机制来保证。 ","date":"2024-02-24","objectID":"/posts/57808a6/:1:2","tags":["微服务"],"title":"微服务的优缺点","uri":"/posts/57808a6/"},{"categories":["java"],"content":"\r微服务拆分的原则 低耦合内聚, 相同的业务，关联度高的放在一起，保证单一职责，边界清晰，避免重复开发，不要你中有我，我中有你，比如一个商城，可以拆分陈商品、订单、用户、支付、物流等。 避免循环调用,避免微服务直接复杂的调用关系，不要出现直接或间接的循环依赖，比如:A-\u003eB-\u003eA, 或A-\u003eB-\u003eC-A，滚雪球事件就是这么发生的，出问题都不好排查。 尽量设计通用接口,不要为某一个业务方做定制接口，比如：查询订单，提供一个查询基础信息和完整信息的接口。 服务之间调用关系要清晰,分层调用，不能反向调用或同层直接互相调用。 微服务拆分要渐进式进行,不要一下子拆的太细，太细运维成本也会增加，根据业务情况调整。 ","date":"2024-02-24","objectID":"/posts/57808a6/:2:0","tags":["微服务"],"title":"微服务的优缺点","uri":"/posts/57808a6/"},{"categories":["db"],"content":"索引是帮助MySQL高效获取数据的排好序的数据结构。 ","date":"2023-08-28","objectID":"/posts/mysql-review/:0:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r索引的优缺点优点 索引大大减少了服务器需要扫描的数据量。 索引可以帮助服务器避免排序和临时表。 索引可以将随机IO变为顺序IO。 缺点 创建索引和维护索引要耗费时间 ，这种时间随着数据量的增加而增加。 索引需要占物理空间 。 ","date":"2023-08-28","objectID":"/posts/mysql-review/:1:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r索引的分类 主键索引(聚簇索引、聚集索引)、二级索引（非聚集索引）。 普通索引、唯一索引、全文索引。 独立索引、复合索引、前缀索引。 B+Tree 索引、Hash索引。 ","date":"2023-08-28","objectID":"/posts/mysql-review/:2:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r索引数据结构常见的索引数据结构有Hash表、二叉树、平衡二叉树、红黑树、B-Tree、B+Tree。 索引数据结构 Hash 索引：Hash 表只能做等值匹配，效率很高。但是不支持范围查找和排序，因为取每个数据要做hash运算，只有取出来才能知道他是什么。 二叉树：二叉树极端情况下树会变成一个链表，也不适合做索引。 平衡二叉树：平衡二叉树无法支持很大的数据，数据量大时，树的高度依然很高，效率不高。 红黑树：红黑树通过限制节点的颜色控制数据变化时树的旋转次数，插入、删除数据时性能有一定提升，但树高依然无法控制，无法支持大数据量。 B-tree：非叶子节点存储真实数据，占用空间大，可存储的索引会减少。 B+tree：所有数据存在叶子节点，非叶子节点只存索引，可容纳更多的索引数据。 SQL性能分析工具Explain 工具详解 在一条查询语句前加 explain 可以获得SQL语句的执行计划，可看到使用了什么索引，大致扫描了多少行等信息，从而分析出SQL语句的瓶颈在哪里。 explain select * from employees where name = ‘Lucy’; ","date":"2023-08-28","objectID":"/posts/mysql-review/:3:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r几个MySQL命令 mysql.server start // 启动MySQL mysql.server stop // 停止MYSQL ./mysqld_safe --data=../data // 从data备份中恢复数据 ./mysql_secure_installation // 修改管理员密码 ","date":"2023-08-28","objectID":"/posts/mysql-review/:4:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\rExplain 工具详解在一条查询语句前加 explain 可以获得SQL语句的执行计划，可看到使用了什么索引，大致扫描了多少行等信息，从而分析出SQL语句的瓶颈在哪里。 explain select * from employees where name = 'Lucy'; 下面介绍下 Explain 中的列。 id 一条SQL语句在MySQL底层可要分成条语句执行，比如关联查询，ID代表SQL语句执行的优先级，ID越大的SQL先执行，ID一样的从上到下一次执行，ID为NULL最后执行。 select_type select_type 代表要执行的SQL语句复杂还是简单，取值有如下几种。 simple : 简单查下，不包括子查询或uniun。 primary：代表复杂查询总最外层的select。 subquery：包含在 select 中的子查询（不在 from 子句中）。 derived：包含在from语句中的子查询，代表用到临时表。 union：包含union 查询。 table 代表正在查询的是哪个表，table 如果是 ，表示使用的临时表，N 就是依赖查询的ID的值，会先执行id=N 语句。当有union 时，table 列为\u003cunion1,2\u003e,1,2 分别代表参与SQL的ID。 type 表示关联类型或访问类型, 查找数据的大致范围，性能从最优到最差一次为：system \u003e const \u003e eq_ref \u003e ref \u003e range \u003e index \u003e ALL，一般DBA要求要达到range，最好是ref。 const或system：primary key 或 unique key 的所有列与常数比较，只匹配一行，速度很快。 eq_ref：primary key 或 unique key 索引的所有部分被连接使用，只返回一行。 ref：普通索引或唯一索引前缀匹配，可能找到多行。 range：范围查找，如：in、between、\u003e 、\u003c、\u003e= 等。 index：扫描二级索引的全部叶节点，一般为覆盖索引。 ALL：扫描主键索引的叶节点，指全表扫描。 possible_keys 代表MySQL可能选择哪些索引来查找。 当possible_keys有值，key 为NULL时，代表数据不多，走索引还要回表，MySQL 认为直接走全表扫描可能会快一点； 当possible_keys为NULL时，代表没有索引可用，直接全表扫描。 key 代表查询实际使用的索引，为NULL表示没有选用索引，如果有可用的索引可以用 force index强制走索引，ignore index忽略索引。 select * from employees force index( idx_name_age_position) where name = ‘Lucy’; key_len 代表查询使用索引的字节数，通过这个值可以算出具体使用索引中的那一列，比如当索引是联合索引的时候。 key_len计算规则如下： 字符串，char(n)和varchar(n) ，5.0.3以后版本中，n均代表字符数，而不是字节数，如果是utf-8，一个数字或字母占1个字节，一个汉字占3个字节。 char(n)：如果存汉字长度就是 3n 字节 varchar(n)：如果存汉字则长度是 3n + 2 字节，加的2字节用来存储字符串长度，因为varchar是变长字符串 数值类型 tinyint：1字节 smallint：2字节 int：4字节 bigint：8字节 时间类型 date：3字节timestamp：4字节 datetime：8字节 如果字段允许为 NULL，需要1字节记录是否为 NULL 索引最大长度是768字节，当字符串过长时，mysql会做一个类似左前缀索引的处理，将前半部分的字符提取出来做索引。 ref 代表key对于的索引中，查找值用到的列或常量，常见的有 const、字段名。 rows 代表大概扫描的行数，不是结果集准确的行数。 Extra 代表额外的信息,取值如下: - Using index：使用覆盖索引。\r- Using where：查询的列没有索引。\r- Using index condition：查询的列表未完全被索引覆盖，要加索引优化。\r- Using temporay：需要临时表处理查询，要优化。 - Using filesort：借用外部空间排序，数据少用内存，数据大用磁盘，要加索引优化。\r- Select tables optimized away：使用聚合函数访问索引字段，如：max,min 等。 ","date":"2023-08-28","objectID":"/posts/mysql-review/:5:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r索引最佳实战实例表 CREATE TABLE `employees` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(24) NOT NULL DEFAULT '' COMMENT '姓名', `age` int(11) NOT NULL DEFAULT '0' COMMENT '年龄', `position` varchar(20) NOT NULL DEFAULT '' COMMENT '职位', `hire_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '入职时间', PRIMARY KEY (`id`), KEY `idx_name_age_position` (`name`,`age`,`position`) USING BTREE ) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8 COMMENT='员工记录表'; 常见实例 不在索引上做任何操作，如：计算、函数、类型转换等，会导致索引失效。 EXPLAIN SELECT * FROM employees WHERE left (name, 3) = 'LiLei'; 存储引擎不能使用索引范围条件右边的列。如下只有 nage 和 age 字段参与索引查找。可通过 key_len 长度确定索引真实用到的字段。 EXPLAIN SELECT * FROM employees WHERE name = 'LiLei' AND age \u003e 22 AND position = 'manager'; 尽量用覆盖索引，减少SLECT * 语句。 EXPLAIN SELECT name, age FROM employees WHERE name = 'LiLei' AND age = 23 AND position = 'manager'; 不等于(!=或者\u003c\u003e)、not in、not exists 都不走索引。 EXPLAIN SELECT * FROM employees WHERE name != 'LiLei'; \u003c、\u003e、\u003c=、\u003e= 索引优化器会根据检索比例、表大小等因素评估是否走索引。 EXPLAIN SELECT * FROM employees WHERE name \u003e= 'LiLei'; is null、is not null 一般也不走索引。 EXPLAIN SELECT * FROM employees WHERE name is null like 查询通配符开都不走索引。 EXPLAIN SELECT * FROM employees WHERE name like '%Lei' 字符串不加单引号会使索引失效。 EXPLAIN SELECT * FROM employees WHERE name = 1000; 少用 or 或 in, 查询时不一定走索引，优化器评估确定是否走索引。 EXPLAIN SELECT * FROM employees WHERE name = 'LiLei' or name = 'HanMeimei'; 强制走索引 EXPLAIN SELECT * FROM employees force index(idx_name_age_position) WHERE name \u003e 'LiLei' AND age = 22 A ND position ='manager'; 虽然使用了强制走索引让联合索引第一个字段范围查找也走索引，扫描的行rows看上去也少了点，但是最终查找效率不一定比全表 扫描高，因为回表效率不高。 索引下推 EXPLAIN SELECT * FROM employees WHERE name like 'LiLei%' AND age = 22 AND position = 'manager'; 在MySQL5.6之前的版本，这个查询只能在联合索引里匹配到名字是’LiLei’开头的索引，然后拿这些索引对应的主键逐个回表，到主键索引上找出相应的记录，再比对age和position这两个字段的值是否符合。 MySQL 5.6引入了索引下推优化，可以在索引遍历过程中，对索引中包含的所有字段先做判断，过滤掉不符合条件的记录之后再回表，可以有效的减少回表次数。使用了索引下推优化后，上面那个查询在联合索引里匹配到名字是’LiLei’ 开头的索引之后，同时还会在索引里过滤age和position这两个字段，拿着过滤完剩下的索引对应的主键id再回表查整行数据。 索引下推会减少回表次数，对于innodb引擎的表索引下推只能用于二级索引，innodb的主键索引（聚簇索引）树叶子节点上保存的是全行数据，所以这个时候索引下推并不会起到减少查询全行数据的效果。 为什么范围查找Mysql没有用索引下推优化？ 估计应该是Mysql认为范围查找过滤的结果集过大，likeKK%在绝大多数情况来看，过滤后的结果集比较小，所以这里Mysql选择给likeKK%用了索引下推优化，当然这也不是绝对的，有时like KK% 也不一定就会走索引下推。 ","date":"2023-08-28","objectID":"/posts/mysql-review/:6:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r一条SQL语句是如何执行的大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。 Server层 主要包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 Store层存 储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5 版本开始成为了默认存储引擎。也就是说如果我们在createtable时不指定表的存储引擎类型,默认会给你设置存储引擎为InnoDB。 连接器 负责与各种客户端建立连接、获取权限、维持和管理连接。 连接过程可分为两步：建立连接，然后要求输入用户名密码认证身份，认证成功后会获取用户所有权限放在用户的Session中。（如果此时修改了系统表user中的权限，也不影响已经建立了的连接，除非断开重连才会生效）。 查看已连接的用户： show processlist; -- Commend为Sleep为空闲连接。 查看连接默认时长： show global variables like \"wait_timeout\"; -- 默认值8小时。 修改连接默认时长： global wait_timeout=28800; -- 设置全局服务器关闭非交互连接之前等待活动的秒数 查询缓存 MySQL收到查询语句时，首先会到查询缓存查询，查不到再去查库，缓存的Key为SQL语句，Value就是查询结果。 只要对一个表更新，这个表上的所有查询缓存就会被清空。一般可以用在静态表中，对于频繁更新的表意义不大。 开启查询缓存： 修改my.cnf query_cache_type=2 // 0代表关闭查询缓存OFF，1代表开启ON，2（DEMAND按需，默认都不走缓存） 指定走查询缓存： select SQL_CACHE * from test where ID = 5; -- 用 SQL_CACHE 显示指定走缓存。 查看缓存是否开启： show global variables like \"%query_cache_type%\"; 控缓存命中率： show status like'%Qcache%'; mysql8.0已经移除了查询缓存功能。 分析器 首先此法分析器会分析每个词代表什么，然后会做语法分析，如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，经过此法分析器后生成一颗语法树。 优化器 优化SQL语句，选择走哪一个索引，或是全表扫码。 执行器 先做一次权限校验，再调用InnoDB的接口执行查询，获取结果； Bin-log 日志 记录CUD执行的日志，用于恢复数据。 ","date":"2023-08-28","objectID":"/posts/mysql-review/:7:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r如何选择索引 - Trace 工具Trace 工具可以清楚的看到一条SQL的详细执行步骤，开启 Trace 工具对MySQL性能有一定的影响，一般只有临时分析问题时开启，用完关闭。 开启 mysql \u003e set session optimizer_trace=\"enabled=on\",end_markers_in_json=on; -- 开启trace 实例 SELECT * FROM employees where name \u003e 'a' order by position; SELECT * FROM information_schema.OPTIMIZER_TRACE; 先执行一条查查语句，紧接着执行上面第二条语句，就能获得SQL执行的 Trace 计划，如下为关键信息说明。 Trace 结果说明文档参考：http://note.youdao.com/noteshare?id=d2e8a0ae8c9dc2a45c799b771a5899f6 结论：全表扫描的成本低于索引扫描，所以mysql最终选择全表扫描。 mysql \u003e set session optimizer_trace=\"enabled=off\"; --关闭trace ","date":"2023-08-28","objectID":"/posts/mysql-review/:8:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r深入优化 - Order by 与 Group By 优化 explain select * from employees where name = 'LiLei' order by age; [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"employees\", \"type\": \"ref\", \"possible_keys\": \"idx_name_age_position\", \"key\": \"idx_name_age_position\", \"key_len\": \"74\", \"ref\": \"const\", \"rows\": 1, \"Extra\": \"Using index condition; Using where\" } ] Extra 中没有 Using fileSort, 使用name索引字段，紧跟着age排序。 explain select * from employees where name = 'LiLei' order by position; [ { \"id\": 1, \"select_type\": \"SIMPLE\", \"table\": \"employees\", \"type\": \"ref\", \"possible_keys\": \"idx_name_age_position\", \"key\": \"idx_name_age_position\", \"key_len\": \"74\", \"ref\": \"const\", \"rows\": 1, \"Extra\": \"Using index condition; Using where; Using filesort\" } ] Extra 中出现 Using fileSort, 使用name索引字段，position排序，中间断了。 1、MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。 2、order by满足两种情况会使用Using index。 order by语句使用索引最左前列。 使用where子句与order by子句条件列组合满足索引最左前列。 3、尽量在索引列上完成排序，遵循索引建立（索引创建的顺序）时的最左前缀法则。 4、如果order by的条件不在索引列上，就会产生Using filesort。 5、能用覆盖索引尽量用覆盖索引 6、group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最左前缀法则。对于group by的优化如果不需要排序的可以加上order by null禁止排序。注意，where高于having，能写在where中 的限定条件就不要去having限定了。 Using filesort文件排序原理 单路排序： 是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；用trace工具可以看到sort_mode信息里显示\u003c sort_key, additional_fields \u003e或者\u003csort_key,packed_additional_fields \u003e 双路排序（又叫回表排序模式）： 是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行 ID，然后在 sort buffer 中进行排序，排序完后需要再次取回其它需要的字段；用trace工具可以看到sort_mode信息里显示\u003c sort_key, rowid \u003e MySQL 通过比较系统变量 max_length_for_sort_data(默认1024字节) 的大小和需要查询的字段总大小来判断使用哪种排序模式。 1、如果 字段的总长度小于max_length_for_sort_data ，那么使用 单路排序模式； 2、如果 字段的总长度大于max_length_for_sort_data ，那么使用 双路排序模∙式。\r","date":"2023-08-28","objectID":"/posts/mysql-review/:9:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r深入优化 - 分页优化创建实例表： employees CREATE TABLE `employees` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(24) NOT NULL DEFAULT '' COMMENT '姓名', `age` int(11) NOT NULL DEFAULT '0' COMMENT '年龄', `position` varchar(20) NOT NULL DEFAULT '' COMMENT '职位', `hire_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '入职时间', PRIMARY KEY (`id`), KEY `idx_name_age_position` (`name`,`age`,`position`) USING BTREE ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT='员工记录表'; 场景一：主键自增且连续的分页 EXPLAIN select * from employees limit 10000,10; 一般会这么写SQL，Mysql 会先取10010条数据，然后抛弃前面10000条返回剩下的10条，当表数据量越来越大是查询会越来越慢。 优化后： mysql\u003e EXPLAIN select * from employees where id \u003e 90000 limit 5; 此种方式会走索引，且扫描行数大大减少，执行效率很高，但要求苛刻，必须有自增ID且连续，不能断（删数据），一般很难满足，不常用。 场景二：非主键字段排序的分页 EXPLAIN select * from employees ORDER BY name limit 90000,5; 即使 name 字段有索引，MySQL 也不会走索引，原因：走 idx_name_age_position 索引，还要回表，要扫描多棵树，MySQL 认为性能不高，还不如全部扫描呢，所以还用了 filesort 排序。 优化后: EXPLAIN select *from employees e inner join (select id from employees order by name limit 90000,5) ed on e.id = ed.id; 按照ID优先级 Mysql 的执行顺序为 2:1:1（ID越大先执行，ID一样从上到下执行）, 先走idx_name_age_position 覆盖索引，找到所有满足条件的记录ID列表，再拿这个结果去聚簇索引扫描。这里用到了临时表 ,type 虽然为ALL，表示全表扫描，但这个临时表也只有5条记录，所以很快。 优化关键：想办法让条件查询、排序返回的值尽量最少，尽量走索引，再取那这个结果到主键索引中查。 ","date":"2023-08-28","objectID":"/posts/mysql-review/:10:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r深入优化 - 关联查询 Join 优化创建实例表 t1,t2 CREATE TABLE `t1` ( `id` int(11) NOT NULL AUTO_INCREMENT, `a` int(11) DEFAULT NULL, `b` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_a` (`a`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 创建表t2，和t1一样 create table t2 like t1; 然后：t1 表插入1w条记录，t2表插入100条记录； t1 大表，t2小表；同时两个表 a 字段都都有索引。 Join 查询有两种算法 Nested-Loop Join 算法（嵌套循环连接） Block Nested-Loop Join 算法（基于块的嵌套循环连接） 第一种：嵌套循环连接 Nested-Loop Join(NLJ) 算法 EXPLAIN select * from t1 inner join t2 on t1.a = t2.a; 执行计划原理图 执行步骤 从t2表中读取一条记录。 从第一步的数据中取出关联字段a，到t1中查找。 取出t1中满足的行和t2中获取的结果集合并。 重复以上3步，直达t2中的记录取完，终止返回。 执行过程分析 t1 表全表扫描，扫描100行，t2表根据索引a扫描二级索引，一次可以扫描t1的一整行完整数据，扫描了100行，因此总共扫描了200行。这种方式称为NLJ算法扫描，特征就是 Extra 中没有 Using join buffer 内容。 那么如果 a 字段没有索引呢，那就走下面的 BNL算法。 第二种：基于块的嵌套循环连接 Block Nested-Loop Join(BNL)算法 EXPLAIN select * from t1 inner join t2 on t1.b = t2.b; 明显 Extra 中有Using join buffer。。。说明就是BNL算法，因为关联字段 b 上没索引。 BNL 执行计划 执行步骤 把 t2 的所有数据放入到 join_buffer 中。 把表 t1 中每一行取出来，跟 join_buffer 中的数据做对比。 返回满足 join 条件的数据。 执行过程分析 join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t2 的所有数据话，策略很简单，就是分段放。整个过程对表 t1 和 t2 都做了一次全表扫描，因此扫描的总行数为10000(表 t1 的数据总量) + 100(表 t2 的数据总量) =10100。并且 join_buffer 里的数据是无序的，因此对表 t1 中的每一行，都要做 100 次判断，所以内存中的判断次数是100 * 10000= 100 万次。 关联SQL的优化原则 关联字段加索引，让mysql做join操作时尽量选择NLJ算法。 小表驱动大表，写多表连接sql时如果明确知道哪张表是小表可以用straight_join写法固定连接驱动方式，省去mysql优化器自己判断的时间。 ","date":"2023-08-28","objectID":"/posts/mysql-review/:11:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r深入优化 - COUNT(*) 优化实例SQL EXPLAIN select count(1) from employees; EXPLAIN select count(id) from employees; EXPLAIN select count(name) from employees; EXPLAIN select count(*) from employees; 执行效率结论 字段有索引：count(*)≈count(1)\u003ecount(字段)\u003ecount(主键 id) 字段无索引：count(*)≈count(1)\u003ecount(主键 id)\u003ecount(字段) 执行计划分析 count(字段)：如果字段有索引，走二级索引，每扫描一行取出字段的值，统计字段的个数,NULL值不算。 count(1)：如果有二级索引，扫描二级索引，累加字段用常量1代替，不需要取出字段的值。 count(*)：如果有二级索引，走二级索引，不需要取出字段的值，扫描到行就会统计加1。 count(id)：如果有二级索引，走二级索引,没有才会走主键索引，因为二级索引数据少，扫描快一些。 优化方案 单独维护总行数。myisam 存储引擎的表，行数会维护在磁盘上，count时会直接返回，不再扫描。 show table status like ‘表名’， 可得到表的预估行数。 将行数维护在 redis 里，但一致性很难保证。 将行数维护在本地库，插入和删除和更新行数放在一个事务里，可保证一致性。 注意：count(字段)不会计算null值的行。 ","date":"2023-08-28","objectID":"/posts/mysql-review/:12:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r深入优化 - 如何选择数据类型 选择数据类型的原则 确定合适的大类型：数字、字符串、时间、二进制； 确定具体的类型：有无符号、取值范围、变长定长等。 注意事项 int(11) 和 int(5)：数字代表显示宽度，没有实际意义。如果类型后面增加 ZEROFILL，则宽度不足时前面会用0补齐。 char(5)：存储固定长度字符串，5代表字符长度，如果不够5个前面会用空格代替，占用存储空间是固定的。char最多255字节。 varchar(20)：20代表最多存储字符的长度。varchar 最长 65535 个字节。 ","date":"2023-08-28","objectID":"/posts/mysql-review/:13:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r索引优化建议及设计原则","date":"2023-08-28","objectID":"/posts/mysql-review/:14:0","tags":["mysql"],"title":"MySQL 优化及索引设计规范","uri":"/posts/mysql-review/"},{"categories":["db"],"content":"\r删除数据并释放空间命令 立刻释放磁盘空间 ，不管是 Innodb和MyISAM drop table table_name 立刻释放磁盘空间 ，不管是 Innodb和MyISAM truncate table table_name 删除表的全部数据，对于MyISAM 会立刻释放磁盘空间 ，而InnoDB 不会释放磁盘空间 delete from table_name 带条件的删除, 不管是innodb还是MyISAM都不会释放磁盘空间；delete操作后使用optimize table table_name 释放磁盘空间，优化表期间会锁定表，所以要在空闲时段执行optimize table delete from table_name where xx ","date":"2023-07-10","objectID":"/posts/mysql_information_schema/:1:0","tags":["mysql"],"title":"MYSQL 表空间分析","uri":"/posts/mysql_information_schema/"},{"categories":["db"],"content":"\r查看表空间占用大小MySQL 表空间信息保存在哪 information_schema.TABLES 中。 查看所有数据库的容量和大小 select table_schema as '数据库', sum(table_rows) as '记录数', sum(truncate(data_length/1024/1024, 2)) as '数据容量(MB)', sum(truncate(index_length/1024/1024, 2)) as '索引容量(MB)', sum(truncate(data_free/1024/1024, 2)) as '碎片空间容量(MB)' from information_schema.tables group by table_schema order by sum(data_length) desc, sum(index_length) desc 查看指定数据库各个表容量大小 select table_schema as '数据库', table_name as '表名', table_rows as '记录数', truncate(data_length/1024/1024, 2) as '数据容量(MB)', truncate(index_length/1024/1024, 2) as '索引容量(MB)', sum(truncate(data_free/1024/1024, 2)) as '碎片空间容量(MB)' from information_schema.tables where table_schema='mysql' -- 数据库名称 order by data_length desc, index_length desc; 查询所有数据库占用磁盘空间大小 select TABLE_SCHEMA, concat(truncate(sum(data_length)/1024/1024,2),' MB') as data_size, concat(truncate(sum(index_length)/1024/1024,2),' MB') as index_size, concat(truncate(sum(data_free)/1024/1024,2),' MB') as data_free_size from information_schema.tables group by TABLE_SCHEMA ORDER BY data_size desc; 查询单个库中所有表磁盘空间大小 select TABLE_NAME, concat(truncate(data_length/1024/1024,2),' MB') as data_size, concat(truncate(index_length/1024/1024,2),' MB') as index_size, concat(truncate(sum(data_free)/1024/1024,2),' MB') as data_free_size from information_schema.tables where TABLE_SCHEMA = '查询的表名' group by TABLE_NAME order by data_length desc; truncate 是MYSQL的系统函数，作用是按照小数点截取，但不进行四舍五入， TRUNCATE(X,D) ，其中X是数值，D是保留小数的位数。 如： TRUNCATE(123.4567, 3); 结果是 123.456，TRUNCATE(123.4567, 2); 结果是 123.45 information_schema.TABLES 表常用字段及说明 字段 含义 Table_catalog 数据表登记目录 Table_schema 数据表所属的数据库名 Table_name 表名称 Table_type 表类型[system view|base table] Engine 使用的数据库引擎[MyISAM|CSV|InnoDB] Version 版本，默认值10 Row_format 行格式[Compact|Dynamic|Fixed] Table_rows 表里所存多少行数据 Avg_row_length 平均行长度 Data_length 数据长度 Max_data_length 最大数据长度 Index_length 索引长度 Data_free 空间碎片 Auto_increment 做自增主键的自动增量当前值 Create_time 表的创建时间 Update_time 表的更新时间 Check_time 表的检查时间 Table_collation 表的字符校验编码集 Checksum 校验和 Create_options 创建选项 Table_comment 表的注释、备注 ","date":"2023-07-10","objectID":"/posts/mysql_information_schema/:2:0","tags":["mysql"],"title":"MYSQL 表空间分析","uri":"/posts/mysql_information_schema/"},{"categories":["db"],"content":"\r参考 MYSQL 删除数据后释放空间：https://www.jianshu.com/p/ebe6ac68099a MySQL 查看数据库表容量大小和磁盘空间占用大小： https://my.oschina.net/90design/blog/4330825 mysql中information_schema.tables字段说明：https://blog.csdn.net/weixin_40918067/article/details/116868906 MySQL的TRUNCATE()函数： https://blog.csdn.net/Fekerkk/article/details/122536574 ","date":"2023-07-10","objectID":"/posts/mysql_information_schema/:3:0","tags":["mysql"],"title":"MYSQL 表空间分析","uri":"/posts/mysql_information_schema/"},{"categories":["中间件"],"content":" Otter架构 ","date":"2023-06-28","objectID":"/posts/otter1/:0:0","tags":["otter"],"title":"Otter数据同步 - 环境搭建","uri":"/posts/otter1/"},{"categories":["中间件"],"content":"\rotter 官网介绍名称：otter [‘ɒtə(r)] 译意： 水獭，数据搬运工 语言： 纯java开发 定位： 基于数据库增量日志解析，准实时同步到本机房或异地机房的mysql/oracle数据库. 一个分布式数据库同步系统。 更多介绍查看Github：https://github.com/alibaba/otter ","date":"2023-06-28","objectID":"/posts/otter1/:1:0","tags":["otter"],"title":"Otter数据同步 - 环境搭建","uri":"/posts/otter1/"},{"categories":["中间件"],"content":"\r架构及工作原理 Canal, 负责监听Bin-log，类似MYSQL的从库，本质上实现了MYSQL的协议，伪装成从库读取bin-log日志。 Manager 管理Otter的配置的后台, 比如管理数据库表之间的映射关系，会把配置推送到 Node。 Node 实现同步功能的核心服务，同时把同步结果实时反馈给Manager。 Zookeepr, 分布式调度，监控节点状态，这个不用解释，分布式系统都会用到。 otter 需要以上四个服务才能工作，搭建比较麻烦，稍后详细说明。 ","date":"2023-06-28","objectID":"/posts/otter1/:2:0","tags":["otter"],"title":"Otter数据同步 - 环境搭建","uri":"/posts/otter1/"},{"categories":["中间件"],"content":"\r本次目标假设要把tb_user表的数据同步到tb_user2, 用otter该如何实现？tb_user 表结构如下。 create table tb_user ( id int(11) unsigned auto_increment comment 'ID' primary key, username varchar(100) default '' not null comment '用户名', age int default 0 not null comment '年龄', email varchar(64) default '' not null comment '邮箱', created_time datetime default CURRENT_TIMESTAMP not null comment '创建时间', modified_time datetime default CURRENT_TIMESTAMP not null on update CURRENT_TIMESTAMP comment '更新时间', is_deleted tinyint(2) default 0 not null comment '是否删除' ) comment '用户信息表' charset = utf8mb4; tb_user2 表结构和tb_user相同。 create table tb_user2 like tb_user; 接下来搭建同步所需的各个服务。 ","date":"2023-06-28","objectID":"/posts/otter1/:3:0","tags":["otter"],"title":"Otter数据同步 - 环境搭建","uri":"/posts/otter1/"},{"categories":["中间件"],"content":"\r安装 zookeeper打开ZK官网，下载最新的包，地址：https://zookeeper.apache.org/releases.html#download 执行下面命令解压文件 tar -zxvf apache-zookeeper-3.8.1-bin.tar.gz 解压后得到如下目录 进入到conf配置目录修改配置文件，拷贝 zoo_sample.cfg 文件重名名为 zoo.cfg cd conf cp zoo_sample.cfg zoo.cfg zoo.cfg vi 修改配置 vi zoo.cfg 主要看下面两个配置，zk 的默认端口是 2181，如果没有被占用，可以不改。 # example sakes. dataDir=/tmp/zookeeper # zk数据存储目录 # the port at which the clients will connect clientPort=2181 # 端口默认2181 # the maximum number of client connections. # increase this if you need to handle more clients #maxClientCnxns=60 启动zk sh bin/zkServer.sh 连接zk bin/zkCli.sh 看到如下所示说明zk安装成功。 ","date":"2023-06-28","objectID":"/posts/otter1/:4:0","tags":["otter"],"title":"Otter数据同步 - 环境搭建","uri":"/posts/otter1/"},{"categories":["中间件"],"content":"\r安装 Canal下载最新文档的 Canal,下载地址：https://github.com/alibaba/canal/releases 解压文件 tar -zxvf canal.deployer-1.1.6.tar.gz 得到如下目录 修改配置,参考官网文档：https://github.com/alibaba/canal/wiki/QuickStart 对于自建 MySQL , 需要先开启 Binlog 写入功能，配置 binlog-format 为 ROW 模式，my.cnf 中配置如下 [mysqld] log-bin=mysql-bin # 开启 binlog binlog-format=ROW # 选择 ROW 模式 server_id=1 # 配置 MySQL replaction 需要定义，不要和 canal 的 slaveId 重复 注意：针对阿里云 RDS for MySQL , 默认打开了 binlog , 并且账号默认具有 binlog dump 权限 , 不需要任何权限或者 binlog 设置,可以直接跳过这一步 授权 canal 链接 MySQL 账号具有作为 MySQL slave 的权限, 如果已有账户可直接 grantCREATE USER canal IDENTIFIED BY ‘canal’; GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON . TO ‘canal’@’%’; – GRANT ALL PRIVILEGES ON . TO ‘canal’@’%’ ; FLUSH PRIVILEGES; vi conf/example/instance.properties ## mysql serverId canal.instance.mysql.slaveId = 1234 #position info，需要改成自己的数据库信息 canal.instance.master.address = 127.0.0.1:3306 canal.instance.master.journal.name = canal.instance.master.position = canal.instance.master.timestamp = #canal.instance.standby.address = #canal.instance.standby.journal.name = #canal.instance.standby.position = #canal.instance.standby.timestamp = #username/password，需要改成自己的数据库信息 canal.instance.dbUsername = canal canal.instance.dbPassword = canal canal.instance.defaultDatabaseName = canal.instance.connectionCharset = UTF-8 #table regex canal.instance.filter.regex = .\\*\\\\\\\\..\\* 启动 sh bin/startup.sh 查看日志 vi logs/canal/canal.log\u003c/pre\u003e 2013-02-05 22:45:27.967 [main] INFO com.alibaba.otter.canal.deployer.CanalLauncher - ## start the canal server. 2013-02-05 22:45:28.113 [main] INFO com.alibaba.otter.canal.deployer.CanalController - ## start the canal server[10.1.29.120:11111] 2013-02-05 22:45:28.210 [main] INFO com.alibaba.otter.canal.deployer.CanalLauncher - ## the canal server is running now ...... ","date":"2023-06-28","objectID":"/posts/otter1/:5:0","tags":["otter"],"title":"Otter数据同步 - 环境搭建","uri":"/posts/otter1/"},{"categories":["中间件"],"content":"\r安装 Manager 先下载安装包，下载地址：https://github.com/alibaba/otter/releases 解压 tar -zxvf manager.deployer-4.2.18.tar.gz 得到下面目录 manager 需要数据库，下载官方SQL脚本，并导入进行数据库表创建和数据初始化 wget https://raw.github.com/alibaba/otter/master/manager/deployer/src/main/resources/sql/otter-manager-schema.sql source otter-manager-schema.sql 修改配置，编辑conf目录下的otter.properties 配置文件，修改如下所示 ## otter manager domain name #修改为正确访问ip，生成URL使用 otter.domainName = 127.0.0.1 ## otter manager http port otter.port = 8080 ## jetty web config xml otter.jetty = jetty.xml ## otter manager database config ，修改为正确数据库信息 otter.database.driver.class.name = com.mysql.jdbc.Driver otter.database.driver.url = jdbc:mysql://127.0.01:3306/ottermanager otter.database.driver.username = root otter.database.driver.password = hello ## otter communication port otter.communication.manager.port = 1099 ## otter communication pool size otter.communication.pool.size = 10 ## default zookeeper address，修改为正确的地址，手动选择一个地域就近的zookeeper集群列表 otter.zookeeper.cluster.default = 127.0.0.1:2181 ## default zookeeper session timeout = 90s otter.zookeeper.sessionTimeout = 90000 ## otter arbitrate connect manager config otter.manager.address = ${otter.domainName}:${otter.communication.manager.port} 启动 sh startup.sh 查看日志 2013-08-14 13:19:45.911 [] WARN com.alibaba.otter.manager.deployer.JettyEmbedServer - ##Jetty Embed Server is startup! 2013-08-14 13:19:45.911 [] WARN com.alibaba.otter.manager.deployer.OtterManagerLauncher - ## the manager server is running now ...... 验证 访问： http://127.0.0.1:8080/，出现otter的页面，即代表启动成功 输入账号密码，默认amdin/admin 注意，因为我的8080端口被占用，这里我改成8082，你可以根据你的情况修改端口，我截图中有两个Channel,这是我测试创建的，刚安装完是什么空的，什么都没有。 一切 OK ！ 把前面安装的ZK服务添加到manger,后面安装Node等需要用到ZK。 点击manager界面的机器管理\u003ezookeeper管理。 然后添加,输入ZK集群的信息，集群名称随意，集群地址填ZK的IP和端口，中间用冒号分隔，形如“ip:端口”的新式，多个分号隔开。 点击保存，OK。 ","date":"2023-06-28","objectID":"/posts/otter1/:6:0","tags":["otter"],"title":"Otter数据同步 - 环境搭建","uri":"/posts/otter1/"},{"categories":["中间件"],"content":"\r安装 Node下载官方安装包，地址：https://github.com/alibaba/otter/releases 和上面的manager同一个地址，下载如下文件。 解压缩，得到如下目录 这时需要回到manger添加一个Node, 得到Node的序号，因为启动Node服务时需要这个序号。 在manger界面选择机器管理\u003eNode管理 在Node管理页面点击添加，输入机器名称、IP和端口，以及选择一个ZK集群，这个几个选项是必填的，机器名称随意，机器IP输入要启动Node服务的IP，端口就是Node服务的端口，默认2088。 保存后得到下面结果，这里有个关键信息有两个，一个是状态，刚添加完为启动Node是状态是未启动，还有一个是序号，序号是点击保存是系统生成的，在后面配置文件中会用到，我这里是1 修改Node的配置 首先在conf目录下创建一个nid的文件，值为前面生成的序号，如下所示 (将环境准备中添加机器后获取到的序号，保存到conf目录下的nid文件，比如我添加的机器对应序号为1) echo 1 \u003e conf/nid 然后修改 otter.properties配置 # otter node root dir otter.nodeHome = ${user.dir}/../node ## otter node dir otter.htdocs.dir = ${otter.nodeHome}/htdocs otter.download.dir = ${otter.nodeHome}/download otter.extend.dir= ${otter.nodeHome}/extend ## default zookeeper sesstion timeout = 90s otter.zookeeper.sessionTimeout = 90000 ## otter communication pool size otter.communication.pool.size = 10 ## otter arbitrate \u0026amp; node connect manager config ， 修改为正确的manager服务地址 otter.manager.address = 127.0.0.1:1099 启动 sh startup.sh 查看日志 vi logs/node/node.log 2013-08-14 15:42:16.886 [main] INFO com.alibaba.otter.node.deployer.OtterLauncher - INFO ## the otter server is running now ...... 验证 再次访问manger 页面， http://127.0.0.1:8080/node_list.htm，查看对应的节点状态，如果变为了已启动，代表已经正常启动。(ps，如果是未启动，会是一个红色高亮) 现在 otter 所需要的各个服务已准备好，接下来配置数据同步。 ","date":"2023-06-28","objectID":"/posts/otter1/:7:0","tags":["otter"],"title":"Otter数据同步 - 环境搭建","uri":"/posts/otter1/"},{"categories":["db","中间件"],"content":" Redis分布式架构 ","date":"2023-06-28","objectID":"/posts/redis/:0:0","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 是什么Redis 是一个高性能的基于内存实现的K-V存储数据库 。 ","date":"2023-06-28","objectID":"/posts/redis/:1:0","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 的优点 性能极高，Redis能读的速度是110000次/s,写的速度是81000次/s 。 支持持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 多种数据类型，同时还提供list，set，zset，hash等数据结构的存储。 支持主从复制，自动同步，可实现读写分离。 丰富的特性，支持pub/sub，key过期策略，事务，支持多个DB等。 ","date":"2023-06-28","objectID":"/posts/redis/:2:0","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 的缺点 基于内存存储，单机容量有限。 重启会加载磁盘缓存到内存，这期间不能提供服务。 主从复制采用全量复制，这个过程会占用更多内存和网络资源。 ","date":"2023-06-28","objectID":"/posts/redis/:3:0","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 应用场景 缓存数据，常见应用。 计数器，单线程可避免并发，保证不出错，性能毫秒级。 队列，可作为简单消息队列使用。 分布式锁与单线程机制 位操作，如统计在线列表 最新列表，获取最新10条新闻数据 排行榜，消费排行榜 ","date":"2023-06-28","objectID":"/posts/redis/:4:0","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 基础","date":"2023-06-28","objectID":"/posts/redis/:5:0","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 下载安装安装从源码安装 # download wget https://download.redis.io/releases/redis-6.2.5.tar.gz tar xzf redis-6.2.5.tar.gz cd redis-6.2.5 make # run redis-server src/redis-server # test src/redis-cli redis\u003e set foo bar OK redis\u003e get foo \"bar\" Ubuntu 安装 sudo add-apt-repository ppa:redislabs/redis sudo apt-get update sudo apt-get install redis Mac 安装 brew install redis ","date":"2023-06-28","objectID":"/posts/redis/:5:1","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rJedis 链接Redis先引入jar包 \u003cdependency\u003e \u003cgroupId\u003eredis.clients\u003c/groupId\u003e \u003cartifactId\u003ejedis\u003c/artifactId\u003e \u003cversion\u003e2.9.0\u003c/version\u003e \u003c/dependency\u003e JAVA 代码调用实例 public class JedisSingleTest { public static void main(String[] args) throws IOException { JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxTotal(20); jedisPoolConfig.setMaxIdle(10); jedisPoolConfig.setMinIdle(5); // timeout，这里既是连接超时又是读写超时，从Jedis 2.8开始有区分connectionTimeout和soTimeout的构造函数 JedisPool jedisPool = new JedisPool(jedisPoolConfig, \"192.168.0.60\", 6379, 3000, null); Jedis jedis = null; try { //从redis连接池里拿出一个连接执行命令 jedis = jedisPool.getResource(); System.out.println(jedis.set(\"single\", \"zhuge\")); System.out.println(jedis.get(\"single\")); } catch (Exception e) { e.printStackTrace(); } finally { //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。 if (jedis != null) jedis.close(); } } } ","date":"2023-06-28","objectID":"/posts/redis/:5:2","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 管道（Pipeline）使用管道可以一次发送多个命令给Redis服务，减少网络开销，如果前面的命令执行失败，后面的命令会继续执行，不会被影响，最后把所有命令的执行结果一次返回。 Pipeline pl = jedis.pipelined(); for (int i = 0; i \u003c 10; i++) { pl.incr(\"pipelineKey\"); pl.set(\"zhuge\" + i, \"zhuge\"); //模拟管道报错 // pl.setbit(\"zhuge\", -1, true); } List\u003cObject\u003e results = pl.syncAndReturnAll(); System.out.println(results); ","date":"2023-06-28","objectID":"/posts/redis/:5:3","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis Lua 脚本使用LUA 脚本可以代替Redis的事务执行，要么所有命令都执行成功，要么都失败，是原子性的，也可以减少网络开销。 在Redis控制台执行： 127.0.0.1:6379\u003e eval \"return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}\" 2 key1 key2 first second 1) \"key1\" 2) \"key2\" 3) \"first\" 4) \"second\" 在代码中使用： 模拟减库存操作，如果后面执行失败，减掉的库存会回滚。 jedis.set(\"product_stock_10016\", \"15\"); //初始化商品10016的库存 String script = \" local count = redis.call('get', KEYS[1]) \" + \" local a = tonumber(count) \" + \" local b = tonumber(ARGV[1]) \" + \" if a \u003e= b then \" + \" redis.call('set', KEYS[1], a-b) \" + \" return 1 \" + \" end \" + \" return 0 \"; Object obj = jedis.eval(script, Arrays.asList(\"product_stock_10016\"), Arrays.asList(\"10\")); System.out.println(obj); ","date":"2023-06-28","objectID":"/posts/redis/:5:4","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis Key 淘汰策略Redis缓存达到最大内存限制时会执行淘汰策略，如下命令设置最大内存。 maxmemory 100mb 如下配置key淘汰策略，默认noeviction（拒绝请求）。 maxmemory-policy noeviction 全部配置参数： noeviction 达到内存限制时返回错误，直接拒绝，del命令除外，是Redis的默认策略。 allkeys-lru 尝试删除最近最少使用的，也就是优先驱逐最长时间没使用的。 volatile-lru 尝试删除最近最少的使用的，但仅限设置了过期时间的key。 allkeys-random 随机驱逐key。 volatile-random 随机驱逐key, 但仅限设置了过期时间的key。 volatile-ttl 驱逐设置了过期时间的key, 优先驱逐生存期较短的。 allkeys-lfu 优先驱逐最近最不常使用的，也就是优先驱逐一定时间内使用次数最少的，4.1 新增的。 volatile-lfu 优先驱逐最近最不常使用的，但仅限设置了过期时间的key，4.1 新增的。 ","date":"2023-06-28","objectID":"/posts/redis/:5:5","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 批量插入海量数据假如用一条条执行 SET的方式插入百万级的数据量，虽然每条命令执行很快，但是网络来来回回折腾带来的开销也不容小觑，为了执行海量数据批量导入，可以结合redis管道完成。 首先将要导入的数据以命令的方式写入到文件中，如下： /tmp/big-data.txt SET name zhangsan SET name1 lisi SET name2 wangwu SET name3 zhaoliu 然后执行以下命令导入 cat big-data.txt | redis-cli --pipe 执行结果 All data transferred. Waiting for the last reply... Last reply received from server. errors: 0, replies: 1000000 ","date":"2023-06-28","objectID":"/posts/redis/:5:6","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 遍历所有元素 keys * 遍历 keys * 会一次返回匹配到的所有key, 当数据量大时要慎用，避免阻塞redis。 实例1：查询所有的key 127.0.0.1:6379\u003e keys * 1) \"name3\" 2) \"name1\" 3) \"name2\" 4) \"name\" 实例2：查询所有前缀为name的key 127.0.0.1:6379\u003e keys name* 1) \"name3\" 2) \"name1\" 3) \"name2\" 4) \"name\" scan 渐进式遍历 scan 遍历可以做到分页遍历，数据量大是比较合适，每次请求会返回下次一的游标，直达游标为0结束，但是在遍历过程中如果有key新增或删除可能出现新重复数据等情况，使用时要注意。 命令格式 SCAN cursor [MATCH pattern] [COUNT count] 实例：扫描key前缀为name的元素，每次返回2条。 127.0.0.1:6379\u003e scan 0 match name* count 2 1) \"1\" 2) 1) \"name3\" 2) \"name2\" 3) \"name\" 127.0.0.1:6379\u003e scan 1 match name* count 2 1) \"0\" 2) 1) \"name1\" 127.0.0.1:6379\u003e 当返回的 cursor 为0时结束。 ","date":"2023-06-28","objectID":"/posts/redis/:5:7","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 持久化方案","date":"2023-06-28","objectID":"/posts/redis/:6:0","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r持久化之rdb 模式根据配置规则redis 会以生生二进制文件dump.rdb的方式持久化数据到磁盘，每次持久化会生成一个新的文件覆盖旧的文件，默认是开启的，配置方法如下所示。 开启rdb模式 save 900 1 save 300 10 save 60 10000 # 60s内有10000个key被改动则触发rdb持久化 关闭RDB只需要将所有的save保存策略注释掉即可。 还可以手动执行命令生成RDB快照，进入redis客户端执行命令save或bgsave可以生成dump.rdb文件， 每次命令执行都会将所有redis内存快照到一个新的rdb文件里，并覆盖原有rdb快照文件。save 会同步执行，阻塞客户端的操作，bgsave会fork一个子进程处理异步处理。 ","date":"2023-06-28","objectID":"/posts/redis/:6:1","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r持久化之aof模式aof 是以记类似日志的方式持久化，默认是关闭的，需要执行以下命令开启。 开启aof模式 appendonly yes aof 策略配置 appendfsync always # 每次有新命令追加到 AOF 文件时就执行一次 fsync ，非常慢，也非常安全。 appendfsync everysec # 每秒 fsync 一次，足够快，并且在故障时只会丢失 1 秒钟的数据。 appendfsync no # 从不 fsync ，将数据交给操作系统来处理。更快，也更不安全的选择。 aof 重写 多次修改同一个key的值后，经过aof重写会只保留最后一次修改的命令，这样可以保持aof文件只保留有效的命且减少占用存储空间，默认自动开启。 auto-aof-rewrite-percentage 100 # aof文件自上一次重写后文件大小增长了100%则再次触发重写 auto-aof-rewrite-min-size 64mb # aof文件至少要达到64M才会自动重写，文件太小恢复速度本来就 很快，重写的意义不大 ","date":"2023-06-28","objectID":"/posts/redis/:6:2","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 主从模式 ","date":"2023-06-28","objectID":"/posts/redis/:7:0","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r主从模式配置 1、复制一份redis.conf文件 2、将相关配置修改为如下值： port 6380 pidfile /var/run/redis_6380.pid # 把pid进程号写入pidfile配置的文件 logfile \"6380.log\" dir /usr/local/redis-5.0.3/data/6380 # 指定数据存放目录 # 需要注释掉bind # bind 127.0.0.1（bind绑定的是自己机器网卡的ip，如果有多块网卡可以配多个ip，代表允许客户端通过机器的哪些网卡ip去访问，内网一般可以不配置bind，注释掉即可） 3、配置主从复制 replicaof 192.168.0.60 6379 # 从本机6379的redis实例复制数据，Redis 5.0之前使用slaveof replica-read-only yes # 配置从节点只读 4、启动从节点 redis-server redis.conf 5、连接从节点 redis-cli -p 6380 6、测试在6379实例上写数据，6380实例是否能及时同步新修改数据 7、可以自己再配置一个6381的从节点 ","date":"2023-06-28","objectID":"/posts/redis/:7:1","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r主从工作原理如果你为master配置了一个slave，不管这个slave是否是第一次连接上Master，它都会发送一个PSYNC命令给master请求复制数据。 master收到PSYNC命令后，会在后台进行数据持久化通过bgsave生成最新的rdb快照文件，持久化期间，master会继续接收客户端的请求，它会把这些可能修改数据集的请求缓存在内存中。当持久化进行完毕以后，master会把这份rdb文件数据集发送给slave，slave会把接收到的数据进行持久化生成rdb，然后再加载到内存中。然后，master再将之前缓存在内存中的命令发送给slave。 当master与slave之间的连接由于某些原因而断开时，slave能够自动重连Master，如果master收到了多个slave并发连接请求，它只会进行一次持久化，而不是一个连接一次，然后再把这一份持久化的数据发送给多个并发连接的slave。 ","date":"2023-06-28","objectID":"/posts/redis/:7:2","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r主从模式的缺点无法实现自动故障转移，主节点挂了从节点需要手动顶上去。 ","date":"2023-06-28","objectID":"/posts/redis/:7:3","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 哨兵模式sentinel哨兵是特殊的redis服务，不提供读写服务，主要用来监控redis实例节点。 哨兵架构下client端第一次从哨兵找出redis的主节点，后续就直接访问redis的主节点，不会每次都通过 sentinel代理访问redis的主节点，当redis的主节点发生变化，哨兵会第一时间感知到，并且将新的redis 主节点通知给client端(这里面redis的client端一般都实现了订阅功能，订阅sentinel发布的节点变动消息) ","date":"2023-06-28","objectID":"/posts/redis/:8:0","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rredis 哨兵架构搭建步骤 1、复制一份sentinel.conf文件 cp sentinel.conf sentinel-26379.conf 2、将相关配置修改为如下值： port 26379 daemonize yes pidfile \"/var/run/redis-sentinel-26379.pid\" logfile \"26379.log\" dir \"/usr/local/redis-5.0.3/data\" # sentinel monitor \u003cmaster-redis-name\u003e \u003cmaster-redis-ip\u003e \u003cmaster-redis-port\u003e \u003cquorum\u003e # quorum是一个数字，指明当有多少个sentinel认为一个master失效时(值一般为：sentinel总数/2 + 1)，master才算真正失效 sentinel monitor mymaster 192.168.0.60 6379 2 # mymaster这个名字随便取，客户端访问时会用到 3、启动sentinel哨兵实例 src/redis-sentinel sentinel-26379.conf 4、查看sentinel的info信息 src/redis-cli -p 26379 127.0.0.1:26379\u003einfo 可以看到Sentinel的info里已经识别出了redis的主从 5、可以自己再配置两个sentinel，端口26380和26381，注意上述配置文件里的对应数字都要修改 ","date":"2023-06-28","objectID":"/posts/redis/:8:1","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rjedis 连接哨兵 public class JedisSentinelTest { public static void main(String[] args) throws IOException { JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(20); config.setMaxIdle(10); config.setMinIdle(5); String masterName = \"mymaster\"; Set\u003cString\u003e sentinels = new HashSet\u003cString\u003e(); sentinels.add(new HostAndPort(\"192.168.0.60\",26379).toString()); sentinels.add(new HostAndPort(\"192.168.0.60\",26380).toString()); sentinels.add(new HostAndPort(\"192.168.0.60\",26381).toString()); //JedisSentinelPool其实本质跟JedisPool类似，都是与redis主节点建立的连接池 //JedisSentinelPool并不是说与sentinel建立的连接池，而是通过sentinel发现redis主节点并与其建立连接 JedisSentinelPool jedisSentinelPool = new JedisSentinelPool(masterName, sentinels, config, 3000, null); Jedis jedis = null; try { jedis = jedisSentinelPool.getResource(); System.out.println(jedis.set(\"sentinel\", \"zhuge\")); System.out.println(jedis.get(\"sentinel\")); } catch (Exception e) { e.printStackTrace(); } finally { //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。 if (jedis != null) jedis.close(); } } } ","date":"2023-06-28","objectID":"/posts/redis/:8:2","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rspring-boot 连接哨兵引入依赖的jar包 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-data-redis\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.commons\u003c/groupId\u003e \u003cartifactId\u003ecommons-pool2\u003c/artifactId\u003e \u003c/dependency\u003e 配置连接信息 server: port: 8080 spring: redis: database: 0 timeout: 3000 sentinel: #哨兵模式 master: mymaster #主服务器所在集群名称 nodes: 192.168.0.60:26379,192.168.0.60:26380,192.168.0.60:26381 lettuce: pool: max-idle: 50 min-idle: 10 max-active: 100 max-wait: 1000 使用代码 @RestController public class IndexController { private static final Logger logger = LoggerFactory.getLogger(IndexController.class); @Autowired private StringRedisTemplate stringRedisTemplate; /** * 测试节点挂了哨兵重新选举新的master节点，客户端是否能动态感知到 * 新的master选举出来后，哨兵会把消息发布出去，客户端实际上是实现了一个消息监听机制， * 当哨兵把新master的消息发布出去，客户端会立马感知到新master的信息，从而动态切换访问的masterip * * @throws InterruptedException */ @RequestMapping(\"/test_sentinel\") public void testSentinel() throws InterruptedException { int i = 1; while (true){ try { stringRedisTemplate.opsForValue().set(\"zhuge\"+i, i+\"\"); System.out.println(\"设置key：\"+ \"zhuge\" + i); i++; Thread.sleep(1000); }catch (Exception e){ logger.error(\"错误：\", e); } } } } ","date":"2023-06-28","objectID":"/posts/redis/:8:3","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r哨兵模式的缺点虽然实现了自动故障转移，主节点挂了从节点会自动顶上去，但集群中只能有一个主节点提供服务，无法适应大量的数据存储，一个节点的内存毕竟的有限的，下面的集模式可以改进次问题，Redis集群模式可以实现数据分片，把不同的数据存储在不同的节点上，理论上可以做到无限大内存。 ","date":"2023-06-28","objectID":"/posts/redis/:8:4","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 集群模式Redis 集群至少需要3个主节点，一般需要给每个主节点配一个从节点。 ","date":"2023-06-28","objectID":"/posts/redis/:9:0","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis集群搭建 第一步：在第一台机器的/usr/local下创建文件夹redis-cluster，然后在其下面分别创建2个文件夾如下 （1）mkdir -p /usr/local/redis-cluster （2）mkdir 8001 8004 第一步：把之前的redis.conf配置文件copy到8001下，修改如下内容： （1）daemonize yes （2）port 8001（分别对每个机器的端口号进行设置） （3）pidfile /var/run/redis_8001.pid # 把pid进程号写入pidfile配置的文件 （4）dir /usr/local/redis-cluster/8001/（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据） （5）cluster-enabled yes（启动集群模式） （6）cluster-config-file nodes-8001.conf（集群节点信息文件，这里800x最好和port对应上） （7）cluster-node-timeout 10000 (8)# bind 127.0.0.1（bind绑定的是自己机器网卡的ip，如果有多块网卡可以配多个ip，代表允许客户端通过机器的哪些网卡ip去访问，内网一般可以不配置bind，注释掉即可） (9)protected-mode no （关闭保护模式） (10)appendonly yes 如果要设置密码需要增加如下配置： (11)requirepass zhuge (设置redis访问密码) (12)masterauth zhuge (设置集群节点间访问密码，跟上面一致) 第三步：把修改后的配置文件，copy到8004，修改第2、3、4、6项里的端口号，可以用批量替换： :%s/源字符串/目的字符串/g 第四步：另外两台机器也需要做上面几步操作，第二台机器用8002和8005，第三台机器用8003和8006 第五步：分别启动6个redis实例，然后检查是否启动成功 （1）/usr/local/redis-5.0.3/src/redis-server /usr/local/redis-cluster/800*/redis.conf （2）ps -ef | grep redis 查看是否启动成功 第六步：用redis-cli创建整个redis集群(redis5以前的版本集群是依靠ruby脚本redis-trib.rb实现) # 下面命令里的1代表为每个创建的主服务器节点创建一个从服务器节点 # 执行这条命令需要确认三台机器之间的redis实例要能相互访问，可以先简单把所有机器防火墙关掉，如果不关闭防火墙则需要打开redis服务端口和集群节点gossip通信端口16379(默认是在redis端口号上加1W) # 关闭防火墙 # systemctl stop firewalld # 临时关闭防火墙 # systemctl disable firewalld # 禁止开机启动 # 注意：下面这条创建集群的命令大家不要直接复制，里面的空格编码可能有问题导致创建集群不成功 （1）/usr/local/redis-5.0.3/src/redis-cli -a zhuge --cluster create --cluster-replicas 1 192.168.0.61:8001 192.168.0.62:8002 192.168.0.63:8003 192.168.0.61:8004 192.168.0.62:8005 192.168.0.63:8006 第七步：验证集群： （1）连接任意一个客户端即可：./redis-cli -c -h -p (-a访问服务端密码，-c表示集群模式，指定ip地址和端口号） 如：/usr/local/redis-5.0.3/src/redis-cli -a zhuge -c -h 192.168.0.61 -p 800* （2）进行验证： cluster info（查看集群信息）、cluster nodes（查看节点列表） （3）进行数据操作验证 （4）关闭集群则需要逐个进行关闭，使用命令： /usr/local/redis-5.0.3/src/redis-cli -a zhuge -c -h 192.168.0.60 -p 800* shutdown ","date":"2023-06-28","objectID":"/posts/redis/:9:1","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rjava 操作Redis集群引入依赖 \u003cdependency\u003e \u003cgroupId\u003eredis.clients\u003c/groupId\u003e \u003cartifactId\u003ejedis\u003c/artifactId\u003e \u003cversion\u003e2.9.0\u003c/version\u003e \u003c/dependency\u003e java 使用实例 public class JedisClusterTest { public static void main(String[] args) throws IOException { JedisPoolConfig config = new JedisPoolConfig(); config.setMaxTotal(20); config.setMaxIdle(10); config.setMinIdle(5); Set\u003cHostAndPort\u003e jedisClusterNode = new HashSet\u003cHostAndPort\u003e(); jedisClusterNode.add(new HostAndPort(\"192.168.0.61\", 8001)); jedisClusterNode.add(new HostAndPort(\"192.168.0.62\", 8002)); jedisClusterNode.add(new HostAndPort(\"192.168.0.63\", 8003)); jedisClusterNode.add(new HostAndPort(\"192.168.0.61\", 8004)); jedisClusterNode.add(new HostAndPort(\"192.168.0.62\", 8005)); jedisClusterNode.add(new HostAndPort(\"192.168.0.63\", 8006)); JedisCluster jedisCluster = null; try { //connectionTimeout：指的是连接一个url的连接等待时间 //soTimeout：指的是连接上一个url，获取response的返回等待时间 jedisCluster = new JedisCluster(jedisClusterNode, 6000, 5000, 10, \"zhuge\", config); System.out.println(jedisCluster.set(\"cluster\", \"zhuge\")); System.out.println(jedisCluster.get(\"cluster\")); } catch (Exception e) { e.printStackTrace(); } finally { if (jedisCluster != null) jedisCluster.close(); } } } ","date":"2023-06-28","objectID":"/posts/redis/:9:2","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rSpring-boot 操作Redis集群引入依赖 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-data-redis\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.commons\u003c/groupId\u003e \u003cartifactId\u003ecommons-pool2\u003c/artifactId\u003e \u003c/dependency\u003e 配置链接信息 server: port: 8080 spring: redis: database: 0 timeout: 3000 password: zhuge cluster: nodes: 192.168.0.61:8001,192.168.0.62:8002,192.168.0.63:8003,192.168.0.61:8004,192.168.0.62:8005,192.168.0.63:8006 lettuce: pool: max-idle: 50 min-idle: 10 max-active: 100 max-wait: 1000 使用代码 @RestController public class IndexController { private static final Logger logger = LoggerFactory.getLogger(IndexController.class); @Autowired private StringRedisTemplate stringRedisTemplate; @RequestMapping(\"/test_cluster\") public void testCluster() throws InterruptedException { stringRedisTemplate.opsForValue().set(\"zhuge\", \"666\"); System.out.println(stringRedisTemplate.opsForValue().get(\"zhuge\")); } } ","date":"2023-06-28","objectID":"/posts/redis/:9:3","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 集群原理分析Redis Cluster 将所有数据划分为 16384 个 slots(槽位)，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中。当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信息并将其缓存在客户端本地。这样当客户端要查找某个 key 时，可以直接定位到目标节点。同时因为槽位的信息可能会存在客户端与服务器不一致的情况，还需要纠正机制来实现槽位信息的校验调整。 槽位定位算法 Cluster 默认会对 key 值使用 crc16 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位。HASH_SLOT = CRC16(key) mod 16384 ","date":"2023-06-28","objectID":"/posts/redis/:9:4","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 核心原理","date":"2023-06-28","objectID":"/posts/redis/:10:0","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r单线程模型Redis之所以快是因为：1、基于内存操作，2-单线程没有上下文切换，3.基于epoll事件分发模型。所有的连接都放在一个队列里，注册到事件分发器上，如果有客户端发送数据，分发器或通知线程处理。 ","date":"2023-06-28","objectID":"/posts/redis/:10:1","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r简单动态字符串SDSRedis 没用使用C自带的字符串，二是自己定义一个，成为sds简单动态字符串。 SDS源码 struct sdshdr { // 记录 buf 数组中已使用字节的数量 // 等于 SDS 所保存字符串的长度 int len; // 记录 buf 数组中未使用字节的数量 int free; // 字节数组，用于保存字符串 char buf[]; } 比起 C 字符串， SDS 具有以下优点 常数复杂度获取字符串长度, O(1)。 杜绝缓冲区溢出，预先扩容，惰性缩容。 减少修改字符串长度时所需的内存重分配次数。 二进制安全。 兼容部分 C 字符串函数。 ","date":"2023-06-28","objectID":"/posts/redis/:10:2","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r链表链表提供了高效的节点重排能力， 以及顺序性的节点访问方式， 并且可以通过增删节点来灵活地调整链表的长度。每个链表节点使用一个 adlist.h/listNode 结构来表示 ，多个 listNode 可以通过 prev 和 next 指针组成双端链表。 链表节点 listNode typedef struct listNode { // 前置节点 struct listNode *prev; // 后置节点 struct listNode *next; // 节点的值 void *value; } listNode; 链表源码 typedef struct list { // 表头节点 listNode *head; // 表尾节点 listNode *tail; // 链表所包含的节点数量 unsigned long len; // 节点值复制函数 void *(*dup)(void *ptr); // 节点值释放函数 void (*free)(void *ptr); // 节点值对比函数 int (*match)(void *ptr, void *key); } list; 用途：链表被广泛用于实现 Redis 的各种功能， 比如列表键， 发布与订阅， 慢查询， 监视器， 等等。 ","date":"2023-06-28","objectID":"/posts/redis/:10:3","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r跳跃表Redis 的有序集合是用跳跃表实现的，跳跃表（skiplist）是一种有序数据结构， 它通过在每个节点中维持多个指向其他节点的指针， 从而达到快速访问节点的目的，跳跃表由 redis.h/zskiplistNode 和 redis.h/zskiplist 两个结构定义。 跳跃表节点 zskiplistNode typedef struct zskiplistNode { // 后退指针 struct zskiplistNode *backward; // 分值 double score; // 成员对象 robj *obj; // 层 struct zskiplistLevel { // 前进指针 struct zskiplistNode *forward; // 跨度 unsigned int span; } level[]; } zskiplistNode; 跳跃表 zskiplist typedef struct zskiplist { // 表头节点和表尾节点 struct zskiplistNode *header, *tail; // 表中节点的数量 unsigned long length; // 表中层数最大的节点的层数 int level; } zskiplist; 图 5-1 展示了一个跳跃表示例， 位于图片最左边的是 zskiplist 结构， 该结构包含以下属性： header ：指向跳跃表的表头节点。 tail ：指向跳跃表的表尾节点。 level ：记录目前跳跃表内，层数最大的那个节点的层数（表头节点的层数不计算在内）。 length ：记录跳跃表的长度，也即是，跳跃表目前包含节点的数量（表头节点不计算在内）。 位于 zskiplist 结构右方的是四个 zskiplistNode 结构， 该结构包含以下属性： 层（level）：节点中用 L1 、 L2 、 L3 等字样标记节点的各个层， L1 代表第一层， L2 代表第二层，以此类推。每个层都带有两个属性：前进指针和跨度。前进指针用于访问位于表尾方向的其他节点，而跨度则记录了前进指针所指向节点和当前节点的距离。在上面的图片中，连线上带有数字的箭头就代表前进指针，而那个数字就是跨度。当程序从表头向表尾进行遍历时，访问会沿着层的前进指针进行。 后退（backward）指针：节点中用 BW 字样标记节点的后退指针，它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。 分值（score）：各个节点中的 1.0 、 2.0 和 3.0 是节点所保存的分值。在跳跃表中，节点按各自所保存的分值从小到大排列。 成员对象（obj）：各个节点中的 o1 、 o2 和 o3 是节点所保存的成员对象。 用途：Redis 的有序集合是用跳跃表实现的。 ","date":"2023-06-28","objectID":"/posts/redis/:10:4","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 常见问题及解决","date":"2023-06-28","objectID":"/posts/redis/:11:0","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r缓存穿透描述：查询了根本不存在的数据，导致请求打倒数据库。产生原因：自身业务代码或数据问题、恶意攻击、爬虫。 解决方案：1.缓存空对象。2.布隆过滤器。功能：布隆过期中不存在的对象一定不存，存在的不一定存在；特点：只能加数据数据，不能删数据。需要预先把所有数据初始化到布隆过滤器；Redis对应的产品：Redison。 ","date":"2023-06-28","objectID":"/posts/redis/:11:1","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r缓存失效(击穿)描述：同一时间大量缓存失效导致请求直达数据库，造成数据库压力过大。 解决方案：在设置过期时间时加上一个随机值。 ","date":"2023-06-28","objectID":"/posts/redis/:11:2","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r缓存雪崩描述：缓存无法支持大量请求宕机，请求全部打到数据库。 解决方案：1.使用缓存高可用架构，如：Redis Sentinel 或 Redis Cluster。2.使用限流熔断并降级，如：Sentinel或Hystrix。3.提前演练，模拟宕机后做出一些应对情况。 ","date":"2023-06-28","objectID":"/posts/redis/:11:3","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r热点缓存失效重建描述：热点缓存失效，重建又比较好耗时，出现这种情况时大量请求会直达后端，有大量线程重建缓存，会造成后端压力过大。 解决方案：加一个分布式锁，只允许一个缓存重建缓存。 ","date":"2023-06-28","objectID":"/posts/redis/:11:4","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\r缓存与数据库不一致描述：在并发情况同时操作数据库和缓存可能导致缓存与数据库不一致。 解决方案：1.大部分场景是容忍短时间内缓存与数据库不一致的，只有设置过期时间即可，不能容忍不一致的可以加读写锁实现，但会牺牲一定的性能。 ","date":"2023-06-28","objectID":"/posts/redis/:11:5","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["db","中间件"],"content":"\rRedis 参考文档 redis 官方文档： https://redis.io/documentation redis 设计与实现：http://redisbook.com/ ","date":"2023-06-28","objectID":"/posts/redis/:12:0","tags":["redis"],"title":"Redis 从入门到精通","uri":"/posts/redis/"},{"categories":["java"],"content":"\r先学会如何使用","date":"2023-06-28","objectID":"/posts/spring-aop/:1:0","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\rSpring-boot 或 Spring-cloud 中使用AOP在Spring-boot 工程中使用AOP功能，先引入相关的依赖。 pom.xml \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-aop\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003cversion\u003e1.18.22\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003cexclusions\u003e \u003cexclusion\u003e \u003cgroupId\u003eorg.junit.vintage\u003c/groupId\u003e \u003cartifactId\u003ejunit-vintage-engine\u003c/artifactId\u003e \u003c/exclusion\u003e \u003c/exclusions\u003e \u003c/dependency\u003e 测试业务接口 UserService.java public interface UserService { void test(); } 测试业务接口实现类 UserServiceImp.java @Slf4j @Service public class UserServiceImpl implements UserService { @Override public void test() { log.info(\"执行业务方法test...\"); } } 切面类 LogAspect.java @Slf4j @Aspect @Component public class LogAspect { @Pointcut(\"execution(public * com.example.service.impl.*.*(..))\") public void pointcut() { } @Before(\"pointcut()\") public void before() { log.info(\"Before通知 -\u003e 业务方法执行前调用...\"); } @After(\"pointcut()\") public void after() { log.info(\"After通知 -\u003e 业务方法执行后调用...\"); } } 启动类 Application.java @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 执行测试类 UserServiceTest.java @SpringBootTest public class SpringTests { } class UserServiceTest extends SpringTests { @Autowired private UserService userService; @Test void test() { userService.test(); } } INFO 53837 --- [ main] com.example.aspect.LogAspect : Before通知 -\u003e 业务方法执行前调用... INFO 53837 --- [ main] c.example.service.impl.UserServiceImpl : 执行业务方法test... INFO 53837 --- [ main] com.example.aspect.LogAspect : After通知 -\u003e 业务方法执行后调用... 可以看到，在springboot项目中只要引入 spring-boot-starter-aop 包，默认会自动开启AOP功能。 这是因为SpringBoot自动配置的特性，如下是AOP的配置类，默认是开启。 @Configuration(proxyBeanMethods = false) @ConditionalOnProperty(prefix = \"spring.aop\", name = \"auto\", havingValue = \"true\", matchIfMissing = true) public class AopAutoConfiguration { // @Configuration(proxyBeanMethods = false) @ConditionalOnClass(Advice.class) static class AspectJAutoProxyingConfiguration { @Configuration(proxyBeanMethods = false) @EnableAspectJAutoProxy(proxyTargetClass = false) @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"false\", matchIfMissing = false) static class JdkDynamicAutoProxyConfiguration { } @Configuration(proxyBeanMethods = false) @EnableAspectJAutoProxy(proxyTargetClass = true) @ConditionalOnProperty(prefix = \"spring.aop\", name = \"proxy-target-class\", havingValue = \"true\", matchIfMissing = true) static class CglibAutoProxyConfiguration { } } } 根据ConditionalOnProperty条件注解，当前环境中存在 spring.aop.auto，且值为true会启用该配置类， 而matchIfMissing的值为 true, 表明当没有手动配置 spring.aop.auto 时其默认值为true, 即默认开启AOP自动配置。 havingValue 表示手动配置的值和havingValue的值相等时才生效。 通过 AspectJAutoProxyingConfiguration 内部类注入 JdkDynamicAutoProxyConfiguration 和 CglibAutoProxyConfiguration 配置类型，到底哪一个会生效呢 ? CglibAutoProxyConfiguration会生效，因为没有配置spring.aop.proxy-target-class时CglibAutoProxyConfiguration上的默认值为true, 所以CglibAutoProxyConfiguration配置生效。 matchIfMissing 表示没有手动配置时 spring.aop.proxy-target-class 配置的默认值。 通过 @EnableAspectJAutoProxy(proxyTargetClass = true) 开启AOP功能，这是实现AOP的关键。 ","date":"2023-06-28","objectID":"/posts/spring-aop/:1:1","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\r原理分析Spring-AOP 的原理可以划分为三个步骤，总共做了三件事，分别是解析切面、创建动态代理、调用代理方法。 解析切面： 在Spring容器启动的过程中会扫描所有的切面类，即标注@Aspect的bean,解析该类中的所有通知方法，生成Advisor，每个含有 @Before、@After… 的类都是一个通知，都会生成一个Advisor，最后将所有解析好的Advisor保存在缓存中。 创建代理对象： 根据切点表达式匹配所有bean和方法，如果匹配成功，实现了接口的bean使用JDK动态代理，没有实现接口使用Cglib动态代理。 调用代理方法： 当调用被代理的类的方法是，AOP会在执行目标方法前后执行被植入的切面逻辑。 ","date":"2023-06-28","objectID":"/posts/spring-aop/:2:0","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\r解析切面从入口 @EnableAspectJAutoProxy 开始。 导入了另一个类 AspectJAutoProxyRegistrar，@Import注解可以将一个普通类注入到spring容器，注册成bean。 @Import(AspectJAutoProxyRegistrar.class) public @interface EnableAspectJAutoProxy {} class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar { @Override public void registerBeanDefinitions( AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { // 注入AOP核心类型 AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry); // 获取 EnableAspectJAutoProxy 注解中的 proxyTargetClass 和 exposeProxy 执行。 // proxyTargetClass = true 表示都使用cglib代理。 // exposeProxy = true 暴露代理对象到AOP的上下文，可以通过AopContext获取。 AnnotationAttributes enableAspectJAutoProxy = AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class); if (enableAspectJAutoProxy != null) { if (enableAspectJAutoProxy.getBoolean(\"proxyTargetClass\")) { AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry); } if (enableAspectJAutoProxy.getBoolean(\"exposeProxy\")) { AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry); } } } } 这里导入的是 ImportBeanDefinitionRegistrar 类型的bean, 通过实现 registerBeanDefinitions 方法可以注入其他任何类型的bean。 关于ImportBeanDefinitionRegistrar 的用法参考另一篇文章：https://juejin.cn/post/7039308644768284679 关键是注册了另一个bean，AnnotationAwareAspectJAutoProxyCreator 。 AnnotationAwareAspectJAutoProxyCreator 实现了 BeenPostProcessor接口 , 是bean的后置处理器。 BeenPostProcessor 中有两个重要方法如下，他们分别在bean初始化前后执行。 default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { return bean; } default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { return bean; } postProcessBeforeInitialization 在bean 初始化前执行。 postProcessAfterInitialization 在 bean 初始化后执行。 另外还实现了 InstantiationAwareBeanPostProcessor接口，该类也有两个方法，分别在bean实例化前后执行。 default Object postProcessBeforeInstantiation(Class\u003c?\u003e beanClass, String beanName) throws BeansException { return null; } default boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException { return true; } postProcessBeforeInstantiation 在bean实例化前执行。 postProcessAfterInstantiation 在bean实例化后执行。 以上四个方法是AOP解析切面、创建代理的关键，在抽象类AbstractAutoProxyCreator中分别实现了这四个方法。 @Override public Object postProcessBeforeInstantiation(Class\u003c?\u003e beanClass, String beanName) { Object cacheKey = getCacheKey(beanClass, beanName); if (!StringUtils.hasLength(beanName) || !this.targetSourcedBeans.contains(beanName)) { if (this.advisedBeans.containsKey(cacheKey)) { return null; } // 解析切面 if (isInfrastructureClass(beanClass) || shouldSkip(beanClass, beanName)) { this.advisedBeans.put(cacheKey, Boolean.FALSE); return null; } } TargetSource targetSource = getCustomTargetSource(beanClass, beanName); if (targetSource != null) { if (StringUtils.hasLength(beanName)) { this.targetSourcedBeans.add(beanName); } Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(beanClass, beanName, targetSource); Object proxy = createProxy(beanClass, beanName, specificInterceptors, targetSource); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; } return null; } @Override public boolean postProcessAfterInstantiation(Object bean, String beanName) { return true; } @Override public Object postProcessBeforeInitialization(Object bean, String beanName) { return bean; } @Override public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) { if (bean != null) { Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) { // 创建代理 return wrapIfNecessary(bean, beanName, cacheKey); } } return bean; } 在 postProcessBeforeInstantiation 方法中实现了切面解析的逻辑，会在第一个bean实例化前执行。 在 postProcessAfterInitialization 方法中实现创建代理，在bean初始化后执行。 ","date":"2023-06-28","objectID":"/posts/spring-aop/:3:0","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\r切面解析入口方法 postProcessBeforeInstantiation // 切面bean缓存 private final Map\u003cObject, Boolean\u003e advisedBeans = new ConcurrentHashMap\u003c\u003e(256); @Override public Object postProcessBeforeInstantiation(Class\u003c?\u003e beanClass, String beanName) { Object cacheKey = getCacheKey(beanClass, beanName); if (!StringUtils.hasLength(beanName) || !this.targetSourcedBeans.contains(beanName)) { // 如果已经解析返回 if (this.advisedBeans.containsKey(cacheKey)) { return null; } // 解析切面 if (isInfrastructureClass(beanClass) || shouldSkip(beanClass, beanName)) { this.advisedBeans.put(cacheKey, Boolean.FALSE); return null; } } return null; } postProcessBeforeInstantiation 在bean实例化前执行。 shouldSkip 方法中实现注解方式AOP的解析过程。 解析过的切面会把beanName存入 advisedBeans 缓存中, 不再重复解析。 ","date":"2023-06-28","objectID":"/posts/spring-aop/:3:1","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\r解析切面核心方法 shouldSkip @Override protected boolean shouldSkip(Class\u003c?\u003e beanClass, String beanName) { // TODO: Consider optimization by caching the list of the aspect names List\u003cAdvisor\u003e candidateAdvisors = findCandidateAdvisors(); for (Advisor advisor : candidateAdvisors) { if (advisor instanceof AspectJPointcutAdvisor \u0026\u0026 ((AspectJPointcutAdvisor) advisor).getAspectName().equals(beanName)) { return true; } } return super.shouldSkip(beanClass, beanName); } @Override protected List\u003cAdvisor\u003e findCandidateAdvisors() { // Add all the Spring advisors found according to superclass rules. List\u003cAdvisor\u003e advisors = super.findCandidateAdvisors(); // Build Advisors for all AspectJ aspects in the bean factory. if (this.aspectJAdvisorsBuilder != null) { advisors.addAll(this.aspectJAdvisorsBuilder.buildAspectJAdvisors()); } return advisors; } shouldSkip 中调用 findCandidateAdvisors() 解析所有候选的切面，切面有两种切面，一种是基于接口的切面，一种是基于注解的切面。 ","date":"2023-06-28","objectID":"/posts/spring-aop/:3:2","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\r解析接口方式的切面一种是调用 super.findCandidateAdvisors() 解析所有实现Advisor接口的切面bean。 protected List\u003cAdvisor\u003e findCandidateAdvisors() { return this.advisorRetrievalHelper.findAdvisorBeans(); } public List\u003cAdvisor\u003e findAdvisorBeans() { String[] advisorNames = this.cachedAdvisorBeanNames; if (advisorNames == null) { // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let the auto-proxy creator apply to them! advisorNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors( this.beanFactory, Advisor.class, true, false); this.cachedAdvisorBeanNames = advisorNames; } if (advisorNames.length == 0) { return new ArrayList\u003c\u003e(); } // ... 略 } 这里的核心操作是解析所有实现 Advisor 接口的bean, 缓存起来。 ","date":"2023-06-28","objectID":"/posts/spring-aop/:3:3","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\r解析注解方式的切面另一种调用 aspectJAdvisorsBuilder.buildAspectJAdvisors() 解析所有注解方式的切面。 // Advisor缓存，key是aspectNeam private final Map\u003cString, List\u003cAdvisor\u003e\u003e advisorsCache = new ConcurrentHashMap\u003c\u003e(); public List\u003cAdvisor\u003e buildAspectJAdvisors() {} buildAspectJAdvisors 的代码很长，这里略过，只说一下核心逻辑，它会解析Spring容器中取出所有的切面，构建成Advisor放入到advisorsCache缓存起来。 现在所有的切面都解析好并且缓存起来了，下面就是创建动态代理。 ","date":"2023-06-28","objectID":"/posts/spring-aop/:3:4","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\r创建动态代理AOP创建动态代理有两种方式，如果代理目标实现了接口，则采用JDK动态代理，如果没有实现接口，则采用Cglib动态代理。 ","date":"2023-06-28","objectID":"/posts/spring-aop/:4:0","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\r代理创建入口方法 postProcessAfterInitialization前面说过在bean初始化后执行。 @Override public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) { if (bean != null) { Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) { // 创建代理 return wrapIfNecessary(bean, beanName, cacheKey); // ① } } return bean; } protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) { if (StringUtils.hasLength(beanName) \u0026\u0026 this.targetSourcedBeans.contains(beanName)) { return bean; } if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) { return bean; } if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) { this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; } // 根据当前bean获取候选的Advisor，这里做第一次筛选，初步筛选，只根据beanClass匹配。 Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null); if (specificInterceptors != DO_NOT_PROXY) { this.advisedBeans.put(cacheKey, Boolean.TRUE); // 创建代理 Object proxy = createProxy( bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean)); this.proxyTypes.put(cacheKey, proxy.getClass()); return proxy; } this.advisedBeans.put(cacheKey, Boolean.FALSE); return bean; } protected Object createProxy(Class\u003c?\u003e beanClass, @Nullable String beanName, @Nullable Object[] specificInterceptors, TargetSource targetSource) { if (this.beanFactory instanceof ConfigurableListableBeanFactory) { AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass); } // 实例化代理工厂并设置创建代理所需的原料 ProxyFactory proxyFactory = new ProxyFactory(); proxyFactory.copyFrom(this); if (!proxyFactory.isProxyTargetClass()) { if (shouldProxyTargetClass(beanClass, beanName)) { proxyFactory.setProxyTargetClass(true); } else { evaluateProxyInterfaces(beanClass, proxyFactory); } } // 构建切面 Advisor[] advisors = buildAdvisors(beanName, specificInterceptors); // 设置切面 proxyFactory.addAdvisors(advisors); // 设置代理目标对象 proxyFactory.setTargetSource(targetSource); customizeProxyFactory(proxyFactory); proxyFactory.setFrozen(this.freezeProxy); if (advisorsPreFiltered()) { proxyFactory.setPreFiltered(true); } return proxyFactory.getProxy(getProxyClassLoader()); } 创建代理工厂，为代理工程设置原料，一个是要创建代理的代理目标，表明为哪些类创建代理对象，这里是当前bean对象。 另一个是要植入的切面，为代理目标增强的那些功能。 public Object getProxy(@Nullable ClassLoader classLoader) { // 创建AOP代理工厂，创建代理对象 return createAopProxy().getProxy(classLoader); } protected final synchronized AopProxy createAopProxy() { if (!this.active) { activate(); } // 创建AOP代理工厂 return getAopProxyFactory().createAopProxy(this); } @Override public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException { if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) { Class\u003c?\u003e targetClass = config.getTargetClass(); if (targetClass == null) { throw new AopConfigException(\"TargetSource cannot determine target class: \" + \"Either an interface or a target is required for proxy creation.\"); } // 如果接口或已经是jdk代理，则走JDK动态代理。 if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) { return new JdkDynamicAopProxy(config); } // CGLIB 动态代理 return new ObjenesisCglibAopProxy(config); } else { // JDK 动态代理 return new JdkDynamicAopProxy(config); } } 首先根据当前bean获取符合条件的签名通知列表。 实例化代理工厂，设置代理目标，设置代理切面通知。 在代理工厂中又创建AOP代理工厂，根据代理目标选择Cglib或jdk动态代理。 最后调用代理工厂中 getProxy 方法生成代理对象。 ","date":"2023-06-28","objectID":"/posts/spring-aop/:4:1","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\rCglibAopProxy cglib动态代理Cglib可以为普通类和接口创建代理类，原理是在应用启动是通过asm技术生成新的字节码文件，新的字节码都统一的签注$$。 实例： 代理目标类 Person.java public class Person { public void sayHello() { System.out.println(\"hello word!\"); } } 代理工厂类 CglibProxyFactory.java public class CglibProxyFactory implements MethodInterceptor { /** * 代理目标 */ private final Object target; private final Enhancer enhancer; public CglibProxyFactory(Object target) { this.target = target; this.enhancer = new Enhancer(); enhancer.setSuperclass(target.getClass()); enhancer.setCallback(this); } public Object getProxy() { return enhancer.create(); } @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { System.out.println(\"业务方法执行前...\"); Object result = methodProxy.invokeSuper(o, objects); System.out.println(\"业务方法执行后...\"); return result; } } 测试 \u0026 执行结果 public static void main(String[] args) { CglibProxyFactory proxyFactory = new CglibProxyFactory(new Person()); Person person = (Person) proxyFactory.getProxy(); person.sayHello(); } 业务方法执行前... hello word! 业务方法执行后... ","date":"2023-06-28","objectID":"/posts/spring-aop/:4:2","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\rJdkDynamicAopProxy JDK动态代理jdk 动态代理只能为实现接口的类创建代理。 jdk 动态代理底层通过生成字节码实现，生成的代理类都会继承一个模板类Proxy, 生成的类名一般为 $Proxy0这样，这也是什么jdk动态代理不能为普通类创建代理的原因，它已经继承Proxy类了，没发再继承另一个了。 实例：创建代理目标和接口 public interface Animal { void test(); } public class Dog implements Animal { @Override public void test() { System.out.println(\"dog 会跑!\"); } } 代理工厂 JdkDynamicProxyFactory.java public class JdkDynamicProxyFactory implements InvocationHandler { /** * 代理目标 */ private final Object target; public JdkDynamicProxyFactory(Object target) { this.target = target; } public Object getProxy() { return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\"业务方法执行前...\"); Object result = method.invoke(target, args); System.out.println(\"业务方法执行后...\"); return result; } } 测试 \u0026 执行结果 public static void main(String[] args) { JdkDynamicProxyFactory proxyFactory = new JdkDynamicProxyFactory(new Dog()); Animal animal = (Animal) proxyFactory.getProxy(); animal.test(); } 业务方法执行前... dog 会跑! 业务方法执行后... ","date":"2023-06-28","objectID":"/posts/spring-aop/:4:3","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\r调用代理方法","date":"2023-06-28","objectID":"/posts/spring-aop/:5:0","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\rJDK 动态代理调用切面方法jdk动态代理调用是通过实现 InvocationHandler 接口的 invoke 方法调用切面方法。 final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable { @Override @Nullable public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { MethodInvocation invocation; Object oldProxy = null; boolean setProxyContext = false; TargetSource targetSource = this.advised.targetSource; Object target = null; try { // 如果是 equals、hashCode 等方法不用调用切面方法，最终调用原方法。 if (!this.equalsDefined \u0026\u0026 AopUtils.isEqualsMethod(method)) { // The target does not implement the equals(Object) method itself. return equals(args[0]); } else if (!this.hashCodeDefined \u0026\u0026 AopUtils.isHashCodeMethod(method)) { // The target does not implement the hashCode() method itself. return hashCode(); } else if (method.getDeclaringClass() == DecoratingProxy.class) { // There is only getDecoratedClass() declared -\u003e dispatch to proxy config. return AopProxyUtils.ultimateTargetClass(this.advised); } else if (!this.advised.opaque \u0026\u0026 method.getDeclaringClass().isInterface() \u0026\u0026 method.getDeclaringClass().isAssignableFrom(Advised.class)) { // Service invocations on ProxyConfig with the proxy config... return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args); } Object retVal; if (this.advised.exposeProxy) { // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; } // Get as late as possible to minimize the time we \"own\" the target, // in case it comes from a pool. target = targetSource.getTarget(); Class\u003c?\u003e targetClass = (target != null ? target.getClass() : null); // 获取方法的连拦截链，这里会根据方法名最进一步的筛选 List\u003cObject\u003e chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); if (chain.isEmpty()) { // 如果拦截链为空，调用原方法 Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); } else { // 构建调用链，使用责任链模式，执行切面方法。 invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain); // Proceed to the joinpoint through the interceptor chain. retVal = invocation.proceed(); } // Massage return value if necessary. Class\u003c?\u003e returnType = method.getReturnType(); if (retVal != null \u0026\u0026 retVal == target \u0026\u0026 returnType != Object.class \u0026\u0026 returnType.isInstance(proxy) \u0026\u0026 !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) { // Special case: it returned \"this\" and the return type of the method // is type-compatible. Note that we can't help if the target sets // a reference to itself in another returned object. retVal = proxy; } else if (retVal == null \u0026\u0026 returnType != Void.TYPE \u0026\u0026 returnType.isPrimitive()) { throw new AopInvocationException( \"Null return value from advice does not match primitive return type for: \" + method); } return retVal; } finally { if (target != null \u0026\u0026 !targetSource.isStatic()) { // Must have come from TargetSource. targetSource.releaseTarget(target); } if (setProxyContext) { // Restore old proxy. AopContext.setCurrentProxy(oldProxy); } } } } ","date":"2023-06-28","objectID":"/posts/spring-aop/:5:1","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\rCglib 动态代理调用切面方法Cglib 通过实现 MethodInterceptor 接口的 intercept 方法调用切面方法。 public interface MethodInterceptor extends Callback { Object intercept(Object var1, Method var2, Object[] var3, MethodProxy var4) throws Throwable; } private static class DynamicAdvisedInterceptor implements MethodInterceptor, Serializable { @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { Object oldProxy = null; boolean setProxyContext = false; Object target = null; TargetSource targetSource = this.advised.getTargetSource(); try { if (this.advised.exposeProxy) { // Make invocation available if necessary. oldProxy = AopContext.setCurrentProxy(proxy); setProxyContext = true; } // Get as late as possible to minimize the time we \"own\" the target, in case it comes from a pool... target = targetSource.getTarget(); Class\u003c?\u003e targetClass = (target != null ? target.getClass() : null); // 获取拦截链 List\u003cObject\u003e chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass); Object retVal; // Check whether we only have one InvokerInterceptor: that is, // no real advice, but just reflective invocation of the target. if (chain.isEmpty() \u0026\u0026 Modifier.isPublic(method.getModifiers())) { // We can skip creating a MethodInvocation: just invoke the target directly. // Note that the final invoker must be an InvokerInterceptor, so we know // it does nothing but a reflective operation on the target, and no hot // swapping or fancy proxying. Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args); retVal = methodProxy.invoke(target, argsToUse); } else { // 责任连调用，切面方法。 retVal = new CglibMethodInvocation(proxy, target, method, args, targetClass, chain, methodProxy).proceed(); } retVal = processReturnType(proxy, target, method, retVal); return retVal; } finally { if (target != null \u0026\u0026 !targetSource.isStatic()) { targetSource.releaseTarget(target); } if (setProxyContext) { // Restore old proxy. AopContext.setCurrentProxy(oldProxy); } } } } cglib的调用类 CglibMethodInvocation 继承 ReflectiveMethodInvocation。 private static class CglibMethodInvocation extends ReflectiveMethodInvocation { private final MethodProxy methodProxy; private final boolean publicMethod; public CglibMethodInvocation(Object proxy, @Nullable Object target, Method method, Object[] arguments, @Nullable Class\u003c?\u003e targetClass, List\u003cObject\u003e interceptorsAndDynamicMethodMatchers, MethodProxy methodProxy) { super(proxy, target, method, arguments, targetClass, interceptorsAndDynamicMethodMatchers); this.methodProxy = methodProxy; this.publicMethod = Modifier.isPublic(method.getModifiers()); } } jdk动态代理调用是通过实现 InvocationHandler 接口的 invoke 方法调用切面方法。 Cglib 通过实现 MethodInterceptor 接口的 intercept 方法调用切面方法。 ReflectiveMethodInvocation 通责任连模式对象切面的调用。 ","date":"2023-06-28","objectID":"/posts/spring-aop/:5:2","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["java"],"content":"\r附：AOP启动流程图 ","date":"2023-06-28","objectID":"/posts/spring-aop/:6:0","tags":["java","spring"],"title":"Spring AOP 从入门到源码解析","uri":"/posts/spring-aop/"},{"categories":["linux"],"content":"\rless从文件开头查看少量内容命令，命令格式：less [参数] 文件 。 参数： - /字符串：向下搜索 - ?字符串：向上搜索 - n：重复前一个搜索(向下搜索) - N：反向重复前一个搜索(向上搜索) - 翻一页 - f：前进一页 - b：回退一页 - 翻半页： - d：前进半页 - u：后退半页 - 翻一行： - e/j：前进一行 - y/k：后退一行 实例1：查看日志, -N 显示行号 less -N /var/a.log 实例2：跳转到最后一行，并滚动打印。 shift + f 操作1：在滚动打印的基础上停止滚动 control + c 操作2：向上搜索关键词 ?kewwaord + enter 按n继续向上搜索相同字符串 按N继续向下搜索相同字符串 操作3：向下搜索关键词 /kewwaord + enter 按N继续向下搜索相同字符串 按n继续向上搜索相同字符串 ","date":"2023-06-28","objectID":"/posts/linux/:1:0","tags":["linux"],"title":"Linux 常用命令","uri":"/posts/linux/"},{"categories":["linux"],"content":"\rchown设置文件所有者对文件的权限。 实例1：给admin用户授于/var/log.a.log文件权限 chown admin /var/log.a.log 实例2：递归给某个用户授于整个目录权限 chown -R admin /var/log/ ","date":"2023-06-28","objectID":"/posts/linux/:2:0","tags":["linux"],"title":"Linux 常用命令","uri":"/posts/linux/"},{"categories":["linux"],"content":"\rchmod设置用户对文件的读、写、执行权限。 命令格式： chmod [ugo+rwx] file 参数： u - 文件拥有者、g - 拥有者同组的其他人、o - 其他用户、a - 所有用户。 r - 读、w - 写、x - 执行 -R 递归收取目录和子目录下所有文件权限 实例1：将文件 file1.txt 设为所有人皆可读取 chmod ugo+r file1.txt # 等价 chmod a+r file1.txt 实例2：所有文件所有人可读。 chmod -R a+r * 实例3：所有人读写执行 chmod 777 file # 等价 chmod a=rwx file ","date":"2023-06-28","objectID":"/posts/linux/:3:0","tags":["linux"],"title":"Linux 常用命令","uri":"/posts/linux/"},{"categories":["linux"],"content":"\rlsof查看端口占用情况。 实例1：查看 占用9876 端口的进程。 lsof -i tcp:9876 # 执行结果 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME java 71184 zhougaojun 69u IPv6 0xd4d49114bb1da0f5 0t0 TCP *:sd (LISTEN) 实例2：查找出正在监听的端口 lsof -i:80 -sTCP:LISTEN lsof -i:80 | grep LISTEN 实例3：另外可以用java自带的jps命令查看java应用进程 jps #执行结果 21873 Main 71184 NamesrvStartup ","date":"2023-06-28","objectID":"/posts/linux/:4:0","tags":["linux"],"title":"Linux 常用命令","uri":"/posts/linux/"},{"categories":["linux"],"content":"\rrz上传本地文件到远程linux服务器。 rz # centos 输入rz命令唤回车起文件选择弹框 ","date":"2023-06-28","objectID":"/posts/linux/:5:0","tags":["linux"],"title":"Linux 常用命令","uri":"/posts/linux/"},{"categories":["linux"],"content":"\rsz下载服务文件到本地。 sz a.txt # 下载文件a.txt到本地机器。 ","date":"2023-06-28","objectID":"/posts/linux/:6:0","tags":["linux"],"title":"Linux 常用命令","uri":"/posts/linux/"},{"categories":["linux"],"content":"\rscp远程和本地之间传输文件, 加-r 拷贝整个文件夹。 实例1：考配置远程服务器tomct.log文件到本地指定位置 scp root@192.168.1.100:/var/log/tomcat/tomcat.log /home/myfile/ scp -r root@192.168.1.100:/data/ /home/myfile/ # 拷贝文件夹到本地服务 实例2：拷贝本地文件到远程服务器 scp /home/myfile/test.txt root@192.168.1.100:/data/ # 单文件拷贝 scp /home/myfile/test1.txt test2.cpp test3.bin test.* root@192.168.1.100:/data/ # 多文件拷贝 scp -r /home/myfile/ root@192.168.1.100:/data/ # 拷贝文件夹 ","date":"2023-06-28","objectID":"/posts/linux/:7:0","tags":["linux"],"title":"Linux 常用命令","uri":"/posts/linux/"},{"categories":["linux"],"content":"\rfind查找文件。 实例1：在home目录下查找名为test的文件。 find /home -name test 实例2：在home目录下查找以test开头的文件。 find /home -name \"test*\" 实例3：在home目录下查找大小大于100k的文件 find /home -size +100k ","date":"2023-06-28","objectID":"/posts/linux/:8:0","tags":["linux"],"title":"Linux 常用命令","uri":"/posts/linux/"},{"categories":["linux"],"content":"\rnetstat显示各种网络信息，如查看TCP连接信息。 参数： a (all)显示所有选项，默认不显示LISTEN相关 t (tcp)仅显示tcp相关选项 u (udp)仅显示udp相关选项 n 拒绝显示别名，能显示数字的全部转化成数字。 l 仅列出有在 Listen (监听) 的服務状态 p 显示建立相关链接的程序名 r 显示路由信息，路由表 e 显示扩展信息，例如uid等 s 按各个协议进行统计 c 每隔一个固定时间，执行该netstat命令。 实例：查看所有TCP连接的端口和进程信息。 netstat -antp ","date":"2023-06-28","objectID":"/posts/linux/:9:0","tags":["linux"],"title":"Linux 常用命令","uri":"/posts/linux/"},{"categories":["linux"],"content":"\rps显示进程的状态，实例。 ps -ef # 显示进程及进程启动详细情况。 ps -aux # 线程带CPU占用、内存信息等详细情况。 其他参数： a：显示一个终端的所有进程，除会话引线外； u：显示进程的归属用户及内存的使用情况； x：显示没有控制终端的进程； l：长格式显示更加详细的信息； e：显示所有进程； ","date":"2023-06-28","objectID":"/posts/linux/:10:0","tags":["linux"],"title":"Linux 常用命令","uri":"/posts/linux/"},{"categories":["linux"],"content":"\rln生成链接文件，实例。 ln -s source_file target_file # 生成软连接，也称为符号链接，相当于快捷方式。 ln source_file target_file # 生成硬链接，也称为实体链接，相当于拷贝。 ","date":"2023-06-28","objectID":"/posts/linux/:11:0","tags":["linux"],"title":"Linux 常用命令","uri":"/posts/linux/"},{"categories":["linux"],"content":"\rtop监控CPU、内存、负载、线程等运营情况 实例1: 基本用法 top # 按CPU占用排序，然后按sheft + p top # 按内存占用排序。然后按 sheft + m top -d 2 # 每个2秒执行一次top。 示例2：查看指定进程下的所有线程。 top -H -p [pid] # 方式1，直接一步完成。 top -p [pid] # 方式2，执行完需要按大写H。 ","date":"2023-06-28","objectID":"/posts/linux/:12:0","tags":["linux"],"title":"Linux 常用命令","uri":"/posts/linux/"},{"categories":["linux"],"content":"\rhtop以一种更友好的方式监控机器的运行状况，安装命令如下。 yum install htop -y # centos brew install htop # mac 实例：直接执行htop可以监控CPU、内存、线程情况，并且以高亮的新式展示。 ","date":"2023-06-28","objectID":"/posts/linux/:13:0","tags":["linux"],"title":"Linux 常用命令","uri":"/posts/linux/"},{"categories":["devops"],"content":"\rDocker 架构 Docker架构 Docker 主要组件包括 Client、Daemon、Images、Container、Registry。 Client ： docker客户端 Daemon：docker服务端守护进程。 Images：docker镜像，有点像jar包。 Container：运行docker镜像的容器，像Tomcat。 Registry：docker镜像仓库，像maven仓库。 ","date":"2023-06-28","objectID":"/posts/docker/:1:0","tags":["docker"],"title":"Docker 入门","uri":"/posts/docker/"},{"categories":["devops"],"content":"\rDocker 常用命令","date":"2023-06-28","objectID":"/posts/docker/:2:0","tags":["docker"],"title":"Docker 入门","uri":"/posts/docker/"},{"categories":["devops"],"content":"\r镜像相关的命令\r搜索镜像 docker search java // 搜索镜像 下载镜像 docker pull java:8 # 下载镜像 查看镜像 docker images # 查看镜像 删除镜像 docker rmi java # 删除镜像，加-f强制删除 docker rmi $(docker images ‐q) # 删除所有镜像 ","date":"2023-06-28","objectID":"/posts/docker/:2:1","tags":["docker"],"title":"Docker 入门","uri":"/posts/docker/"},{"categories":["devops"],"content":"\r容器相关的命令\r运行Docker镜像 docker run -d -p 8080:80 nginx:least -d 后台运行 -p 指定端口 如：8080:8080，宿主主机端口：容器端口 -m 指定容器的内存大小 如 ：-m 500M -e 指定环境变量 如：-e JAVA_OPTS=’‐Xms1028M ‐Xmx1028M ‐Xmn512M ‐Xss512K ‐XX:MetaspaceSize=256M ‐XX:MaxMetaspaceSize= 256M' -net 设置网络 –net=bridge 桥接，默认 –net=host 容器使用宿主网络，不安全。 –net=container=容器ID，使用和其他容器一样的网络 -v 指定挂在目录 如: /var/nginx/logs : /nginx/logs , 宿主主机：容器主机。 列出容器列表 docker ps # 加 -a 可列出所有的容器，包含停止的容器 停止容器 docker stop [容器ID] // 停止容器 docker kill [容器ID] // 强制停止容器 启动容器 docker start [容器ID] 查看日志 docker container logs [容器ID] 查看容器信息 docker inspect [容器ID] 查看容器里的进程 docker top [容器ID] 文件传输 docker cp [容器ID]:/容器文件路径 宿主主机文件路径 // 从容器cp到主机 docker cp 宿主主机文件路径 [容器ID]:/容器文件路径 // 从主机cp到容器 进入到容器的 shell docker exec -it [容器ID] /bin/bash 删除容器 docker rm [容器ID] // 删除已停止的容器 docker rm -f [容器ID] // 强制删除正在运行的容器 docker rm ‐f $(docker ps ‐a ‐q) // 强制删除所有容器 ","date":"2023-06-28","objectID":"/posts/docker/:2:2","tags":["docker"],"title":"Docker 入门","uri":"/posts/docker/"},{"categories":["devops"],"content":"\rDocker 构建镜像","date":"2023-06-28","objectID":"/posts/docker/:3:0","tags":["docker"],"title":"Docker 入门","uri":"/posts/docker/"},{"categories":["devops"],"content":"\rDockerfile 命令 FROM 指定基础镜像，如 java:8 RUN 构建镜像执行的命令。 ADD 文件复制 COPY 文件复制，不支持URL和压缩。 CMD 容器启动命令。 EXPOSE 容器暴露端口。 WORKID 容器工作路径。 ENV 环境变量。 ENTRPINT 和CMD类似。 VOLUME 指定存储目录，如：VOLUME[\"/data\"]。 ","date":"2023-06-28","objectID":"/posts/docker/:3:1","tags":["docker"],"title":"Docker 入门","uri":"/posts/docker/"},{"categories":["devops"],"content":"\r编写Dockerfile执行 vi Dockerfile编写镜像文件 # 基础镜像 FROM java:8 # 复制文件 ADD java-demo.jar /app.jar # 暴露端口 EXPOSE 8080 # 运行程序 CMD java -jar /app.jar ","date":"2023-06-28","objectID":"/posts/docker/:3:2","tags":["docker"],"title":"Docker 入门","uri":"/posts/docker/"},{"categories":["devops"],"content":"\r构建镜像在Dockerfile 文件所在的目录执行以下命令构建镜像。 docker build -t java-demo:0.0.1 . -t 指定镜像的名称和版本，不指定版本默认为latest ‘.’ 点代表Dockerfile文件的位置 ","date":"2023-06-28","objectID":"/posts/docker/:3:3","tags":["docker"],"title":"Docker 入门","uri":"/posts/docker/"},{"categories":["devops"],"content":"\r上传到Docker镜像仓库 在docker hub 注册账号 在控制台使用 docker login 命令登录 给镜像打一个tag分组名称, 如： docker tag java-demo.jar:0.0.1 zhangsan/java-demo.jar:0.0.1 push到远程仓库, 如：docker push zhangsan/java-demo.jar ","date":"2023-06-28","objectID":"/posts/docker/:3:4","tags":["docker"],"title":"Docker 入门","uri":"/posts/docker/"},{"categories":["devops"],"content":"\rDocker-Compose可以批量管理多个容器。 ","date":"2023-06-28","objectID":"/posts/docker-compose/:1:0","tags":["docker"],"title":"Docker-Compose 容器编排","uri":"/posts/docker-compose/"},{"categories":["devops"],"content":"\r编写 docker-compose 文件 以Redis为例，执行 vi docker-compose-redis.yml。 version: '3' services: # redis redis: image: redis volumes: - /var/volumes/redis_data:/data restart: always ports: - \"6379:6379\" ","date":"2023-06-28","objectID":"/posts/docker-compose/:1:1","tags":["docker"],"title":"Docker-Compose 容器编排","uri":"/posts/docker-compose/"},{"categories":["devops"],"content":"\r启动容器 docker-compose -f docker-compose-redis.yml up -d docker-compose -f docker-compose-redis.yml up -d --build // 每次重新打包新的镜像 -f 指定compose 文件，默认查找docker-compose.yml. -d 后台启动。 ","date":"2023-06-28","objectID":"/posts/docker-compose/:1:2","tags":["docker"],"title":"Docker-Compose 容器编排","uri":"/posts/docker-compose/"},{"categories":["devops"],"content":"\r配置文件常用参数 image 指定镜像名称或ID image：java build 指定Dockerfile文件的路径 build: ./dir command 覆盖容器启动后默认执行的命令。 links 连接其他容器 web: links: - db - redis external_links 连接外部容器，格式和links一样。 ports 暴露端口信息，格式：宿主主机端口：容器端口,只指定容器端口时宿主主机端口随机 ports: - \"8081\" - \"8080:8080\" expose 只保留容器端口 expose: - \"8000\" - \"9000\" volumes 卷挂在路径，格式：宿主主机路径:容器路径 volumes: - /opt/data:/var/lib/mysql environment 设置环境变量 environment: RACK_ENV dev SHOW: false net 设置网络 net: \"bridge\" net: \"host\" net: \"none\" net: \"container:[service name or container name/id]\" dns 设置dns,可以一个，也可以是多个 dns: 8.8.8.8 dns: - 8.8.8.8 - 9.9.9.9 ","date":"2023-06-28","objectID":"/posts/docker-compose/:1:3","tags":["docker"],"title":"Docker-Compose 容器编排","uri":"/posts/docker-compose/"},{"categories":["devops"],"content":"\rdocker-compose 常用操作命令 查看容器 docker-compose -f docker-compose.yml ps 关闭/启动/重启某个容器 docker-compose -f docker-compose.yml stop/start/restart \u003c服务名称\u003e // 不加服务名则会操作所有容器 查看容器日志 docker-compose -f docker-compose.yml logs -f // 查看所有容器日志 docker-compose -f docker-compose.yml logs -f \u003c服务名\u003e // 查看指定容器日志 docker-compose -f docker-compose.yml logs -f \u003e\u003e app.log \u0026 // 把日志输出到文件 重新构建镜像并启动 docker-compose -f docker-compose.yml up --build -d 重新构建 cokder-compose.yml 有变化的容器并启动 docker-compose -f docker-compose.yml up --fore-recreate -d 停掉容器并删除 docker-compose -f docker-compose.yml down ","date":"2023-06-28","objectID":"/posts/docker-compose/:1:4","tags":["docker"],"title":"Docker-Compose 容器编排","uri":"/posts/docker-compose/"},{"categories":["devops"],"content":"\rprometheus + grafana 搭建监控","date":"2023-06-28","objectID":"/posts/docker-compose/:2:0","tags":["docker"],"title":"Docker-Compose 容器编排","uri":"/posts/docker-compose/"},{"categories":["devops"],"content":"\r安装 redis-exporter docker run -d \\ --name redis_exporter \\ -p 9121:9121 \\ -v /etc/localtime:/etc/localtime:ro \\ oliver006/redis_exporter \\ --redis.addr redis://192.168.202.101:6379 \\ # redis 地址 ","date":"2023-06-28","objectID":"/posts/docker-compose/:2:1","tags":["docker"],"title":"Docker-Compose 容器编排","uri":"/posts/docker-compose/"},{"categories":["devops"],"content":"\r安装 prometheus cd /opt mkdir prometheus cd /opt/prometheus vi prometheus.yml prometheus.yml global: scrape_interval: 5s scrape_configs: - job_name: prometheus static_configs: - targets: ['localhost:9090'] labels: instance: prometheus - job_name: redis static_configs: - targets: ['192.168.202.101:9121'] # redis_exporter 地址 labels: instance: redis docker 启动 prometheus docker run -d \\ -p 9090:9090 \\ --name=prometheus \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml \\ prom/prometheus ","date":"2023-06-28","objectID":"/posts/docker-compose/:2:2","tags":["docker"],"title":"Docker-Compose 容器编排","uri":"/posts/docker-compose/"},{"categories":["devops"],"content":"\r安装grafana cd /opt mkdir grafana-storage chmod 777 grafana-storage # grafana docker run -d \\ -p 3000:3000 \\ --name=grafana \\ -v /opt/grafana-storage:/var/lib/grafana \\ -v /etc/localtime:/etc/localtime:ro \\ grafana/grafana docker run -d --name node_exporter \\ -p 9100:9100 \\ --restart=always \\ --net=\"host\" \\ --pid=\"host\" \\ -v \"/proc:/host/proc:ro\" \\ -v \"/sys:/host/sys:ro\" \\ -v \"/:/rootfs:ro\" \\ prom/node-exporter \\ --path.procfs=/host/proc \\ --path.rootfs=/rootfs \\ --path.sysfs=/host/sys \\ --collector.filesystem.ignored-mount-points='^/(sys|proc|dev|host|etc)($$|/)' ","date":"2023-06-28","objectID":"/posts/docker-compose/:2:3","tags":["docker"],"title":"Docker-Compose 容器编排","uri":"/posts/docker-compose/"},{"categories":["other"],"content":"\rmac 软件包管理工具 brew install #[包名] 安装包。 brew uninstall #[包名] 卸载包。 brew search #[包名] 查询包。 brew list #列出已安装的软件。 brew update #更新brew。 - brew outdated #查看可更新的包。 brew upgrade #(更新所有) 更新所有包。 brew upgrade [包名] #更新置顶包。 brew cleanup #清理所有包的旧版本。 brew cleanup [包名] #清理指定包的旧版本。 brew cleanup -n #查看可清理的旧版本包，不执行实际操作。 brew home #用浏览器打开brew的官方网站。 brew info [包名] #显示软件信息。 brew deps [包名] #显示包依赖。 brew install --cask [包名] #安装桌面软件。 ","date":"2023-06-28","objectID":"/posts/homebrew/:1:0","tags":["other"],"title":"Homebrew 常用命令","uri":"/posts/homebrew/"},{"categories":["other"],"content":"\r服务管理 brew services list # 查询服务列表和状态 brew services run mysql # 启动mysql 服务 brew services start mysql # 启动 mysql 服务，并注册开机自启 brew services stop mysql # 停止 mysql 服务，并取消开机自启 brew services restart mysql # 重启 mysql 服务，并注册开机自启 brew services cleanup # 清除已卸载应用的无用配置 ","date":"2023-06-28","objectID":"/posts/homebrew/:2:0","tags":["other"],"title":"Homebrew 常用命令","uri":"/posts/homebrew/"},{"categories":["other"],"content":"\r环境变量文件存储位置 \u003e /etc/paths （全局建议修改这个文件 ） \u003e /etc/profile （建议不修改这个文件 ） \u003e /etc/bashrc （一般在这个文件中添加系统级环境变量） \u003e ~/.profile 文件为系统的每个用户设置环境信息,当用户第一次登录时,该文件被执行.并从/etc/profile.d目录的配置文件中搜集shell的设置 \u003e ~/.bashrc 每一个运行bash shell的用户执行此文件.当bash shell被打开时,该文件被读取 \u003e ~/.bash_profile 该文件包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该文件被读取 ","date":"2023-06-28","objectID":"/posts/modify-env/:1:0","tags":["mac"],"title":"Mac 修改环境变量","uri":"/posts/modify-env/"},{"categories":["other"],"content":"\r修改完让其生效 source ~/.bash_profile ","date":"2023-06-28","objectID":"/posts/modify-env/:2:0","tags":["mac"],"title":"Mac 修改环境变量","uri":"/posts/modify-env/"},{"categories":["linux"],"content":"\rshell 常用命令 more /etc/shells # 查查有多少个shell echo $SHELL # 查看当前shell chsh -s /bin/bash # 切换到 bash chsh -s /bin/zsh # 切换到zsh chsh -s /usr/local/bin/fish #切换到fish ","date":"2023-06-28","objectID":"/posts/shell-change/:1:0","tags":["mac","shell"],"title":"Mac 更换控制台 shell","uri":"/posts/shell-change/"},{"categories":null,"content":"\r自我介绍 Java 程序员，十年工作经验，擅长微服务系统构建。 联系邮箱：telzhou618@qq.com 个人主页：https://telzhou618.github.io Github：https://github.com/telzhou618 Gitee：https://gitee.com/zhougaojun ","date":"2023-06-27","objectID":"/about/:1:0","tags":null,"title":"About me","uri":"/about/"},{"categories":null,"content":"\r开源贡献 【框架】手写各种框架源码，https://github.com/telzhou618/java-source-code 【框架】管理后台框，https://gitee.com/zhougaojun/KangarooAdmin 【框架】SpringCloud商城框架，https://github.com/telzhou618/springcloud-mall 【框架】Dubbo 商城框架，https://github.com/telzhou618/vacomall 【文章】一文搞懂RocketMQ， https://telzhou618.github.io/post/rocketmq 【文章】MySQL优化及索引设计规范，https://telzhou618.github.io/post/mysql-review 【文章】SpringAOP从入门到源码解析，https://telzhou618.github.io/post/spring-aop ","date":"2023-06-27","objectID":"/about/:2:0","tags":null,"title":"About me","uri":"/about/"},{"categories":null,"content":"\r兴趣爱好 游泳 书法 ","date":"2023-06-27","objectID":"/about/:3:0","tags":null,"title":"About me","uri":"/about/"},{"categories":["linux"],"content":"\rssh 免密登录配置 生成公钥秘钥对 ssh-keygen -t rsa -b 4096 -C \"telzhou618@qq.com\" 在文件在 ~/.ssh 文件夹下，会生成两个文件id_rsa是私钥，id_rsa.pub是公钥。 2. 使用ssh复制公钥到目标服务器，会存储在目标服务的 authorized_keys文件中，下次登录目标服务不再需要密码。 ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.6 ","date":"2023-05-02","objectID":"/posts/f460746/:1:0","tags":["centos","ssh"],"title":"Centos ssh 免密登录配置","uri":"/posts/f460746/"},{"categories":["devops"],"content":"\r安装最新 git安装在最新yum源,ius源官方：https://ius.io/setup yum install \\ https://repo.ius.io/ius-release-el7.rpm \\ https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm 安装 git yum remove git yum install -y git236 git --version ","date":"2023-04-23","objectID":"/posts/ssh-key/:1:0","tags":["ssh","git"],"title":"SSK key 免密访问 gitlab 配置","uri":"/posts/ssh-key/"},{"categories":["devops"],"content":"\rssh-gen 命令举个例子，生成算法为rsa，长度为4096字节的秘钥对。 ssh-keygen -t rsa -b 4096 -C \"telzhou618@qq.com\" 参数说明： ","date":"2023-04-23","objectID":"/posts/ssh-key/:2:0","tags":["ssh","git"],"title":"SSK key 免密访问 gitlab 配置","uri":"/posts/ssh-key/"},{"categories":["devops"],"content":"\rlinux 生成本地秘钥生成 rsa 算法公钥和秘钥,运行ssk-keygen 一路回车，注意，如果秘钥已存在会覆盖 ssh-keygen -t rsa -b 4096 -C \"telzhou618@qq.com\" -t ：指定算法类型 -b ：指定秘钥长度 -C ：大C，注释说明 -f ：保存秘钥的文件名 复制公钥（id_rsa.pub）文件中的内容填写在gitlab中。 然后再 git clone, 不需要再输入用户名和密码。 ","date":"2023-04-23","objectID":"/posts/ssh-key/:3:0","tags":["ssh","git"],"title":"SSK key 免密访问 gitlab 配置","uri":"/posts/ssh-key/"},{"categories":["devops"],"content":"\rwindows 配置生成秘钥方法和Linux类似 ssh-keygen -t rsa -b 4096 -C \"telzhou618@qq.com\" cat /c/Users/Administrator/.ssh/id_rsa.pub 设置到 gitlab, 和前面linux一样。 ","date":"2023-04-23","objectID":"/posts/ssh-key/:4:0","tags":["ssh","git"],"title":"SSK key 免密访问 gitlab 配置","uri":"/posts/ssh-key/"},{"categories":["devops"],"content":"\r本地多秘钥生成比如要同时免密访问github和gitlab仓库，就需要生成两组秘钥，入校所示： 为gitlab生成秘钥,-f指定文件名称 ssh-keygen -t rsa -C 'yourEmail@xx.com' -f ~/.ssh/gitlab-rsa 为github生成秘钥 ssh-keygen -t rsa -C 'yourEmail2@xx.com' -f ~/.ssh/github-rsa 在~/.ssh目录下创建名为config的文件，用于配置不同host的不同ssk key。 touch ~/.ssh/config 内容如下所示 # gitlab Host gitlab.com HostName gitlab.com PreferredAuthentications publickey IdentityFile ~/.ssh/gitlab_id-rsa # github Host github.com HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/github_id-rsa # 配置文件参数 # Host : Host可以看作是一个你要识别的模式，对识别的模式，进行配置对应的的主机名和ssh文件 # HostName : 要登录主机的主机名 # User : 登录名 # IdentityFile : 指明上面User对应的identityFile路径 分别在github 和 gitlab 配置公钥信息, 这样就可以再不同平台的代码仓库免密克隆项目了。 ","date":"2023-04-23","objectID":"/posts/ssh-key/:5:0","tags":["ssh","git"],"title":"SSK key 免密访问 gitlab 配置","uri":"/posts/ssh-key/"},{"categories":["devops"],"content":"\rdocker 安装卸载旧的docker sudo yum remove -y docker* 安装 yum-utils yum install -y yum-utils 设置docker 源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum makecache fast 查看docker所有版本 yum list docker-ce --showduplicates | sort -r 安装docker yum install -y docker-ce-3:19.03.9-3.el7.x86_64 设置为开机启动 systemctl start docker systemctl enable docker 验证是否成功 dokcer version 修改阿里云 docker 镜像源加速，https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u003c\u003c-'EOF' { \"registry-mirrors\": [\"https://0qnvd2nu.mirror.aliyuncs.com\"] } EOF sudo systemctl daemon-reload sudo systemctl restart docker ","date":"2023-04-11","objectID":"/posts/docker-install/:1:0","tags":["docker"],"title":"CentOS 安装 Docker","uri":"/posts/docker-install/"},{"categories":["devops"],"content":"\r部署 Tomcat拉取镜像 docker pull tomcat:7.0.59 查看镜像 docker images 启动容器 docker run -d -p 8080:8080 --name my-tomcat tomcat:7.0.59 访问测试, http://192.168.1.5:8080 ","date":"2023-04-11","objectID":"/posts/docker-install/:2:0","tags":["docker"],"title":"CentOS 安装 Docker","uri":"/posts/docker-install/"},{"categories":["devops"],"content":"\r常用命令当然！以下是从提供的 shell 脚本中提取出的各个 Docker 命令： 拉取 Docker 镜像: docker pull java:8 查看本地 Docker 镜像: docker images 删除本地 Docker 镜像: docker rmi java 删除所有本地 Docker 镜像: docker rmi $(docker images -q) 运行 Docker 容器: docker run -d -p 8080:8080 --name my-tomcat tomcat:7.0.59 查看正在运行的 Docker 容器: docker ps 查看所有 Docker 容器（包括停止的）: docker ps -a 停止 Docker 容器: docker stop 7c5721a009cc 强制停止 Docker 容器: docker kill 7c5721a009cc 启动 Docker 容器: docker start 7c5721a009cc 查看 Docker 容器内部信息: docker inspect 7c5721a009cc 查看 Docker 容器日志: docker container logs 7c5721a009cc 监控 Docker 容器日志: docker container logs 7c5721a009cc -f 查看 Docker 容器内进程: docker top 7c5721a009cc 复制文件到/从 Docker 容器: docker cp 7c5721a009cc:/etc/nginx/nginx.conf /mydata/nginx # 从容器复制到主机 docker cp /mydata/nginx/nginx.conf 7c5721a009cc:/etc/nginx/ # 从主机复制到容器 进入 Docker 容器 Shell: docker exec -it 7c5721a009cc /bin/bash 删除 Docker 容器: docker rm 7c5721a009cc # 只能删除已停止的容器 docker rm -f 7c5721a009cc # 可以强制删除正在运行的容器 强制删除所有 Docker 容器: docker rm -f $(docker ps -a -q) 从 Dockerfile 构建 Docker 镜像: docker build -t demo:1.0.0 . 查看容器的CPU、内存 docker stats 这些命令用于在命令行界面有效地管理 Docker 容器、镜像及相关操作。每个命令都在 Docker 生态系统中具有特定的用途。 ","date":"2023-04-11","objectID":"/posts/docker-install/:3:0","tags":["docker"],"title":"CentOS 安装 Docker","uri":"/posts/docker-install/"},{"categories":["devops"],"content":"\rDockerfile 编写 构建 spring-boot 项目镜像 From java:8 ADD target/demo.jar /app.jar EXPOSE 8080 ENTRYPOINT java ${JAVA_OPTS} -jar /app.jar ","date":"2023-04-11","objectID":"/posts/docker-install/:4:0","tags":["docker"],"title":"CentOS 安装 Docker","uri":"/posts/docker-install/"},{"categories":["中间件"],"content":"\r安装最新版 Nginx配置 EPEL 源,否则安装的是旧的或找不到Nginx源 sudo yum install -y epel-release 安装Nginx sudo yum install -y nginx 启动 Nginx systemctl start nginx 访问: http://localhost, Nginx 默认端口是80，可以省略 ","date":"2023-03-23","objectID":"/posts/nginx/:1:0","tags":["nginx"],"title":"CentOS 安装和使用最新版 Nginx","uri":"/posts/nginx/"},{"categories":["中间件"],"content":"\rNginx 常用命令 # 检查 nginx 配置是否正确 nginx -t # 停止服务 nginx -s stop # 退出服务 nginx -s quit # 重启服务 nginx -s reload ","date":"2023-03-23","objectID":"/posts/nginx/:2:0","tags":["nginx"],"title":"CentOS 安装和使用最新版 Nginx","uri":"/posts/nginx/"},{"categories":["中间件"],"content":"\r用 systemctl 操作1.启动 Nginx systemctl start nginx 2.停止 Nginx systemctl stop nginx 3.重启 Nginx systemctl restart nginx 4.查看 Nginx 状态 systemctl status nginx 5.启用开机启动 Nginx systemctl enable nginx 6.禁用开机启动 Nginx systemctl disable nginx ","date":"2023-03-23","objectID":"/posts/nginx/:3:0","tags":["nginx"],"title":"CentOS 安装和使用最新版 Nginx","uri":"/posts/nginx/"},{"categories":["中间件"],"content":"\r配置域名转发cd 到 /etc/nginx/conf.d 目录,创建配置文件，创建后缀为conf的文件,这里以gitlab服务为例，假如 gitlab 的IP端口为 http://192.168.1.4:10008 cd /etc/nginx/conf.d vi www.gitlab.net.conf 键入以下配置 server { listen 80; server_name www.gitlab.net; location / { proxy_pass http://192.168.1.4:10008; } } 保存,重启 Nginx # 测试配置 nginx -t # 无报错重启 nginx -s reload 修改本机 hosts 测试 192.168.1.4 www.gitlab.net 访问 www.gitlab.net 测试,ok! ","date":"2023-03-23","objectID":"/posts/nginx/:4:0","tags":["nginx"],"title":"CentOS 安装和使用最新版 Nginx","uri":"/posts/nginx/"},{"categories":["java"],"content":"Java SPI（Service Provider Interface）是Java平台提供的一种机制，用于实现服务发现和扩展的功能。它允许开发人员定义一组接口，然后允许其他开发人员在应用程序中提供不同的实现。 ","date":"2023-03-05","objectID":"/posts/java-spi/:0:0","tags":["java","spi"],"title":"Java SPI 应用","uri":"/posts/java-spi/"},{"categories":["java"],"content":"\r举个例子某应该需要外部提供数据，具体使用USB接口传输还是Typec接口传输并不关心，官方只需定义接口，USB厂商和typec厂商各自去实现接口即可，具体如下。 创建 maven 项目 data-trans-api 为接口项目, xml 配置如下 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cparent\u003e \u003cartifactId\u003espi-demo\u003c/artifactId\u003e \u003cgroupId\u003eorg.example\u003c/groupId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/parent\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cartifactId\u003edata-trans-api\u003c/artifactId\u003e \u003cproperties\u003e \u003cmaven.compiler.source\u003e8\u003c/maven.compiler.source\u003e \u003cmaven.compiler.target\u003e8\u003c/maven.compiler.target\u003e \u003c/properties\u003e \u003c/project\u003e 定义接口 package com.example; public interface DataProvider { String getData(); } ","date":"2023-03-05","objectID":"/posts/java-spi/:1:0","tags":["java","spi"],"title":"Java SPI 应用","uri":"/posts/java-spi/"},{"categories":["java"],"content":"\rusb实现项目创建一个名称为 usb 的 maven 项目，引入前面提供的 data-trans-api 包，完整的XML如下 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cparent\u003e \u003cartifactId\u003espi-demo\u003c/artifactId\u003e \u003cgroupId\u003eorg.example\u003c/groupId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/parent\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cartifactId\u003eusb\u003c/artifactId\u003e \u003cproperties\u003e \u003cmaven.compiler.source\u003e8\u003c/maven.compiler.source\u003e \u003cmaven.compiler.target\u003e8\u003c/maven.compiler.target\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.example\u003c/groupId\u003e \u003cartifactId\u003edata-trans-api\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e 创建类 UsbDataProvider，实现 DataProvider 接口，编写提供数据的逻辑，这里简单返回一个字符串。 package com.example; public class UsbDataProvider implements DataProvider { @Override public String getData() { return \"从Usb接口获取数据...\"; } } 在 resources 目录下依次创建目录 META-INF/services/ 在 services 目录创建配置文件，名称为接口类的完全限定名，这里是 com.example.DataProvider 在文件内添加实现类的完全限定名，这里是 com.example.UsbDataProvider, 如果有多个实现，换行写入，每个实现类单独一行, 完整的结果如下 文件路径：resource/META-INF/services/com.example.DataProvider，文件内容如下 com.example.UsbDataProvider ","date":"2023-03-05","objectID":"/posts/java-spi/:1:1","tags":["java","spi"],"title":"Java SPI 应用","uri":"/posts/java-spi/"},{"categories":["java"],"content":"\r使用 demo创建 maven 项目，名称为 demo, 引入前面的接口包和实现包 \u003cdependency\u003e \u003cgroupId\u003eorg.example\u003c/groupId\u003e \u003cartifactId\u003edata-trans-api\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.example\u003c/groupId\u003e \u003cartifactId\u003eusb\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e 编写如下代码，ServiceLoader 是 jdk 提供的获取spi对象的方法 public class Main { public static void main(String[] args) { ServiceLoader\u003cDataProvider\u003e load = ServiceLoader.load(DataProvider.class); Iterator\u003cDataProvider\u003e iterator = load.iterator(); while (iterator.hasNext()) { DataProvider provider = iterator.next(); String data = provider.getData(); System.out.println(data); } } } 运行结果 从Usb接口获取数据... 可以看到拿到了 UsbDataProvider 对象实例，并且调用 getData方法成功获取到数据。 原理：ServiceLoader 会扫描所有jar包的 DataProvider 配置文件，加载实现类，并通过反射实例化。 如果有一天要用Typec获取数据，在不修改代码的情况下如何实现？ ","date":"2023-03-05","objectID":"/posts/java-spi/:1:2","tags":["java","spi"],"title":"Java SPI 应用","uri":"/posts/java-spi/"},{"categories":["java"],"content":"\rtypc实现创建名为 typec 的 maven 项目，引入接口包 data-trans-api, xml 如下 \u003cdependency\u003e \u003cgroupId\u003eorg.example\u003c/groupId\u003e \u003cartifactId\u003edata-trans-api\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e 创建类 TypecDataProvider，实现 DataProvider 接口，编写提供数据的逻辑 package com.example; public class TypecDataProvider implements DataProvider { @Override public String getData() { return \"从Typec接口获取数据...\"; } } 同样创建配置文件 resource/META-INF/services/com.example.DataProvider，内容为TypecDataProvider 的包完全限定名，如下 com.example.TypecDataProvider 编译打包 将前面 demo 中的 usb 依赖改成新写的 typec 包 \u003cdependency\u003e \u003cgroupId\u003eorg.example\u003c/groupId\u003e \u003cartifactId\u003edata-trans-api\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.example\u003c/groupId\u003e \u003cartifactId\u003etypec\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e 再次运行 main 方法 从Typc接口获取数据... 做到了不修改代码，只更换jar包的方式满足项目的扩展。 如果同时引入 usb 和 typec，再次运行 demo 从Usb接口获取数据... 从typc接口获取数据... 两个都成功，spi 允许多实现，通过 ServiceLoader#load 方法获取到的是一个集合 Iterator 对象。 ","date":"2023-03-05","objectID":"/posts/java-spi/:1:3","tags":["java","spi"],"title":"Java SPI 应用","uri":"/posts/java-spi/"},{"categories":["java"],"content":"\r优点 方便扩展，松耦合 ","date":"2023-03-05","objectID":"/posts/java-spi/:2:0","tags":["java","spi"],"title":"Java SPI 应用","uri":"/posts/java-spi/"},{"categories":["java"],"content":"\r缺点 不能懒加载，会加载所有的实现类，只能通过 Iterator 迭代才能找到想要的类。 ","date":"2023-03-05","objectID":"/posts/java-spi/:3:0","tags":["java","spi"],"title":"Java SPI 应用","uri":"/posts/java-spi/"},{"categories":["java"],"content":" 把创建耗时的对象提前创建好，放在池中管理，需要时直接取，用完归还，可以做对象复用，避免用时创建慢且提高系统的效率。 比如数据库连接、网络连接、大对象创建等都可以池化处理。 ","date":"2022-06-28","objectID":"/posts/commons-pool2/:0:0","tags":["java"],"title":"Commons-pool2 应用与实战","uri":"/posts/commons-pool2/"},{"categories":["java"],"content":"\rcommons-pool的优点对象复用，减少创建开销。对于数据库的连接池可以减少创建连接带来的开销，连接用完归还可以给其他线程复用。 ","date":"2022-06-28","objectID":"/posts/commons-pool2/:1:0","tags":["java"],"title":"Commons-pool2 应用与实战","uri":"/posts/commons-pool2/"},{"categories":["java"],"content":"\r三个核心对象","date":"2022-06-28","objectID":"/posts/commons-pool2/:2:0","tags":["java"],"title":"Commons-pool2 应用与实战","uri":"/posts/commons-pool2/"},{"categories":["java"],"content":"\rGenericObjectPool连接池对象，继承自BaseGenericObjectPool 用双端阻塞队列LinkedBlockingDeque保存空闲链接，用ConcurrentHashMap保存所有的链接。 构造方法 public GenericKeyedObjectPool(KeyedPooledObjectFactory\u003cK, T\u003e factory, GenericKeyedObjectPoolConfig\u003cT\u003e config) { //... } GenericObjectPoolConfig和PooledObjectFactory是创建对象池所必须的两个对象，稍后详细说明。 重要方法 borrowObject() 从连接池中取对象。 returnObject() 归还对象。 ","date":"2022-06-28","objectID":"/posts/commons-pool2/:2:1","tags":["java"],"title":"Commons-pool2 应用与实战","uri":"/posts/commons-pool2/"},{"categories":["java"],"content":"\rPooledObjectFactory生产对象的工厂，有如下一些方法： makeObject() 生产一个对象 连接池初始化,驱逐过期连接后小于最小连接数，所有连接被占用且总连接数小于最大连接时调用。 destroyObject() 销毁一个对象 validateObject() 校验一个对象 activateObject() 重新激活一个对象 passivateObject() 钝化一个对象 没有特别要求可用PooledObjectFactory 的子类 BasePooledObjectFactory作为生产对象的工厂更简洁。 create() 生产对象的逻辑 wrap() 将对象包装成 PooledObject，必须支持多线程。 ","date":"2022-06-28","objectID":"/posts/commons-pool2/:2:2","tags":["java"],"title":"Commons-pool2 应用与实战","uri":"/posts/commons-pool2/"},{"categories":["java"],"content":"\rGenericObjectPoolConfig连接池配置对象，继承自BaseObjectPoolConfig 。 常用参数： maxTotal：对象池中管理的最多对象个数。默认值是8。 maxIdle：对象池中最大的空闲对象个数。默认值是8。 minIdle：对象池中最小的空闲对象个数。默认值是0。 ","date":"2022-06-28","objectID":"/posts/commons-pool2/:2:3","tags":["java"],"title":"Commons-pool2 应用与实战","uri":"/posts/commons-pool2/"},{"categories":["java"],"content":"\r实例代码创建一个简单的连接对象，模拟数据库连接对象。 /** * 连接对象 */ @Getter @Setter @ToString static class Connection { private Integer id; public Connection(Integer id) { this.id = id; } } 生产连接对象的工厂,需要继承 BasePooledObjectFactory 类 /** * 对象生产工厂 */ static class ConnectionObjectFactory extends BasePooledObjectFactory\u003cConnection\u003e { private AtomicInteger atomicInteger = new AtomicInteger(1); @Override public Connection create() throws Exception { // 模拟连接对象的创建过程 return new Connection(atomicInteger.getAndIncrement()); } @Override public PooledObject\u003cConnection\u003e wrap(Connection connection) { // 将连接包装成PooledObject对象，要线程安全 return new DefaultPooledObject\u003c\u003e(connection); } } 自定义配置对象，继承GenericObjectPoolConfig，如不需要特殊配置可直接用GenericObjectPoolConfig。 /** * 连接池配置信息 */ static class ConnectionPoolConfig extends GenericObjectPoolConfig { public ConnectionPoolConfig() { setTestWhileIdle(true); setMinEvictableIdleTimeMillis(60000); setTimeBetweenEvictionRunsMillis(30000); setNumTestsPerEvictionRun(-1); } } 使用 public static void main(String[] args) throws Exception { // 实例化对象生产工厂 ConnectionObjectFactory factory = new ConnectionObjectFactory(); // 实例化连接池配置信息 ConnectionPoolConfig config = new ConnectionPoolConfig(); config.setMaxTotal(5); config.setMaxWaitMillis(1000); // 实例化连接池 GenericObjectPool\u003cConnection\u003e pool = new GenericObjectPool\u003c\u003e(factory, config); for (int i = 0; i \u003c 10; i++) { // 获取连接 Connection connection = pool.borrowObject(); System.out.println(connection); // 归还连接 // pool.returnObject(connection); } } 先注释归还对象的方法 pool.returnObject(connection)，执行结果如下，只能取到5个连接对象，因为设置的最大连接数是5。 在打开 pool.returnObject(connection) 代码，每次获取的第一个连接，说明归还了对象可以接着用，实现连接对象复用。 ","date":"2022-06-28","objectID":"/posts/commons-pool2/:3:0","tags":["java"],"title":"Commons-pool2 应用与实战","uri":"/posts/commons-pool2/"},{"categories":["java"],"content":"\rRedis客户端jedis的的连接池典型应用","date":"2022-06-28","objectID":"/posts/commons-pool2/:4:0","tags":["java"],"title":"Commons-pool2 应用与实战","uri":"/posts/commons-pool2/"},{"categories":["java"],"content":"\rJedisPoolConfig配置类源码, 只修改了默认的几个参数，其余继承GenericObjectPoolConfig public class JedisPoolConfig extends GenericObjectPoolConfig { public JedisPoolConfig() { // defaults to make your life with connection pool easier :) setTestWhileIdle(true); setMinEvictableIdleTimeMillis(60000); setTimeBetweenEvictionRunsMillis(30000); setNumTestsPerEvictionRun(-1); } } ","date":"2022-06-28","objectID":"/posts/commons-pool2/:4:1","tags":["java"],"title":"Commons-pool2 应用与实战","uri":"/posts/commons-pool2/"},{"categories":["java"],"content":"\rJedisFactory生成jedis对象的工厂，继承commons-pool2的 PooledObjectFactory，重点实现了makeObject()生产jedis对象。 class JedisFactory implements PooledObjectFactory\u003cJedis\u003e { @Override public PooledObject\u003cJedis\u003e makeObject() throws Exception { final HostAndPort hostAndPort = this.hostAndPort.get(); final Jedis jedis = new Jedis(hostAndPort.getHost(), hostAndPort.getPort(), connectionTimeout, soTimeout, ssl, sslSocketFactory, sslParameters, hostnameVerifier); try { jedis.connect(); if (null != this.password) { jedis.auth(this.password); } if (database != 0) { jedis.select(database); } if (clientName != null) { jedis.clientSetname(clientName); } } catch (JedisException je) { jedis.close(); throw je; } return new DefaultPooledObject\u003cJedis\u003e(jedis); } } ","date":"2022-06-28","objectID":"/posts/commons-pool2/:4:2","tags":["java"],"title":"Commons-pool2 应用与实战","uri":"/posts/commons-pool2/"},{"categories":["java"],"content":"\rJedisPool实例化jedis连接池，初始化连接对象。 public class JedisPool extends Pool\u003cJedis\u003e { protected GenericObjectPool\u003cT\u003e internalPool; // 实例化连接池 参数省略... public JedisPool(hostname,port,...){ this.internalPool = new GenericObjectPool\u003cJedis\u003e(new JedisFactory(host, Protocol.DEFAULT_PORT, Protocol.DEFAULT_TIMEOUT, Protocol.DEFAULT_TIMEOUT, null, Protocol.DEFAULT_DATABASE, null, false, null, null, null), new GenericObjectPoolConfig()); } @Override public Jedis getResource() { //获取jedis对象 } @Override public void returnResource(final Jedis resource) { //归还jedis对象 } } 最终调用GenericObjectPool作为对象池管理jedis对象，传入JedisFactory工厂和默认的配置对象GenericObjectPoolConfig，配置类可以使用redis自定义的JedisPoolConfig对象。 Jedis客户端通过依赖commons-pool2实现连接池，使得Jedis本身只关注自身和Redis服务的交互上，不需要关系连接怎么创建、销毁等。 ","date":"2022-06-28","objectID":"/posts/commons-pool2/:4:3","tags":["java"],"title":"Commons-pool2 应用与实战","uri":"/posts/commons-pool2/"},{"categories":["java"],"content":"\r调试按钮说明 ","date":"2022-06-28","objectID":"/posts/java8-debug/:1:0","tags":["java","java8"],"title":"JAVA8 debug 技巧","uri":"/posts/java8-debug/"},{"categories":["java"],"content":"\rStream 调试实例代码： // 1.Stream 调试 List\u003cInteger\u003e list1 = Lists.newArrayList(1, 5, 3, 2, 4); List\u003cInteger\u003e list2 = list1.stream() .filter(o -\u003e o \u003e 2) .sorted() .collect(Collectors.toList()); System.out.println(list2); 在 stram() 处设置断点，debug 运行。 可以看到Debug视图中 Trace Current Steam Chain 图标会点亮。 点击该图标弹出 Stream Trace 视图。可以看到 filter、sorted、collect 每一个方法执行之后的结果。 ok，成功。 ","date":"2022-06-28","objectID":"/posts/java8-debug/:2:0","tags":["java","java8"],"title":"JAVA8 debug 技巧","uri":"/posts/java8-debug/"},{"categories":["java"],"content":"\rOptional 调试实例代码： // 2.Optional 调试 User user = new User() .setId(1) .setName(\"tom\") .setArea(new Area().setProvince(\"beijing\")); String province = Optional.ofNullable(user) .map(User::getArea) .map(Area::getProvince) .orElse(\"未知\"); System.out.println(province); 在 Optaionl 处加断点，debug 运行，可以看到 Evaluate Express 图标。 点击该图标弹出 Evaluate 视图，输入需要调试的代码，点击右下角 Evaluate 图标，可以看到执行结果。 注：Optaionl 不像 Stream 那样，有专门的调试器，他需要借助 Evaluate Express 视图完成调试。 ","date":"2022-06-28","objectID":"/posts/java8-debug/:3:0","tags":["java","java8"],"title":"JAVA8 debug 技巧","uri":"/posts/java8-debug/"},{"categories":["java"],"content":"\r条件断点实例代码： // 3.条件断点, 循环 List\u003cInteger\u003e integerList = Lists.newArrayList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10); for (Integer x : integerList) { System.out.print(x); } 有时候在循环中调试时，我们希望只关心我们需要关心的那个对象，但是一次循环记录有很多，每一个都跟一遍很是麻烦，那么条件断点就可以上场了。 在需要的地方加断点，在断点上右键弹出条件断点视图，输入条件表达式，点击 Done。 然后 debug 运行, 只有当 x 的值为 5 的时候才会停住，进入断点。 ","date":"2022-06-28","objectID":"/posts/java8-debug/:4:0","tags":["java","java8"],"title":"JAVA8 debug 技巧","uri":"/posts/java8-debug/"},{"categories":["java"],"content":"\r多线程调试实例代码： // 4.多线程调试 new Thread(() -\u003e { System.out.println(\"线程1执行\"); }, \"线程1\").start(); new Thread(() -\u003e { System.out.println(\"线程2执行\"); }, \"线程2\").start(); System.out.println(\"主线程\"); 线程的执行时间是有系统分配，开发人员无法控制，但是通过Idea 专用的线程调试功能可以很好的选择要执行的线程代码，达到调试代码的目的。 先在线程内设置断点，在断点上右键选择 Thread 类型。 然后 debug 运行项目，在 Debug 的 Frames 视图可以方便的选择要执行的线程，选择后可继续一步步调试代码。 ","date":"2022-06-28","objectID":"/posts/java8-debug/:5:0","tags":["java","java8"],"title":"JAVA8 debug 技巧","uri":"/posts/java8-debug/"},{"categories":["java"],"content":"\r方法回退实例代码： public static void method1() { System.out.println(\"method1\"); method2(); } public static void method2() { System.out.println(\"method2\"); method3(); } public static void method3() { System.out.println(\"method3\"); } public static void main(String[] args) { method1(); } 通过工具栏里的按钮可回退到上一步。 通过选中方法右键选择 Drop Frame 可回退到指定的方法。 如：阅读Spring IOC 启动流程源码时，方法调用都很深，想退回来再看看上一步做了啥，用方法回退很方便。 但是对于修改了共享数据的方法，如果回退再执行一次，可能产生异常数据。 ","date":"2022-06-28","objectID":"/posts/java8-debug/:6:0","tags":["java","java8"],"title":"JAVA8 debug 技巧","uri":"/posts/java8-debug/"},{"categories":["java"],"content":"\r强制返回Debug 调试代码时，跟到一个无关痛痒的方法，有时候我们希望提前返回，可以使用下面的方法强制返回一个指定的值。 选择方法右键，选择Fore Return。 会弹出一个窗口，输入要返回的值即可。 ","date":"2022-06-28","objectID":"/posts/java8-debug/:7:0","tags":["java","java8"],"title":"JAVA8 debug 技巧","uri":"/posts/java8-debug/"},{"categories":["java"],"content":"\r热修改变量的值有时候，在Debug 的过程中我们想调整一个参数的值又不想重启项目，可以使用Idea提供的实时修改变量值的功能。 首先在 Variables 视图选要修改的变量，右键选择Set Value。 输入要修改的内容，回车可进行热修改。 ","date":"2022-06-28","objectID":"/posts/java8-debug/:8:0","tags":["java","java8"],"title":"JAVA8 debug 技巧","uri":"/posts/java8-debug/"},{"categories":["java"],"content":"\r开启TLAB开启开启TLAB后,为没个线程预先分配一块内存，创建对象优先使用TLAB内存分配空间。 XX:+UseTLAB # 开启TLAB，默认开启 XX:TLABSize # 设置缓存区大小 ","date":"2022-06-28","objectID":"/posts/jvm/:1:0","tags":["java","jvm"],"title":"JVM 常用参数","uri":"/posts/jvm/"},{"categories":["java"],"content":"\r开启指针压缩在64位平台的HotSpot中使用32位指针，内存使用会多出1.5倍左右，使用较大指针在主内存和缓存之间移动数据， 占用较大宽带，同时GC也会承受较大压力，默认开启！ XX:+UseCompressedOops ","date":"2022-06-28","objectID":"/posts/jvm/:2:0","tags":["java","jvm"],"title":"JVM 常用参数","uri":"/posts/jvm/"},{"categories":["java"],"content":"\r开启逃逸分析jdk1.7 后默认开启。 -XX:+DoEscapeAnalysis ","date":"2022-06-28","objectID":"/posts/jvm/:3:0","tags":["java","jvm"],"title":"JVM 常用参数","uri":"/posts/jvm/"},{"categories":["java"],"content":"\r开启标量替换jdk1.7 后默认开启。 -XX:+EliminateAllocations ","date":"2022-06-28","objectID":"/posts/jvm/:4:0","tags":["java","jvm"],"title":"JVM 常用参数","uri":"/posts/jvm/"},{"categories":["java"],"content":"\rSerial收集器 -XX:+UseSerialGC -XX:+UseSerialOldGC ","date":"2022-06-28","objectID":"/posts/jvm/:5:0","tags":["java","jvm"],"title":"JVM 常用参数","uri":"/posts/jvm/"},{"categories":["java"],"content":"\rParallel Scavenge 收集器 -XX:+UseParallelGC -XX:+UseParallelOldGC ","date":"2022-06-28","objectID":"/posts/jvm/:6:0","tags":["java","jvm"],"title":"JVM 常用参数","uri":"/posts/jvm/"},{"categories":["java"],"content":"\rParNew 收集器 -XX:+UseParNewGC ","date":"2022-06-28","objectID":"/posts/jvm/:7:0","tags":["java","jvm"],"title":"JVM 常用参数","uri":"/posts/jvm/"},{"categories":["java"],"content":"\rCMS收集器 -XX:+UseConcMarkSweepGC -XX:+UseConcMarkSweepGC：启用cms -XX:ConcGCThreads：并发的GC线程数 -XX:+UseCMSCompactAtFullCollection：FullGC之后做压缩整理（减少碎片） -XX:CMSFullGCsBeforeCompaction：多少次FullGC之后压缩一次，默认是0，代表每次FullGC后都会压缩一 次 -XX:CMSInitiatingOccupancyFraction: 当老年代使用达到该比例时会触发FullGC（默认是92，这是百分比） -XX:+UseCMSInitiatingOccupancyOnly：只使用设定的回收阈值(-XX:CMSInitiatingOccupancyFraction设 定的值)，如果不指定，JVM仅在第一次使用设定值，后续则会自动调整 -XX:+CMSScavengeBeforeRemark：在CMS GC前启动一次minor gc，目的在于减少老年代对年轻代的引 用，降低CMS GC的标记阶段时的开销，一般CMS的GC耗时 80%都在标记阶段 -XX:+CMSParallellnitialMarkEnabled：表示在初始标记的时候多线程执行，缩短STW -XX:+CMSParallelRemarkEnabled：在重新标记的时候多线程执行，缩短STW; ","date":"2022-06-28","objectID":"/posts/jvm/:8:0","tags":["java","jvm"],"title":"JVM 常用参数","uri":"/posts/jvm/"},{"categories":["java"],"content":"\rG1收集器 -XX:+UseG1GC:使用G1收集器 -XX:ParallelGCThreads:指定GC工作的线程数量 -XX:G1HeapRegionSize:指定分区大小(1MB~32MB，且必须是2的N次幂)，默认将整堆划分为2048个分区 -XX:MaxGCPauseMillis:目标暂停时间(默认200ms) -XX:G1NewSizePercent:新生代内存初始空间(默认整堆5%) -XX:G1MaxNewSizePercent:新生代内存最大空间 -XX:TargetSurvivorRatio:Survivor区的填充容量(默认50%)，Survivor区域里的一批对象(年龄1+年龄2+年龄n的多个 年龄对象)总和超过了Survivor区域的50%，此时就会把年龄n(含)以上的对象都放入老年代 -XX:MaxTenuringThreshold:最大年龄阈值(默认15) -XX:InitiatingHeapOccupancyPercent:老年代占用空间达到整堆内存阈值(默认45%)，则执行新生代和老年代的混合 收集(MixedGC)，比如我们之前说的堆默认有2048个region，如果有接近1000个region都是老年代的region，则可能 就要触发MixedGC了 -XX:G1MixedGCLiveThresholdPercent(默认85%) region中的存活对象低于这个值时才会回收该region，如果超过这 个值，存活对象过多，回收的的意义不大。 -XX:G1MixedGCCountTarget:在一次回收过程中指定做几次筛选回收(默认8次)，在最后一个筛选回收阶段可以回收一 会，然后暂停回收，恢复系统运行，一会再开始回收，这样可以让系统不至于单次停顿时间过长。 -XX:G1HeapWastePercent(默认5%): gc过程中空出来的region是否充足阈值，在混合回收的时候，对Region回收都 是基于复制算法进行的，都是把要回收的Region里的存活对象放入其他Region，然后这个Region中的垃圾对象全部清 理掉，这样的话在回收过程就会不断空出来新的Region，一旦空闲出来的Region数量达到了堆内存的5%，此时就会立 即停止混合回收，意味着本次混合回收就结束了。 ","date":"2022-06-28","objectID":"/posts/jvm/:9:0","tags":["java","jvm"],"title":"JVM 常用参数","uri":"/posts/jvm/"},{"categories":["java"],"content":"\r普通应用CMS GC 设置 设置内存分配参数, 设置元空间初始大小和最大值相等可加快应用的启动。 设置垃圾收集器, 年轻代用ParNew,老年期用CMS。 打印GC日志，使用滚动方式打印。 -Xms2048M -Xmx2048M -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=92 -XX:+UseCMSInitiatingOccupancyOnly -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M -Xloggc:/tmp/gc-cms-%t.log ","date":"2022-06-28","objectID":"/posts/jvm/:10:0","tags":["java","jvm"],"title":"JVM 常用参数","uri":"/posts/jvm/"},{"categories":["java"],"content":"\rKafka JVM 参数设置LinkedIn 60个broker使用G1收集器 -Xmx6g -Xms6g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80 -XX:+ExplicitGCInvokesConcurrent 60 brokers 50k partitions (replication factor 2) 800k messages/sec in 300 MB/sec inbound, 1 GB/sec+ outbound ","date":"2022-06-28","objectID":"/posts/jvm/:11:0","tags":["java","jvm"],"title":"JVM 常用参数","uri":"/posts/jvm/"},{"categories":["java"],"content":"\rRocketmq 推荐参数设置推荐 8G 内存，使用G1收集器 -Xms8g -Xmx8g -Xmn4g -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:MaxGCPauseMillis -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m -Xloggc:/dev/shm/mq_gc_%p.log ","date":"2022-06-28","objectID":"/posts/jvm/:12:0","tags":["java","jvm"],"title":"JVM 常用参数","uri":"/posts/jvm/"},{"categories":["java"],"content":"一款轻量级的ORM框架。 ","date":"2022-06-28","objectID":"/posts/mybatis/:0:0","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":"\rMyBatis 的优点 封装底层乏味的JDBC操作，让开发中更关注业务。 SQL语句写在XML里和代码分离，便于维护，低耦合。 ","date":"2022-06-28","objectID":"/posts/mybatis/:1:0","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":"\rMyBatis 的缺点 相比全自动的hibernat, SQL编写工作量大。 对数据库SQL依赖比较强，移植性差。 ","date":"2022-06-28","objectID":"/posts/mybatis/:2:0","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":"\rMyBatis 核心组件","date":"2022-06-28","objectID":"/posts/mybatis/:3:0","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":"\rConfiguration配置类，MyBatis启动是会解析全局配置文件全局配置文件 mybatis-config.xml及所有的 XXXMapper.xml文件,解析结果存入Configuration对象中，该对象是单例的，存在会话的上下文，贯穿这个MyBatis的执行过程。 ","date":"2022-06-28","objectID":"/posts/mybatis/:3:1","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":"\rSqlSessionSQL执行的顶层接口，定义了和数据库交互的所有方法，有CRUD及开始事务、提交事务、回滚事务等，有一个默认的实现类 DefaultSqlSession，持有Configuration和Executor对象，SqlSession本身没有做多少有用的事，具体的SQL语句执行委托给了Executor执行。 ","date":"2022-06-28","objectID":"/posts/mybatis/:3:2","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":"\rExecutor执行器，实现了SqlSession定义的SQL操作方法，实现了MyBatis的一级缓存，具体的SQL执行委托给它的下一级 StatementHandler。 ","date":"2022-06-28","objectID":"/posts/mybatis/:3:3","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":"\rStatementHandler真正和数据交互的对象，实现了执行SQL语句，自身持有ParameterHandler和ResultSetHandler对象。 ","date":"2022-06-28","objectID":"/posts/mybatis/:3:4","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":"\rParameterHandler负责参数解析。 ","date":"2022-06-28","objectID":"/posts/mybatis/:3:5","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":"\rResultSetHandler负责处理SQL执行结果。 以上是MyBtais重要的几个组成部件，下面分析一下具体的源码执行流程。 ","date":"2022-06-28","objectID":"/posts/mybatis/:3:6","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":"\rMyBatis 源码分析","date":"2022-06-28","objectID":"/posts/mybatis/:4:0","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":"\r从Configuration配置解析开始实例如下： public static void main(String[] args) throws IOException { String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); Blog blog = session.selectOne(\"com.example.mapper.BlogMapper.selectBlog\", 1); System.out.println(blog); } 从 new SqlSessionFactoryBuilder().build(inputStream) 入手解读配置解析 public SqlSessionFactory build(InputStream inputStream) { return build(inputStream, null, null); } public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) { try { XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties); return build(parser.parse()); } catch (Exception e) { throw ExceptionFactory.wrapException(\"Error building SqlSession.\", e); } finally { //... } } public SqlSessionFactory build(Configuration config) { return new DefaultSqlSessionFactory(config); } 关键方法 parser.parse(), 这里完成了所以配置文件的解析。 // 解析配置 public Configuration parse() { //... 省略 parseConfiguration(parser.evalNode(\"/configuration\")); return configuration; } // 解析配置 private void parseConfiguration(XNode root) { try { //分步骤解析 //issue #117 read properties first //1.properties propertiesElement(root.evalNode(\"properties\")); //2.类型别名 typeAliasesElement(root.evalNode(\"typeAliases\")); //3.插件 pluginElement(root.evalNode(\"plugins\")); //4.对象工厂 objectFactoryElement(root.evalNode(\"objectFactory\")); //5.对象包装工厂 objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\")); //6.设置 settingsElement(root.evalNode(\"settings\")); // read it after objectFactory and objectWrapperFactory issue #631 //7.环境 environmentsElement(root.evalNode(\"environments\")); //8.databaseIdProvider databaseIdProviderElement(root.evalNode(\"databaseIdProvider\")); //9.类型处理器 typeHandlerElement(root.evalNode(\"typeHandlers\")); //10.映射器 mapperElement(root.evalNode(\"mappers\")); } catch (Exception e) { throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e); } } // 解析 properties 节点。 private void propertiesElement(XNode context) throws Exception { if (context != null) { //...省略 parser.setVariables(defaults); configuration.setVariables(defaults); } } parse方法最终调用parseConfiguration解析不同的节点，比如解析properties节点，把解析出来的结果设置到 configuration配置文件中，到此配置解析结束。 ","date":"2022-06-28","objectID":"/posts/mybatis/:4:1","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":"\rselectOne 一条SQL语句是如何执行从获取SqlSession对象开始，前面已经完成了配置解析，下面先看下如何生成SqlSession对象。 先用解析好的Configuration对象生成SqlSessionFactory。 public SqlSessionFactory build(Configuration config) { return new DefaultSqlSessionFactory(config); } 再调用 openSession() 生成 SqlSession public SqlSession openSession() { return openSessionFromDataSource(configuration.getDefaultExecutorType(), null, false); } private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) { Transaction tx = null; try { final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); //通过事务工厂来产生一个事务 tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); //生成一个执行器(事务包含在执行器里) final Executor executor = configuration.newExecutor(tx, execType); //然后产生一个DefaultSqlSession return new DefaultSqlSession(configuration, executor, autoCommit); } catch (Exception e) { //如果打开事务出错，则关闭它 closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\"Error opening session. Cause: \" + e, e); } finally { //最后清空错误上下文 ErrorContext.instance().reset(); } } 使用 DefaultSqlSession 实例化SqlSession对象，这里需要传入执一个执行器对象Executor。 执行器 Executor 实例化，直接Configuration类中的newExecutor方法产生。 //产生执行器 public Executor newExecutor(Transaction transaction, ExecutorType executorType) { executorType = executorType == null ? defaultExecutorType : executorType; //这句再做一下保护,囧,防止粗心大意的人将defaultExecutorType设成null? executorType = executorType == null ? ExecutorType.SIMPLE : executorType; Executor executor; //然后就是简单的3个分支，产生3种执行器BatchExecutor/ReuseExecutor/SimpleExecutor if (ExecutorType.BATCH == executorType) { executor = new BatchExecutor(this, transaction); } else if (ExecutorType.REUSE == executorType) { executor = new ReuseExecutor(this, transaction); } else { executor = new SimpleExecutor(this, transaction); } //如果要求缓存，生成另一种CachingExecutor(默认就是有缓存),装饰者模式,所以默认都是返回CachingExecutor if (cacheEnabled) { executor = new CachingExecutor(executor); } //此处调用插件,通过插件可以改变Executor行为 executor = (Executor) interceptorChain.pluginAll(executor); return executor; } Configuration 中配置默认执行器类型是 ExecutorType.SIMPLE，对应的执行器是SimpleExecutor，由于一级缓存cacheEnabled开关状态默认为true, 最终生成的执行器是 CachingExecutor。 到此，SqlSession对象已经有，下面看一条SQL语句的执行过程。 执行SQL语句 Blog blog = session.selectOne(\"com.example.mapper.BlogMapper.selectBlog\", 1); System.out.println(blog); public class DefaultSqlSession implements SqlSession { // 第一步 @Override public \u003cT\u003e T selectOne(String statement, Object parameter) { List\u003cT\u003e list = this.\u003cT\u003eselectList(statement, parameter); if (list.size() == 1) { return list.get(0); } else if (list.size() \u003e 1) { throw new TooManyResultsException(\"Expected one result (or null) to be returned by selectOne(), but found: \" + list.size()); } else { return null; } } // 第二步 @Override public \u003cE\u003e List\u003cE\u003e selectList(String statement, Object parameter) { return this.selectList(statement, parameter, RowBounds.DEFAULT); } // 第三步 @Override public \u003cE\u003e List\u003cE\u003e selectList(String statement, Object parameter, RowBounds rowBounds) { try { //根据statement id找到对应的MappedStatement MappedStatement ms = configuration.getMappedStatement(statement); //转而用执行器来查询结果,注意这里传入的ResultHandler是null return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); } catch (Exception e) { throw ExceptionFactory.wrapException(\"Error querying database. Cause: \" + e, e); } finally { ErrorContext.instance().reset(); } } } 从上面代码看到，selectOne查查最终委托各Executor对象的query方法来完成。 继续，Executor#query 前面在实例化Executor是我们已经知道最后生成的执行器是CachingExecutor。 public class CachingExecutor implements Executor { // 第一步 @Override public \u003cE\u003e List\u003cE\u003e query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException { BoundSql boundSql = ms.getBoundSql(parameterObject); //query时传入一个cachekey参数 CacheKey key = createCacheKey(ms, parameterObject, rowBo","date":"2022-06-28","objectID":"/posts/mybatis/:4:2","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":"\rMyBatis 源码完整流程图 ","date":"2022-06-28","objectID":"/posts/mybatis/:5:0","tags":["java","mybatis"],"title":"MyBatis 源码解析","uri":"/posts/mybatis/"},{"categories":["java"],"content":" 分布式锁是为了解决跨进程、跨服务应用在高并发场景下造成线程不安全的问题的一种同步加锁的技术方案，在互联网公司有广泛的使用场景，如秒杀项目减库存场景，分布式锁可以保证所有参与者按顺序排队访问某一资源，谁排在最前面谁就有资格获得资源的使用权，排在后面的线程必须等到持有锁的线程释放锁才有可能获取资源使用权，后面的线程要么等待要么放弃。 分布式锁是缺点：造型系统 吞吐量、可用性 下降。 ","date":"2022-06-28","objectID":"/posts/distributed-lock/:0:0","tags":["lock","java"],"title":"Redis 或 Zookeeper 实现分布式锁","uri":"/posts/distributed-lock/"},{"categories":["java"],"content":"\rRedis 实现分布式锁 需要用到redisson包,新建spring-boot项目，导入redisson包 \u003cdependency\u003e \u003cgroupId\u003eorg.redisson\u003c/groupId\u003e \u003cartifactId\u003eredisson-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e3.15.6\u003c/version\u003e \u003c/dependency\u003e 配置Redis连接信息 spring: redis: database: 0 host: 127.0.0.1 port: 6379 锁的具体使用代码 @RestController @AllArgsConstructor public class DistributedLockRedissonController { private final RedissonClient redissonClient; private final StringRedisTemplate stringRedisTemplate; /** * redisson 分布式锁 */ @RequestMapping(\"/redisson/doReduceStack\") public String doReduceStack() { // 检查库存 int store = Integer.parseInt(stringRedisTemplate.opsForValue().get(\"store\")); if (store \u003c= 0) { throw new RuntimeException(\"库存不足\"); } RLock lock = redissonClient.getLock(\"lock\"); try { lock.lock(); // 双重检查 store = Integer.parseInt(stringRedisTemplate.opsForValue().get(\"store\")); if (store \u003c= 0) { throw new RuntimeException(\"库存不足\"); } // 减库存 stringRedisTemplate.opsForValue().set(\"store\", String.valueOf(store - 1)); // 生成订单 System.out.println(\"下单成功\"); return \"下单成功\"; } finally { if (lock.isLocked() \u0026\u0026 lock.isHeldByCurrentThread()) { lock.unlock(); } } } } 实现原理 待完善 ","date":"2022-06-28","objectID":"/posts/distributed-lock/:1:0","tags":["lock","java"],"title":"Redis 或 Zookeeper 实现分布式锁","uri":"/posts/distributed-lock/"},{"categories":["java"],"content":"\rZK 实现分布式锁 需要用到curator包，新建spring-boot项目，导入curator包 \u003cdependency\u003e \u003cgroupId\u003eorg.apache.curator\u003c/groupId\u003e \u003cartifactId\u003ecurator-framework\u003c/artifactId\u003e \u003cversion\u003e5.1.0\u003c/version\u003e \u003c/dependency\u003e 配置zookeeper连接信息 spring: zookeeper: address: 127.0.0.1:2181 注册CuratorFramework客户端 @Configuration public class CommonConfig { @Value(\"${spring.zookeeper.address}\") private String zookeeperAddress; @Bean @ConditionalOnMissingBean({CuratorFramework.class}) public CuratorFramework curatorFramework() { CuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(zookeeperAddress, new RetryNTimes(5, 1000)); curatorFramework.start(); return curatorFramework; } } zookeeper分布式锁使用 @RestController @AllArgsConstructor public class DistributedLockZookeeperController { private CuratorFramework curatorFramework; /** * zookeeper 分布式锁 */ @RequestMapping(\"/zookeeper/get-lock\") public String doReduceStack() throws Exception { InterProcessMutex lock = new InterProcessMutex(curatorFramework, \"/zookeeper/lockId\"); // zookeeper 加锁的两种方式 // lock.acquire() // 尝试加锁，如果加锁失败，会一致的等到加锁成功。 // lock.acquire(3, TimeUnit.SECONDS) // 尝试加锁，如果加锁失败会在3秒内不断获取所，如果3秒内获取锁失败，则抛异常 if (lock.acquire(3, TimeUnit.SECONDS)) { try { // 执行业务 System.out.println(\"获得锁成功，执行业务逻辑！\"); TimeUnit.SECONDS.sleep(2); return \"success\"; } finally { if (lock.isOwnedByCurrentThread()) { lock.release(); } } } else { throw new RuntimeException(\"操作过于频繁\"); } } } 实现原理 待完善 ","date":"2022-06-28","objectID":"/posts/distributed-lock/:2:0","tags":["lock","java"],"title":"Redis 或 Zookeeper 实现分布式锁","uri":"/posts/distributed-lock/"},{"categories":["java"],"content":"\r分布式锁总结","date":"2022-06-28","objectID":"/posts/distributed-lock/:3:0","tags":["lock","java"],"title":"Redis 或 Zookeeper 实现分布式锁","uri":"/posts/distributed-lock/"},{"categories":["java"],"content":"Spring 事务利用AOP原理实现,主要过程和AOP原理一样，可以分为三步，启用事务、生成代理对对象、执行。 ","date":"2022-06-28","objectID":"/posts/spring-transaction/:0:0","tags":["java","spring"],"title":"Spring 事务源码解析","uri":"/posts/spring-transaction/"},{"categories":["java"],"content":"\r从如何使用事务开始本实例使用Spring的 JdbcTemplate 作为操作数据库的工具，使用 druid 做为数据库连接池。 首先导入相关的 jar 包 \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003cversion\u003e8.0.20\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e \u003cartifactId\u003edruid\u003c/artifactId\u003e \u003cversion\u003e1.2.4\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-jdbc\u003c/artifactId\u003e \u003cversion\u003e5.2.12.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-tx\u003c/artifactId\u003e \u003cversion\u003e5.2.12.RELEASE\u003c/version\u003e \u003c/dependency\u003e 在配置类上加上 @EnableTransactionManagement 注解表示开启Spring事务功能 @ComponentScan(\"com.example\") @EnableTransactionManagement public class ApplicationMain {} 配置数据源、配置JdbcTemplate、配置事务管理器 @Configuration public class JdbcConfig { @Bean(initMethod = \"init\") public DruidDataSource dataSource() { DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(\"jdbc:mysql://localhost/test?useUnicode=true\u0026characterEncoding=utf-8\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"rootroot\"); return dataSource; } @Bean public JdbcTemplate jdbcTemplate(DataSource dataSource) { return new JdbcTemplate(dataSource); } @Bean public TransactionManager transactionManager(DataSource dataSource) { return new DataSourceTransactionManager(dataSource); } } 创建测试表 blog、创建实体对象Blog create table blog ( id int auto_increment comment 'id' primary key, title varchar(20) null comment '标题', content varchar(100) null comment '内容' ) comment 'blog表'; 创建实体对象 @Getter @Setter @ToString @Accessors(chain = true) public class Blog { private Integer id; private String title; private String content; } 创建 BlogService和一个 insert 方法插入一条记录，在方法上加上 @Transactional 注解，在执行插入数据成功后故意写个异常情况1/0，测试事务是否回滚。 @Service @AllArgsConstructor public class BlogService { private final JdbcTemplate jdbcTemplate; @Transactional(rollbackFor = Exception.class) public int insert(Blog blog) { String sql = \"insert into blog(title,content) value(?,?)\"; Object[] args = new Object[]{blog.getTitle(), blog.getContent()}; int ret = jdbcTemplate.update(sql, args); System.out.println(1 / 0); return ret; } } 执行测试方法,看运行结果 @ComponentScan(\"com.example\") @EnableTransactionManagement public class ApplicationMain { public static void main(String[] args) { ApplicationContext context = new AnnotationConfigApplicationContext(ApplicationMain.class); BlogService blogService = context.getBean(BlogService.class); Blog blog = new Blog().setTitle(\"xxx222\").setContent(\"xxx2222\"); System.out.println(blogService.insert(blog)); } } 查询执行结果 从执行结果看，后面的代码抛异常后，事务回滚了，那个仅凭一个简单的注解事务是如何开启、提交已经回滚的呢，下面我们从底层源码一探究竟。 ","date":"2022-06-28","objectID":"/posts/spring-transaction/:1:0","tags":["java","spring"],"title":"Spring 事务源码解析","uri":"/posts/spring-transaction/"},{"categories":["java"],"content":"\r从事务的入口 开始@EnableTransactionManagement 点开 @EnableTransactionManagement 注解，我们发现他导入了另一类@Import(TransactionManagementConfigurationSelector.class)，@Import 的作用是它可以导入一个普通类到Spring容器中，使其注册为一个bean。 TransactionManagementConfigurationSelector 类它有实现了 ImportSelector 接口，重写了 selectImports 方法，该方法会在Spring扫描的时候执行，通过返回的类名数组生成bean，最后发现添加EnableTransactionManagement注解的最终目的是注入 AutoProxyRegistrar 和 ProxyTransactionManagementConfiguration 这两个类到Spring容器。 AutoProxyRegistrar AopConfigUtils.registerAutoProxyCreatorIfNecessary(registry); @Nullable public static BeanDefinition registerAutoProxyCreatorIfNecessary( BeanDefinitionRegistry registry, @Nullable Object source) { return registerOrEscalateApcAsRequired(InfrastructureAdvisorAutoProxyCreator.class, registry, source); } public class InfrastructureAdvisorAutoProxyCreator extends AbstractAdvisorAutoProxyCreator { @Nullable private ConfigurableListableBeanFactory beanFactory; @Override protected void initBeanFactory(ConfigurableListableBeanFactory beanFactory) { super.initBeanFactory(beanFactory); this.beanFactory = beanFactory; } @Override protected boolean isEligibleAdvisorBean(String beanName) { return (this.beanFactory != null \u0026\u0026 this.beanFactory.containsBeanDefinition(beanName) \u0026\u0026 this.beanFactory.getBeanDefinition(beanName).getRole() == BeanDefinition.ROLE_INFRASTRUCTURE); } } AutoProxyRegistrar 实现了 ImportBeanDefinitionRegistrar，重写了 registerBeanDefinitions 方法，该方法在Spring容器启动的时候回执行，可以注册bean定义，在这里核心是注册了另一个 bean InfrastructureAdvisorAutoProxyCreator,InfrastructureAdvisorAutoProxyCreator方法中几乎没有什么核心代码，它的全部功能来源于 AOP 解析类 AbstractAdvisorAutoProxyCreator。 ProxyTransactionManagementConfiguration @Configuration public class ProxyTransactionManagementConfiguration extends AbstractTransactionManagementConfiguration { @Bean(name = TransactionManagementConfigUtils.TRANSACTION_ADVISOR_BEAN_NAME) @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public BeanFactoryTransactionAttributeSourceAdvisor transactionAdvisor() { BeanFactoryTransactionAttributeSourceAdvisor advisor = new BeanFactoryTransactionAttributeSourceAdvisor(); advisor.setTransactionAttributeSource(transactionAttributeSource()); advisor.setAdvice(transactionInterceptor()); if (this.enableTx != null) { advisor.setOrder(this.enableTx.\u003cInteger\u003egetNumber(\"order\")); } return advisor; } @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public TransactionAttributeSource transactionAttributeSource() { return new AnnotationTransactionAttributeSource(); } @Bean @Role(BeanDefinition.ROLE_INFRASTRUCTURE) public TransactionInterceptor transactionInterceptor() { TransactionInterceptor interceptor = new TransactionInterceptor(); interceptor.setTransactionAttributeSource(transactionAttributeSource()); if (this.txManager != null) { interceptor.setTransactionManager(this.txManager); } return interceptor; } } ProxyTransactionManagementConfiguration 类是一个配置类，他注册了三个bean。 BeanFactoryTransactionAttributeSourceAdvisor 它是一个Advisor，实现了Advisor 接口，它是是AOP的其中一种方式和 @Aspect 注解效果是一样的，都会被AOP解析识别。 AnnotationTransactionAttributeSource 是事务属性源，他主要负责判断一个bean及其方法是不是有@Transactional注解，如果有就要生成动态代理。 TransactionInterceptor 该类是代理类具体实现逻辑，生成代理代理对象时会用到，在具体执行事务时会调用其中的 invock 方法。 另外 AnnotationTransactionAttributeSource 和 TransactionInterceptor 都是 BeanFactoryTransactionAttributeSourceAdvisor 的属性，具体的调用在BeanFactoryTransactionAttributeSourceAdvisor 完成。 以上就是启用事务时所作的事情。 ","date":"2022-06-28","objectID":"/posts/spring-transaction/:2:0","tags":["java","spring"],"title":"Spring 事务源码解析","uri":"/posts/spring-transaction/"},{"categories":["java"],"content":"\r何时生成代理对象什么时候生成代理对象 ？ 为那些bean生成代理对象？ InfrastructureAdvisorAutoProxyCreator 还记得它吗，该对象时具体扫描 @Transactional 标注的类和方法，再生成代理对象的，但是它的核心功能都是继承自AOP的对象AbstractAdvisorAutoProxyCreator 的，所以说事务的实现在于创建了符合AOP规则的 Advisor(BeanFactoryTransactionAttributeSourceAdvisor) ，然后交给AOP去生成代理对象, AOP 在哪里找到 BeanFactoryTransactionAttributeSourceAdvisor ? ","date":"2022-06-28","objectID":"/posts/spring-transaction/:3:0","tags":["java","spring"],"title":"Spring 事务源码解析","uri":"/posts/spring-transaction/"},{"categories":["java"],"content":"\r何时调用事务方法未完 ","date":"2022-06-28","objectID":"/posts/spring-transaction/:4:0","tags":["java","spring"],"title":"Spring 事务源码解析","uri":"/posts/spring-transaction/"},{"categories":["java"],"content":"常见注册bean对象到spring容器的方式: @Component、@Controller、@Service、@Repository 方式 @Bean 工厂方式 @mport 普通类 @Import ImportSelector @Import ImportBeanDefinitionRegistrar 实现 BeanDefinitionRegistryPostProcessor#postProcessBeanDefinitionRegistry ","date":"2022-06-28","objectID":"/posts/spring-ioc-bean-register/:0:0","tags":["java","spring"],"title":"Spring容器注册bean有哪些方式？","uri":"/posts/spring-ioc-bean-register/"},{"categories":["java"],"content":"\r方式一：@注解方式最常见的可以用 @Component、@Controller、@Service、@Repository 注解方式注入对象到spring容器中。 @Component public class RequestTemplate{ } @Service public class UserServiceImpl implements UserService { } ","date":"2022-06-28","objectID":"/posts/spring-ioc-bean-register/:1:0","tags":["java","spring"],"title":"Spring容器注册bean有哪些方式？","uri":"/posts/spring-ioc-bean-register/"},{"categories":["java"],"content":"\r方式二：Bean 工厂方式 @Configuration public class AppConfig { /** * 注册 user对象，默认方法名为beanName */ @Bean public User user(){ return new User(); } } ","date":"2022-06-28","objectID":"/posts/spring-ioc-bean-register/:2:0","tags":["java","spring"],"title":"Spring容器注册bean有哪些方式？","uri":"/posts/spring-ioc-bean-register/"},{"categories":["java"],"content":"\r方式三：@Import 普通类 @Import(Cat.class) @Configuration public class AppConfig { } ","date":"2022-06-28","objectID":"/posts/spring-ioc-bean-register/:3:0","tags":["java","spring"],"title":"Spring容器注册bean有哪些方式？","uri":"/posts/spring-ioc-bean-register/"},{"categories":["java"],"content":"\r方式四：@Import ImportSelector可以通过 import 实现ImportSelector接口的类，重写selectImports方法可以再注册其他的类。 public class UserImportSelector implements ImportSelector { @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) { // 注册User类型到spring容器中 return new String[]{User.class.getName()}; } } @Import(UserImportSelector.class) public class ImportSelectorSpringBeanDemo { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(ImportSelectorSpringBeanDemo.class); System.out.println(ctx.getBean(User.class)); } } ","date":"2022-06-28","objectID":"/posts/spring-ioc-bean-register/:4:0","tags":["java","spring"],"title":"Spring容器注册bean有哪些方式？","uri":"/posts/spring-ioc-bean-register/"},{"categories":["java"],"content":"\r方式五：@Import ImportBeanDefinitionRegistrar通过import实现 ImportBeanDefinitionRegistrar 接口的类，重写registerBeanDefinitions方法可以再注册其他类。 public class UserImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { // 注册User的ben定义 BeanDefinition beanDefinition = new RootBeanDefinition(User.class); registry.registerBeanDefinition(User.class.getName(), beanDefinition); } } @Import(UserImportBeanDefinitionRegistrar.class) public class ImportBeanDefinitionRegistrarSpringBeanDemo { public static void main(String[] args) { ApplicationContext ctx = new AnnotationConfigApplicationContext(ImportBeanDefinitionRegistrarSpringBeanDemo.class); System.out.println(ctx.getBean(User.class)); } } ","date":"2022-06-28","objectID":"/posts/spring-ioc-bean-register/:5:0","tags":["java","spring"],"title":"Spring容器注册bean有哪些方式？","uri":"/posts/spring-ioc-bean-register/"},{"categories":["java"],"content":"\r方式六：实现 BeanDefinitionRegistryPostProcessor 接口 @Component public class MyBeanDefinitionRegistryPostProcessor implements BeanDefinitionRegistryPostProcessor { @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException { // 注册其他bean RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Dog.class); registry.registerBeanDefinition(\"dog\", rootBeanDefinition); } 前提先注册 MyBeanDefinitionRegistryPostProcessor对象, spring容器才能触发 postProcessBeanDefinitionRegistry 方法。 ","date":"2022-06-28","objectID":"/posts/spring-ioc-bean-register/:6:0","tags":["java","spring"],"title":"Spring容器注册bean有哪些方式？","uri":"/posts/spring-ioc-bean-register/"},{"categories":["other"],"content":"\r查找Command + F ","date":"2022-06-28","objectID":"/posts/vscode/:1:0","tags":["vscode"],"title":"Vscode 常用快捷键","uri":"/posts/vscode/"},{"categories":["other"],"content":"\r查找替换Command + R ","date":"2022-06-28","objectID":"/posts/vscode/:2:0","tags":["vscode"],"title":"Vscode 常用快捷键","uri":"/posts/vscode/"},{"categories":["other"],"content":"\r多行编辑Shit + Option + I 先 Comand+A 批量选中多行，再Shift+Optaion+i 插入多行光标。 ","date":"2022-06-28","objectID":"/posts/vscode/:3:0","tags":["vscode"],"title":"Vscode 常用快捷键","uri":"/posts/vscode/"},{"categories":["other"],"content":"\r多行转一行Control + Shift + j 先 Comand+A 批量选中多行，再 Control + Shift + j 转为一行。 ","date":"2022-06-28","objectID":"/posts/vscode/:4:0","tags":["vscode"],"title":"Vscode 常用快捷键","uri":"/posts/vscode/"},{"categories":["other"],"content":"\r批量替换Command + Shift + L 方法一：先选中一个要编辑的内容，再 Command + Shift + L 就批量选中所有相同的内容，再编辑； 方法二：先Control + F 查找要编辑的内容，再 Command + Shift + L 就批量选中所有相同的内容，再Esc关闭查找框，再编辑。 方法三：先Controll + R ，输入查找和替换的内容，再点击替换框后面最后一个图标。 ","date":"2022-06-28","objectID":"/posts/vscode/:5:0","tags":["vscode"],"title":"Vscode 常用快捷键","uri":"/posts/vscode/"},{"categories":["中间件"],"content":"\rRocketMQ 集群架构图 ","date":"2022-06-28","objectID":"/posts/rocketmq/:1:0","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rRocketMQ 四大核心集群 NameServer 集群：作为注册中心，维护着所有的broker和topic的映射关系，以及路由功能，多台部署，之间不互相通信。 Broker集群 ：负责消息存储，消息转发。 Producer集群 ：生产消息，一般是自己的Application集群。 Consumer集群：消费消息，一般是自己的Application集群。 ","date":"2022-06-28","objectID":"/posts/rocketmq/:2:0","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rRocketMQ 其他核心组件 Consumer Group：消费者组，集群模式相同Group的每个Consumer平均分摊消息，广播模式相同Group的每个Consumer都接收全量消息。 Topic：一类消息的集合，一个消息只能属于一个Topic。 Message：消息的载体。 Message Queue：消息分区，每个Topic下可以有多个分区。 Tag：给消息设置一个标签，消费者可以过滤出想要的消息。 ","date":"2022-06-28","objectID":"/posts/rocketmq/:3:0","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rRocketMQ 消息发送方式","date":"2022-06-28","objectID":"/posts/rocketmq/:4:0","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\r单项发送只负责发出去，不管是否成功，没有返回值，一般用在可靠性不高的场景，如记录日志。 producer.sendOneway(msg); ","date":"2022-06-28","objectID":"/posts/rocketmq/:4:1","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\r同步发送需要同步等待消费发送的结果，有返回值，用在可靠性要求高，性能不高的场景。 // Send message to one of brokers SendResult sendResult = producer.send(msg); // Check whether the message has been delivered by the callback of sendResult System.out.printf(\"%s%n\", sendResult); ","date":"2022-06-28","objectID":"/posts/rocketmq/:4:2","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\r异步发送无需等待返回值，需要实现回调方法，消息发送完成会自动执行回调方法，用在可靠性和性能要求较高的场景。 producer.send(msg, new SendCallback() { @Override public void onSuccess(SendResult sendResult) { System.out.printf(\"%-10d OK %s %n\", index, sendResult.getMsgId()); } @Override public void onException(Throwable e) { System.out.printf(\"%-10d Exception %s %n\", index, e); e.printStackTrace(); } }); ","date":"2022-06-28","objectID":"/posts/rocketmq/:4:3","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rRocketMQ 消息类型","date":"2022-06-28","objectID":"/posts/rocketmq/:5:0","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\r顺序消息 局部有序：需要生产者和消费者同时保证，只能把需要保证有序的消息发送到同一个MessageQuenue，在消费者端同一个MessageQuenue的消息只能由一个消费者消费。 如：电商场景的下单业务，对于同一个丁当它从下单、付款、发货是有序的，但不同的订单之间又是无序的，可用这种方案。 生产者端代码：实现 select 方法，把相同订单的消息发在同一个 quenue。 SendResult sendResult = producer.send(msg, new MessageQueueSelector() { @Override public MessageQueue select(List\u003cMessageQueue\u003e mqs, Message msg, Object arg) { Long id = (Long) arg; //根据订单id选择发送queue long index = id % mqs.size(); return mqs.get((int) index); } }, orderList.get(i).getOrderId());//订单id 消费者端代码： 重要的是注册一个MessageListenerOrderly类型的消费者 consumer.registerMessageListener(new MessageListenerOrderly() { @Override public ConsumeOrderlyStatus consumeMessage(List\u003cMessageExt\u003e msgs, ConsumeOrderlyContext context) { context.setAutoCommit(true); for (MessageExt msg : msgs) { // 可以看到每个queue有唯一的consume线程来消费, 订单对每个queue(分区)有序 System.out.println(\"consumeThread=\" + Thread.currentThread().getName() + \"queueId=\" + msg.getQueueId() + \", content:\" + new String(msg.getBody())); } return ConsumeOrderlyStatus.SUCCESS; } }); 全局有序：一个Topic只能有一个MessageQuenue以及消费只能有一个消费者，一般不这么用。 ","date":"2022-06-28","objectID":"/posts/rocketmq/:5:1","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\r事务消息是指应用本地事务和消息可以定义在一个全局事务中，要么同时成功，要么同时失败，可应用在消息和数据库数据严格一致的场景。 样例：https://github.com/apache/rocketmq/blob/master/docs/cn/RocketMQ_Example.md#61-发送事务消息样例 ","date":"2022-06-28","objectID":"/posts/rocketmq/:5:2","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\r延迟消息消息发送给brocker后不会立即消息，一段时间后投递给真正的 Topic， 比如：电商场景一个订单创建1小时候没付款，自动释放库存。 Message message = new Message(\"TestTopic\", (\"Hello scheduled message \" + i).getBytes()); // 设置延时等级3,这个消息将在10s之后发送(现在只支持固定的几个时间,详看delayTimeLevel) message.setDelayTimeLevel(3); // 发送消息 producer.send(message); 使用限制 private String messageDelayLevel = \"1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h\"; ","date":"2022-06-28","objectID":"/posts/rocketmq/:5:3","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\r可靠消息 如何保证生产者发消息成功？同步发消息、同步方式同步从节点、同步方式刷盘。 如何保证消费者消费成功？不要异步消费，消费成功返回ACK，如果消费失败，MQ会重试。 MQ 集群宕机怎么办？把消息咱存在Redis，等MQ恢复后再异步再发给MQ。 ","date":"2022-06-28","objectID":"/posts/rocketmq/:5:4","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\r消息过滤发消息时设置 TAG，消费端可以用TAG过滤只选择自己想要的消息，不想要的不会发给消费者，可以减少网络传输，但增加复杂性。 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"CID_EXAMPLE\"); consumer.subscribe(\"TOPIC\", \"TAGA || TAGB || TAGC\"); ","date":"2022-06-28","objectID":"/posts/rocketmq/:5:5","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\r回溯消息消费过的消息不会立即删除，如果MQ宕机重启后，消费者可以选择重新消费某一时间前的历史消息重新消费，称为回溯消息。 ","date":"2022-06-28","objectID":"/posts/rocketmq/:5:6","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\r流量控制如果 broker 的处理能达到瓶颈，可设置拒绝消息发送，消费者端可通过降低拉取消息的评率流控。 ","date":"2022-06-28","objectID":"/posts/rocketmq/:5:7","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\r死信队列对于消费失败的消息，重试次数达到最大值后会迁移到一个特殊的队列，这类消息称为死信，可以在MQ控制台手动重发来进行消费。 ","date":"2022-06-28","objectID":"/posts/rocketmq/:5:8","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rRocketMQ 核心原理","date":"2022-06-28","objectID":"/posts/rocketmq/:6:0","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\r事务消息原理","date":"2022-06-28","objectID":"/posts/rocketmq/:6:1","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rBrocker 选主原理 Broker 启动后会主动向NameServer注册自己的信息，之后每隔30秒上报一次Topic路由信息。 为保证Broker高可用，borker 引入了 dledger 集群部署方式，当主节点宕机后，dledger集群会自动产生一个新的主节点提供服务，dledger 实现了 Raft 协议，支持选主等功能，更多参考：DLedger - 基于 Raft 算法的 Commitlog Library 。 相比kafa引入 zk 实现动态选主的方式dledger 更加轻量，可以直接以 jar 使用。 ","date":"2022-06-28","objectID":"/posts/rocketmq/:6:2","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rBrocker 存储消息原理RocketMQ 实现消息持久化存储，主要有如下三种文件组成。 CommitLog：具体存储消息的载体，提前申请连续存储空间，顺序写入速度快。 ConsumeQueue：消费队列，记录Topic和消息存储关系，已经记录消息的当前消费位置（偏移量）。 IndexFile：索引文件，可通过KEY或时间区间快速查询消息。 ","date":"2022-06-28","objectID":"/posts/rocketmq/:6:3","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rRocketMQ 源码解析","date":"2022-06-28","objectID":"/posts/rocketmq/:7:0","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rNameServer 源码 从启动类 NamesrvStartup 开始 public static void main(String[] args) { main0(args); } public static NamesrvController main0(String[] args) { try { // 实例化 NamesrvController 对象 NamesrvController controller = createNamesrvController(args); // 执行启动逻辑 start(controller); return controller; } catch (Throwable e) { e.printStackTrace(); System.exit(-1); } return null; } 关键代码就以上两行，createNamesrvController 方法实例化NamesrvController对象，然后执行start方法实现启动逻辑 createNamesrvController() 方法解析 public static NamesrvController createNamesrvController(String[] args) throws IOException, JoranException { System.setProperty(RemotingCommand.REMOTING_VERSION_KEY, Integer.toString(MQVersion.CURRENT_VERSION)); //PackageConflictDetect.detectFastjson(); Options options = ServerUtil.buildCommandlineOptions(new Options()); commandLine = ServerUtil.parseCmdLine(\"mqnamesrv\", args, buildCommandlineOptions(options), new PosixParser()); if (null == commandLine) { System.exit(-1); return null; } // 实例化 NameServer 配置类 final NamesrvConfig namesrvConfig = new NamesrvConfig(); // 实例化 Netty 配置类 final NettyServerConfig nettyServerConfig = new NettyServerConfig(); nettyServerConfig.setListenPort(9876); if (commandLine.hasOption('c')) { // 解析参数C，C参数用来置顶配置的文件, 具体逻辑代码忽略。 } if (commandLine.hasOption('p')) { // 解析参数p，p参数用来单独设置配置属性和属性值，具体逻辑代码忽略。 } MixAll.properties2Object(ServerUtil.commandLine2Properties(commandLine), namesrvConfig); if (null == namesrvConfig.getRocketmqHome()) { System.out.printf(\"Please set the %s variable in your environment to match the location of the RocketMQ installation%n\", MixAll.ROCKETMQ_HOME_ENV); System.exit(-2); } // 加载日志配置文件 LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); JoranConfigurator configurator = new JoranConfigurator(); configurator.setContext(lc); lc.reset(); configurator.doConfigure(namesrvConfig.getRocketmqHome() + \"/conf/logback_namesrv.xml\"); log = InternalLoggerFactory.getLogger(LoggerName.NAMESRV_LOGGER_NAME); MixAll.printObjectProperties(log, namesrvConfig); MixAll.printObjectProperties(log, nettyServerConfig); // 使用前面两个 configure 对象实例化 NamesrvController对象。 final NamesrvController controller = new NamesrvController(namesrvConfig, nettyServerConfig); // remember all configs to prevent discard controller.getConfiguration().registerConfig(properties); return controller; } 这里主要做了两件事，1.把所有的配置信息解析成 NamesrvConfig 和 NettyServerConfig 对象。2.传入使用配置对象实例化NamesrvController对象。 下面看下实例化 NamesrvController 的构造方法做可哪些事 public NamesrvController(NamesrvConfig namesrvConfig, NettyServerConfig nettyServerConfig) { this.namesrvConfig = namesrvConfig; this.nettyServerConfig = nettyServerConfig; this.kvConfigManager = new KVConfigManager(this); this.routeInfoManager = new RouteInfoManager(); this.brokerHousekeepingService = new BrokerHousekeepingService(this); this.configuration = new Configuration( log, this.namesrvConfig, this.nettyServerConfig ); this.configuration.setStorePathFromConfig(this.namesrvConfig, \"configStorePath\"); } 就是一些对象的赋值操作，测试 NamesrvController 对象创建完毕。 启动方法 start(controller) public static NamesrvController start(final NamesrvController controller) throws Exception { if (null == controller) { throw new IllegalArgumentException(\"NamesrvController is null\"); } // 执行 NamesrvController 的初始化方法 boolean initResult = controller.initialize(); if (!initResult) { controller.shutdown(); System.exit(-3); } // 注册钩子方法，服务关闭是执行，做一些清理工作。 Runtime.getRuntime().addShutdownHook(new ShutdownHookThread(log, new Callable\u003cVoid\u003e() { @Override public Void call() throws Exception { controller.shutdown(); return null; } })); // 执行启动 controller.start(); return controller; } 这里重要有两个方法，controller.initialize() 和 controller.start()，下面具体看下执行逻辑。 controller.initialize() public boolean initialize() { // 加载 kv存储模块，读取配置中的 kvConfig.json文件内容。 this.kvConfigManager.load(); // 实例化 Netty服务端对象，用于处理客户端和 broker的请求。 this.remotingServer = new NettyRemotingServer(this.nettyServerConfig, this.brokerHousekeepingService); this.remotingExecutor = Executors.newFixedThreadPo","date":"2022-06-28","objectID":"/posts/rocketmq/:7:1","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rBroker 启动源码从启动类 BrokerStartup 开始 public static void main(String[] args) { start(createBrokerController(args)); } 有两个核心方法，createBrokerController 方法创建BrokerController对象，然后传个 start 方法执行启动工作。 createBrokerController 方法 public static BrokerController createBrokerController(String[] args) { try { //PackageConflictDetect.detectFastjson(); Options options = ServerUtil.buildCommandlineOptions(new Options()); commandLine = ServerUtil.parseCmdLine(\"mqbroker\", args, buildCommandlineOptions(options), new PosixParser()); if (null == commandLine) { System.exit(-1); } // 实例化 broker 的配置对象 final BrokerConfig brokerConfig = new BrokerConfig(); // 实例化 Netty 配置对象 final NettyServerConfig nettyServerConfig = new NettyServerConfig(); final NettyClientConfig nettyClientConfig = new NettyClientConfig(); // 设置 Netty 的端口 nettyServerConfig.setListenPort(10911); // 实例化消息存储的配置对象 final MessageStoreConfig messageStoreConfig = new MessageStoreConfig(); if (BrokerRole.SLAVE == messageStoreConfig.getBrokerRole()) { int ratio = messageStoreConfig.getAccessMessageInMemoryMaxRatio() - 10; messageStoreConfig.setAccessMessageInMemoryMaxRatio(ratio); } if (commandLine.hasOption('c')) { // 解析参数 c } MixAll.properties2Object(ServerUtil.commandLine2Properties(commandLine), brokerConfig); if (null == brokerConfig.getRocketmqHome()) { System.out.printf(\"Please set the %s variable in your environment to match the location of the RocketMQ installation\", MixAll.ROCKETMQ_HOME_ENV); System.exit(-2); } String namesrvAddr = brokerConfig.getNamesrvAddr(); if (null != namesrvAddr) { try { String[] addrArray = namesrvAddr.split(\";\"); for (String addr : addrArray) { RemotingUtil.string2SocketAddress(addr); } } catch (Exception e) { System.out.printf( \"The Name Server Address[%s] illegal, please set it as follows, \\\"127.0.0.1:9876;192.168.0.1:9876\\\"%n\", namesrvAddr); System.exit(-3); } } switch (messageStoreConfig.getBrokerRole()) { case ASYNC_MASTER: case SYNC_MASTER: brokerConfig.setBrokerId(MixAll.MASTER_ID); break; case SLAVE: if (brokerConfig.getBrokerId() \u003c= 0) { System.out.printf(\"Slave's brokerId must be \u003e 0\"); System.exit(-3); } break; default: break; } if (messageStoreConfig.isEnableDLegerCommitLog()) { brokerConfig.setBrokerId(-1); } messageStoreConfig.setHaListenPort(nettyServerConfig.getListenPort() + 1); LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); JoranConfigurator configurator = new JoranConfigurator(); configurator.setContext(lc); lc.reset(); configurator.doConfigure(brokerConfig.getRocketmqHome() + \"/conf/logback_broker.xml\"); if (commandLine.hasOption('p')) { // 解析参数 p } else if (commandLine.hasOption('m')) { // 解析参数 m } log = InternalLoggerFactory.getLogger(LoggerName.BROKER_LOGGER_NAME); MixAll.printObjectProperties(log, brokerConfig); MixAll.printObjectProperties(log, nettyServerConfig); MixAll.printObjectProperties(log, nettyClientConfig); MixAll.printObjectProperties(log, messageStoreConfig); // 实例化 BrokerController 对象 final BrokerController controller = new BrokerController( brokerConfig, nettyServerConfig, nettyClientConfig, messageStoreConfig); // remember all configs to prevent discard controller.getConfiguration().registerConfig(properties); boolean initResult = controller.initialize(); if (!initResult) { controller.shutdown(); System.exit(-3); } // 注册一个 JVM 关闭时的钩子方法，用于做一些清理工作 Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() { private volatile boolean hasShutdown = false; private AtomicInteger shutdownTimes = new AtomicInteger(0); @Override public void run() { synchronized (this) { log.info(\"Shutdown hook was invoked, {}\", this.shutdownTimes.incrementAndGet()); if (!this.hasShutdown) { this.hasShutdown = true; long beginTime = System.currentTimeMillis(); controller.shutdown(); long consumingTimeTotal = System.currentTimeMillis() - beginTime; log.info(\"Shutdown hook over, consuming total time(ms): {}\", consumingTimeTotal); } } } }, \"ShutdownHook\")); return controller; } catch (Throwable e) { e.printStackTrace(); System.","date":"2022-06-28","objectID":"/posts/rocketmq/:7:2","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rProducer 发消息给Broker 源码Producer 发消息主要代码在 client 包中实现，发消息的方式大致有三种，单向、同步、异步。发消息的默认入口都在 DefaultMQProducerImpl 这个类中，下面看下最简单的单向发消息接口。 单向发消息 DefaultMQProducerImpl 类中的 sendOneway 是单向发消息的入口 public void sendOneway(Message msg) throws MQClientException, RemotingException, InterruptedException { try { this.sendDefaultImpl(msg, CommunicationMode.ONEWAY, null, this.defaultMQProducer.getSendMsgTimeout()); } catch (MQBrokerException e) { throw new MQClientException(\"unknown exception\", e); } } 接着调用私有方法 this.sendDefaualtImpl() private SendResult sendDefaultImpl( Message msg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout ) throws MQClientException, RemotingException, MQBrokerException, InterruptedException { // ... 忽略一些不必要的代码 // 获取Topic信息 TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); // 判断Topic是否正常 if (topicPublishInfo != null \u0026\u0026 topicPublishInfo.ok()) { boolean callTimeout = false; MessageQueue mq = null; Exception exception = null; SendResult sendResult = null; int timesTotal = communicationMode == CommunicationMode.SYNC ? 1 + this.defaultMQProducer.getRetryTimesWhenSendFailed() : 1; int times = 0; String[] brokersSent = new String[timesTotal]; for (; times \u003c timesTotal; times++) { String lastBrokerName = null == mq ? null : mq.getBrokerName(); // 选择一个MessageQueue MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, lastBrokerName); if (mqSelected != null) { mq = mqSelected; brokersSent[times] = mq.getBrokerName(); try { beginTimestampPrev = System.currentTimeMillis(); if (times \u003e 0) { //Reset topic with namespace during resend. msg.setTopic(this.defaultMQProducer.withNamespace(msg.getTopic())); } long costTime = beginTimestampPrev - beginTimestampFirst; if (timeout \u003c costTime) { callTimeout = true; break; } // 发送消息 sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, topicPublishInfo, timeout - costTime); endTimestamp = System.currentTimeMillis(); this.updateFaultItem(mq.getBrokerName(), endTimestamp - beginTimestampPrev, false); switch (communicationMode) { case ASYNC: // 异步发送消息不关心返回值 return null; case ONEWAY: // 单项发送消息不关心返回值 return null; case SYNC: // 同步发送消息需要返回值 if (sendResult.getSendStatus() != SendStatus.SEND_OK) { if (this.defaultMQProducer.isRetryAnotherBrokerWhenNotStoreOK()) { continue; } } return sendResult; default: break; } } catch (RemotingException e) { // 处理异常... } } else { break; } } if (sendResult != null) { return sendResult; } //... } 选择要发送的 MessageQucence, 这里有具体的负载均衡算实现。 发送消息都调用私有方法 this.sendKernelImpl 实现。 this.sendKernelImpl()方法 private SendResult sendKernelImpl(final Message msg, final MessageQueue mq, final CommunicationMode communicationMode, final SendCallback sendCallback, final TopicPublishInfo topicPublishInfo, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException { long beginStartTime = System.currentTimeMillis(); // 根据 broker名称查询地址 String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName()); if (null == brokerAddr) { tryToFindTopicPublishInfo(mq.getTopic()); brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName()); } SendMessageContext context = null; if (brokerAddr != null) { brokerAddr = MixAll.brokerVIPChannel(this.defaultMQProducer.isSendMessageWithVIPChannel(), brokerAddr); byte[] prevBody = msg.getBody(); try { //for MessageBatch,ID has been set in the generating process // 设置参数，忽略 SendResult sendResult = null; switch (communicationMode) { case ASYNC: // 异步发送消息 Message tmpMessage = msg; boolean messageCloned = false; if (msgBodyCompressed) { //If msg body was compressed, msgbody should be reset using prevBody. //Clone new message using commpressed message body and recover origin massage. //Fix bug:https://github.com/apache/rocketmq-externals/issues/66 tmpMessage = MessageAccessor.cloneMessage(msg); messageCloned = true; msg.setBody(prevBody); } if (topicWithNamespace) { if (!mess","date":"2022-06-28","objectID":"/posts/rocketmq/:7:3","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rBroker 负载均衡源码Producer 发送消息给Topic时，会选择一个MessageQuence, 默认的负载均衡算法是轮询，每个qucence大致平均分配。 private SendResult sendDefaultImpl( Message msg, final CommunicationMode communicationMode, final SendCallback sendCallback, final long timeout ) throws MQClientException, RemotingException, MQBrokerException, InterruptedException { //... // 选择一个MessageQueue MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, lastBrokerName); //... } 默认情况下最终调用下面方法，每个线程第一访问时，会随机取一个整型值，每次对该值加1取绝对值后对quence的数量取模。 public MessageQueue selectOneMessageQueue() { int index = this.sendWhichQueue.incrementAndGet(); int pos = Math.abs(index) % this.messageQueueList.size(); if (pos \u003c 0) pos = 0; return this.messageQueueList.get(pos); } ","date":"2022-06-28","objectID":"/posts/rocketmq/:7:4","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rBroker 接收消息及刷盘持久化源码待补充 ","date":"2022-06-28","objectID":"/posts/rocketmq/:7:5","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rConsumer 推模式源码推模式实时性高，但占用网络资源多。 ","date":"2022-06-28","objectID":"/posts/rocketmq/:7:6","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rConsumer 拉模式源码拉模式可以批量消费，实时性不高，但能减少网络带宽。 ","date":"2022-06-28","objectID":"/posts/rocketmq/:7:7","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rRocketMQ 对比其他MQ RabbitMQ 安全性高，可靠性高，但吞吐量低。 Kafka 性能高，但功能单一，且可能会丢消息。 RocketMQ 性能高，功能全，几乎全场景都能使用。 ","date":"2022-06-28","objectID":"/posts/rocketmq/:8:0","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"},{"categories":["中间件"],"content":"\rRocketMQ 常见问题 如何保证消息不丢失？ MQ服务正常时，生产者端采用同步发送、同步刷盘、同步同步发给从节点，消费者端消费失败自动重试。 MQ服务挂掉时，把消息在暂时存入Redis，等MQ服务恢复后再发给MQ。 如何保证消息有序？ 局部有序：生产者这段把需要保证有序的消息发在同一个队列，消费者端一个队列只绑定一下消费者。 全局有序：所有消息只有有一个队列，性能很低。 如何处理消息积压？ 当队列多时：增加消费者提高消费的效率。 当队列少时：创建一个队列多的Topic，迁移消息，再增加消费者消费。 ","date":"2022-06-28","objectID":"/posts/rocketmq/:9:0","tags":["java","rocketmq"],"title":"一文搞懂 RocketMQ","uri":"/posts/rocketmq/"}]